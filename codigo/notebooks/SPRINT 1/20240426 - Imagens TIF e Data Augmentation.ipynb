{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u6gu0z2zxJp"
      },
      "source": [
        "# Image Preprocessing\n",
        "\n",
        "O pré-processamento de imagens é uma etapa crucial na preparação de imagens para aprendizado de máquina tarefas. Envolve diversas técnicas para melhorar a qualidade das imagens, reduzir ruído e extrair recursos significativos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XD96HrTB9qc"
      },
      "source": [
        "### Visualizando a imagem\n",
        "Estamos utilizando as diferentes bandas (dispostas nos arquivos tifs em _./images_) agregando por duas maneiras diferentes. Testes utilizando o PCA e a principal delas, através da agregação dos pixels utilizando a média."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oebIVey37NRI"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "class ImageMerge:\n",
        "  def __init__(self, image_paths):\n",
        "    self.images = []\n",
        "    self.target_size = (1200, 1200)\n",
        "\n",
        "    for path in image_paths:\n",
        "      image = self.load_image(path)\n",
        "\n",
        "      if image is not None:\n",
        "        self.images.append(image)\n",
        "\n",
        "  def load_image(self, path):\n",
        "    image = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "    if image is None:\n",
        "      print(f\"Failed to load image: {path}\")\n",
        "      return None\n",
        "\n",
        "    if image.shape[:2] != self.target_size:\n",
        "      image = cv2.resize(image, self.target_size[::-1])\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "  def merge_images(self):\n",
        "    if not self.images:\n",
        "      raise ValueError(\"Nenhuma imagem foi carregada no pipeline.\")\n",
        "\n",
        "    # Cada pixel na imagem resultante é a média dos pixels correspondentes de todas as imagens.\n",
        "    merged_image = np.mean(self.images, axis=0, dtype=np.float32)\n",
        "    \n",
        "    # normalizando para valores de 0 a 255\n",
        "    merged_image = cv2.normalize(merged_image, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
        "\n",
        "    return merged_image\n",
        "\n",
        "  def merge_images_pca(self, n_components=3):\n",
        "    if not self.images:\n",
        "      raise ValueError(\"Nenhuma imagem foi carregada no pipeline.\")\n",
        "\n",
        "    # Empilhar todas as imagens em uma matriz 2D (pixels x bandas)\n",
        "    data = np.stack([img.ravel() for img in self.images], axis=-1)\n",
        "\n",
        "    pca = PCA(n_components=n_components)\n",
        "    principal_components = pca.fit_transform(data)\n",
        "\n",
        "    merged_image = principal_components.reshape(self.images[0].shape[:2] + (n_components,))\n",
        "    merged_image = cv2.normalize(merged_image, None, 0, 255, norm_type=cv2.NORM_MINMAX).astype(np.uint8)\n",
        "\n",
        "    return merged_image\n",
        "\n",
        "  # O método abaixo permite visualizar a imagem com a resulução de seu tamanho\n",
        "  def view_image(self, image):\n",
        "    dpi = 100  \n",
        "    height, width = image.shape[:2]\n",
        "    figsize = width / float(dpi), height / float(dpi)  \n",
        "\n",
        "    plt.figure(figsize=figsize, dpi=dpi)  \n",
        "\n",
        "    if image.ndim == 2 or image.shape[2] == 1:\n",
        "      plt.imshow(image, cmap='gray')  \n",
        "\n",
        "    else:\n",
        "      plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArzdrOVd9XIa",
        "outputId": "2b202c34-4339-4d8e-d8c2-06259214dd1c"
      },
      "outputs": [],
      "source": [
        "image_paths = ['../../data/dataset_inteli_test/images/595_2019-8-14_S2L1C_21JYJ/b11.tif', '../../data/dataset_inteli_test/images/595_2019-8-14_S2L1C_21JYJ/b12.tif', '../../data/dataset_inteli_test/images/595_2019-8-14_S2L1C_21JYJ/b2.tif', '../../data/dataset_inteli_test/images/595_2019-8-14_S2L1C_21JYJ/b3.tif', '../../data/dataset_inteli_test/images/595_2019-8-14_S2L1C_21JYJ/b4.tif', '../../data/dataset_inteli_test/images/595_2019-8-14_S2L1C_21JYJ/b5.tif', '../../data/dataset_inteli_test/images/595_2019-8-14_S2L1C_21JYJ/b6.tif', '../../data/dataset_inteli_test/images/595_2019-8-14_S2L1C_21JYJ/b7.tif', '../../data/dataset_inteli_test/images/595_2019-8-14_S2L1C_21JYJ/b8.tif', '../../data/dataset_inteli_test/images/595_2019-8-14_S2L1C_21JYJ/b8a.tif' ]\n",
        "\n",
        "pipe = ImageMerge(image_paths)\n",
        "# int(pipe.images[1])\n",
        "np.max(pipe.images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 961
        },
        "id": "DUSMN4VXB29c",
        "outputId": "a119d8d0-29cd-4b40-c2a1-cd045b9a7919"
      },
      "outputs": [],
      "source": [
        "# Usando média como mescla\n",
        "merged_image_mean = pipe.merge_images()\n",
        "pipe.view_image(merged_image_mean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 961
        },
        "id": "TYdTI4wY5eGz",
        "outputId": "7f33e797-e7b3-4ab7-e926-151b098f6b59"
      },
      "outputs": [],
      "source": [
        "# Uma visualização rudimentar utilizando PCA\n",
        "merged_image_pca = pipe.merge_images_pca()\n",
        "pipe.view_image(merged_image_pca)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Analisando imagem crua através do CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
        "\n",
        "O método de equalização de histograma é usado em processamento de imagens para melhorar o contraste. Ele redistribui os níveis de intensidade dos pixels em uma imagem, resultando em uma distribuição de intensidades mais uniforme. Isso pode ajudar a melhorar a qualidade visual das imagens, destacando detalhes que estavam anteriormente ocultos devido a baixo contraste.\n",
        "\n",
        "[Referência](https://docs.opencv.org/4.x/d5/daf/tutorial_py_histogram_equalization.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4xudcupUrER"
      },
      "outputs": [],
      "source": [
        "hist, bins = np.histogram(merged_image_mean.flatten(),256,[0,256])\n",
        " \n",
        "cdf = hist.cumsum()\n",
        "cdf_normalized = cdf * float(hist.max()) / cdf.max()\n",
        " \n",
        "plt.plot(cdf_normalized, color = 'b')\n",
        "plt.hist(merged_image_mean.flatten(),256,[0,256], color = 'r')\n",
        "\n",
        "plt.xlim([0,256])\n",
        "plt.legend(('cdf','histogram'), loc = 'upper left')\n",
        "plt.show(), plt.imshow(merged_image_mean, cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create a CLAHE object (Arguments are optional).\n",
        "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "cl1 = clahe.apply(merged_image_mean) \n",
        "\n",
        "plt.imshow(cl1, cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.imshow(merged_image_mean, cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculando o histograma para a imagem \"equalizada\"\n",
        "hist, bins = np.histogram(cl1.flatten(),256,[0,256])\n",
        "\n",
        "cdf = hist.cumsum()\n",
        "cdf_normalized = cdf * hist.max() / cdf.max()\n",
        "\n",
        "plt.plot(cdf_normalized, color = 'b')\n",
        "plt.hist(cl1.flatten(),256,[0,256], color = 'r')\n",
        "\n",
        "plt.xlim([0,256])\n",
        "plt.legend(('cdf','histogram'), loc = 'upper left')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjxyzFU3PYqM"
      },
      "source": [
        "## Pipeline de processamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class ImageProcessingPipeline:\n",
        "    def __init__(self, images):\n",
        "        self.images = images  \n",
        "\n",
        "    def normalize_image(image):\n",
        "        return image / 255.0\n",
        "\n",
        "    def resize_image(image, target_size=(1200, 1200)):\n",
        "        return cv2.resize(image, target_size)\n",
        "\n",
        "    def apply_clahe(self, image):\n",
        "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "        return clahe.apply(image.astype(np.uint8))\n",
        "\n",
        "    def crop_image(image, crop_size=(200, 200)):\n",
        "        crops = []\n",
        "        for i in range(0, image.shape[0], crop_size[0]):\n",
        "            for j in range(0, image.shape[1], crop_size[1]):\n",
        "                crop = image[i:i+crop_size[0], j:j+crop_size[1]]\n",
        "                if crop.shape[0] == crop_size[0] and crop.shape[1] == crop_size[1]:\n",
        "                    crops.append(crop)\n",
        "        return crops\n",
        "\n",
        "    def augment_images(self, image):\n",
        "        aug_images = []\n",
        "        for angle in [0, 90, 180, 270]:\n",
        "            rotated = self.rotate_image(image, angle)\n",
        "            aug_images.append(rotated)\n",
        "            aug_images.append(cv2.flip(rotated, 1))\n",
        "        return aug_images\n",
        "\n",
        "    def rotate_image(image, angle):\n",
        "        (h, w) = image.shape[:2]\n",
        "        center = (w // 2, h // 2)\n",
        "        M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
        "        return cv2.warpAffine(image, M, (w, h))\n",
        "\n",
        "    def process_images(self):\n",
        "        processed_images = []\n",
        "        for img in self.images:\n",
        "            clahe_img = self.apply_clahe(img)\n",
        "            norm_img = ImageProcessingPipeline.normalize_image(clahe_img)\n",
        "            resized_img = ImageProcessingPipeline.resize_image(norm_img)\n",
        "            cropped_images = self.crop_image(resized_img)\n",
        "            for crop in cropped_images:\n",
        "                augmented_imgs = self.augment_images(crop)\n",
        "                processed_images.extend(augmented_imgs)\n",
        "        return processed_images\n",
        "\n",
        "    def show_image(self, image):\n",
        "        plt.imshow(image, cmap='gray')\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "pipeline = ImageProcessingPipeline([merged_image_mean])\n",
        "processed_images = pipeline.process_images()\n",
        "\n",
        "# Mostrar algumas das imagens processadas\n",
        "for img in processed_images[:8]:  # Mostra as primeiras 8 imagens processadas\n",
        "    pipeline.show_image(img)\n",
        "\n",
        "len(processed_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Testes Unitários\n",
        "\n",
        "Os testes unitários são cruciais para garantir a qualidade do código, identificando bugs e garantindo que cada unidade funcione conforme o esperado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mesclagem de imagens\n",
        "Abaixo estamos testando se as funções responsáveis por trazer visibilidade a imagem estão funcionando corretamente. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Load Image**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "O teste abaixo visa verificar se a função load_image está funcionando corretamente.\n",
        "\n",
        "Como input, temos uma série de imagens .tif que pode ser encontradas na pasta images.\n",
        "\n",
        "O resultado esperado é um array de imagens em tons de cinza com dimensões (1200, 1200).\n",
        "\"\"\"\n",
        "\n",
        "image_path = '../../data/dataset_inteli_test/images/595_2019-8-14_S2L1C_21JYJ/b11.tif'\n",
        "pipe = ImageMerge([image_path])\n",
        "pipe.images # A função load_image é carregada na inicialização da classe ImageMerge\n",
        "\n",
        "# Visualizando a imagem e comparando com a imagem original \n",
        "print(\"Imagem GERADA:\")\n",
        "plt.imshow(pipe.images[0], cmap='gray')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_original = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
        "print(\"Imagem ORIGINAL:\")\n",
        "plt.imshow(image_original, cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A imagem foi gerada com tamanho maior do que a original, pois, foi passado justamente o valor de 1200 pixels como target size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Merge Images**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "O teste abaixo visa verificar se a função merge_images está funcionando corretamente.\n",
        "\n",
        "O input, neste caso, é uma lista de imagens em tons de cinza com dimensões (1200, 1200).\n",
        "\n",
        "O objetivo é retornar uma única matriz, normalizada entre 0 a 255, que possui a média das imagens\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# Para visualizar a média iremos replicar a pipeline com mais imagens:\n",
        "image_path = ['../../data/dataset_inteli_test/images/595_2019-8-14_S2L1C_21JYJ/b11.tif', '../../data/dataset_inteli_test/images/595_2019-8-14_S2L1C_21JYJ/b12.tif', '../../data/dataset_inteli_test/images/595_2019-8-14_S2L1C_21JYJ/b2.tif', '../../data/dataset_inteli_test/images/595_2019-8-14_S2L1C_21JYJ/b3.tif', '../../data/dataset_inteli_test/images/595_2019-8-14_S2L1C_21JYJ/b4.tif', '../../data/dataset_inteli_test/images/595_2019-8-14_S2L1C_21JYJ/b5.tif', '../../data/dataset_inteli_test/images/595_2019-8-14_S2L1C_21JYJ/b6.tif', '../../data/dataset_inteli_test/images/595_2019-8-14_S2L1C_21JYJ/b7.tif', '../../data/dataset_inteli_test/images/595_2019-8-14_S2L1C_21JYJ/b8.tif', '../../data/dataset_inteli_test/images/595_2019-8-14_S2L1C_21JYJ/b8a.tif' ]\n",
        "pipe = ImageMerge(image_path)\n",
        "\n",
        "# Aplicando o algoritmo desejado para mesclar as imagens\n",
        "images = pipe.images\n",
        "expected_merge_image = np.mean(images, axis=0, dtype=np.float32)\n",
        "expected_merge_image = cv2.normalize(expected_merge_image, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
        "\n",
        "# Aplicando algoritmo da classe ImageMerge\n",
        "merge_image = pipe.merge_images()\n",
        "\n",
        "# Verificando se a imagem gerada é igual a esperada\n",
        "np.testing.assert_array_equal(merge_image, expected_merge_image)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Merge Images With PCA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "O teste abaixo visa verificar se a função merge_images_pca está funcionando corretamente.\n",
        "\n",
        "O input, neste caso, é uma lista de imagens em tons de cinza com dimensões (1200, 1200).\n",
        "\n",
        "O resultado esperado de merge_images_pca é uma representação condensada das imagens originais\n",
        "que destaca suas características mais informativas ou variáveis, estruturada de forma que possa \n",
        "ser visualizada como uma imagem multi-canal.\n",
        "\"\"\"\n",
        "\n",
        "# Aplicando algoritmo da classe ImageProcessingPipeline\n",
        "image_path = ['../../data/dataset_inteli_test/images/595_2019-8-14_S2L1C_21JYJ/b11.tif', '../../data/dataset_inteli_test/images/595_2019-8-14_S2L1C_21JYJ/b12.tif', '../../data/dataset_inteli_test/images/595_2019-8-14_S2L1C_21JYJ/b2.tif', '../../data/dataset_inteli_test/images/595_2019-8-14_S2L1C_21JYJ/b3.tif', '../../data/dataset_inteli_test/images/595_2019-8-14_S2L1C_21JYJ/b4.tif', '../../data/dataset_inteli_test/images/595_2019-8-14_S2L1C_21JYJ/b5.tif', '../../data/dataset_inteli_test/images/595_2019-8-14_S2L1C_21JYJ/b6.tif', '../../data/dataset_inteli_test/images/595_2019-8-14_S2L1C_21JYJ/b7.tif', '../../data/dataset_inteli_test/images/595_2019-8-14_S2L1C_21JYJ/b8.tif', '../../data/dataset_inteli_test/images/595_2019-8-14_S2L1C_21JYJ/b8a.tif' ]\n",
        "pipe = ImageMerge(image_path)\n",
        "\n",
        "merged_image_pca = pipe.merge_images_pca(3)\n",
        "\n",
        "# Para testar, vamos apenas imprimir as dimensões e tipo para simplificar\n",
        "print(merged_image_pca.shape, merged_image_pca.dtype)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.imshow(merged_image_pca)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**View Image**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "O teste abaixo visa verificar se a função view_image está funcionando corretamente.\n",
        "\n",
        "O input, neste caso, é uma imagem, como uma matriz. \n",
        "\n",
        "O objetivo é poder visualizar a imagem, em tons de cinza, quando trata-se de uma matriz 2d ou quando o terceiro dimensionamento tem tamanho 1. E colorido, caso contrário.\n",
        "\"\"\"\n",
        "\n",
        "# Testando para uma imagem em tons de cinza\n",
        "pipe.view_image(merged_image_mean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizando uma imagem colorida\n",
        "pipe.view_image(merged_image_pca)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pipeline de processamento\n",
        "\n",
        "Abaixo estamos testando se as funções responsáveis por realizar normalizações e manipulações na imagem estão funcionando corretamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Normalize image**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\" \n",
        "O teste abaixo visa verificar se a função normalize_image está funcionando corretamente.\n",
        "\n",
        "O input, é uma imagem, como uma matriz.\n",
        "\n",
        "O objetivo é fazer com que os valores dos pixels da imagem estejam no intervalo [0, 1].\n",
        "\"\"\"\n",
        "image_before_normalization = cv2.imread('../../data/dataset_inteli_test/tci_pngs/595_2019-8-14_S2L1C_21JYJ_TCI.png', cv2.IMREAD_UNCHANGED)\n",
        "print(\"Imagem fora do intervalor: \", image_before_normalization)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_after_normalization = ImageProcessingPipeline.normalize_image(image_before_normalization)\n",
        "print(\"Imagem dentro do intervalo: \", image_after_normalization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Resize image**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "O teste abaixo visa verificar se a função resize_image está funcionando corretamente.\n",
        "\n",
        "O input, é uma imagem, como uma matriz. \n",
        "\n",
        "O output é uma imagem normalizada com dimensões (1200, 1200).\n",
        "\"\"\"\n",
        "\n",
        "image_before_resize = cv2.imread('../../data/dataset_inteli_test/images/595_2019-8-14_S2L1C_21JYJ/b11.tif', cv2.IMREAD_UNCHANGED)\n",
        "print(\"Tamanho da imagem, antes do processamento: \", image_before_resize.shape)\n",
        "\n",
        "image_after_resize = ImageProcessingPipeline.resize_image(image_before_resize)\n",
        "print(\"Tamanho da imagem, após o processamento: \", image_after_resize.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Apply Clahe**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "O teste abaixo visa verificar se a função apply_clahe está funcionando corretamente.\n",
        "\n",
        "O input, é uma imagem, como uma matriz.\n",
        "\n",
        "O output é uma imagem com contraste melhorado.\n",
        "\"\"\"\n",
        "image_path = ['../../data/dataset_inteli_test/images/595_2019-8-14_S2L1C_21JYJ/b11.tif', '../../data/dataset_inteli_test/images/595_2019-8-14_S2L1C_21JYJ/b12.tif', '../../data/dataset_inteli_test/images/595_2019-8-14_S2L1C_21JYJ/b2.tif', '../../data/dataset_inteli_test/images/595_2019-8-14_S2L1C_21JYJ/b3.tif', '../../data/dataset_inteli_test/images/595_2019-8-14_S2L1C_21JYJ/b4.tif', '../../data/dataset_inteli_test/images/595_2019-8-14_S2L1C_21JYJ/b5.tif', '../../data/dataset_inteli_test/images/595_2019-8-14_S2L1C_21JYJ/b6.tif', '../../data/dataset_inteli_test/images/595_2019-8-14_S2L1C_21JYJ/b7.tif', '../../data/dataset_inteli_test/images/595_2019-8-14_S2L1C_21JYJ/b8.tif', '../../data/dataset_inteli_test/images/595_2019-8-14_S2L1C_21JYJ/b8a.tif' ]\n",
        "image_before_clahe = ImageMerge(image_path).merge_images()\n",
        "print(\"Imagem antes do CLAHE: \")\n",
        "plt.imshow(image_before_clahe, cmap='gray')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "image_processing_pipe = ImageProcessingPipeline([image_before_clahe])\n",
        "image_after_clahe = image_processing_pipe.apply_clahe(image_before_clahe)\n",
        "print(\"Imagem após o CLAHE: \")\n",
        "plt.imshow(image_after_clahe, cmap='gray')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Crop Images**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "O teste abaixo visa verificar se a função crop_image está funcionando corretamente.\n",
        "\n",
        "O input, é uma imagem, como uma matriz.\n",
        "\n",
        "O output é uma lista de 36 imagens cortadas, com dimensões (200, 200).\n",
        "\"\"\"\n",
        "\n",
        "image_before_crop = cv2.imread('../../data/dataset_inteli_test/tci_pngs/595_2019-8-14_S2L1C_21JYJ_TCI.png', cv2.IMREAD_UNCHANGED)\n",
        "print(\"Tamanho da imagem, antes do processamento: \", image_before_crop.shape)\n",
        "\n",
        "crops = ImageProcessingPipeline.crop_image(image_before_crop)\n",
        "print(\"Número de imagens cortadas: \", len(crops))\n",
        "print(\"Tamanho das imagens cortadas: \", crops[0].shape)\n",
        "\n",
        "for crop in crops:\n",
        "\t\tplt.imshow(crop, cmap='gray')\n",
        "\t\tplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Rotate images**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "O teste abaixo visa verificar se a função rotate_image está funcionando corretamente.\n",
        "\n",
        "O input, é uma imagem, como uma matriz.\n",
        "\n",
        "O output é uma imagem rotacionada, para este teste, em 90 graus.\n",
        "\"\"\"\n",
        "\n",
        "image_before_rotate = cv2.imread('../../data/dataset_inteli_test/tci_pngs/595_2019-8-14_S2L1C_21JYJ_TCI.png', cv2.IMREAD_UNCHANGED)\n",
        "plt.imshow(image_before_rotate, cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_after_rotate = ImageProcessingPipeline.rotate_image(image_before_rotate, 90)\n",
        "plt.imshow(image_after_rotate, cmap='gray')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Augment images**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "O teste abaixo visa verificar se a função augment_images está funcionando corretamente.\n",
        "\n",
        "O input, é uma imagem, como uma matriz.\n",
        "\n",
        "O output é uma lista de 8 imagens, sendo 4 rotacionadas em 90, 180, 270 graus e 4 espelhadas.\n",
        "\"\"\"\n",
        "\n",
        "image_before_augment = cv2.imread('../../data/dataset_inteli_test/tci_pngs/595_2019-8-14_S2L1C_21JYJ_TCI.png', cv2.IMREAD_UNCHANGED)\n",
        "plt.imshow(image_before_augment, cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_processing_pipe = ImageProcessingPipeline([image_before_augment])\n",
        "augmented_images = image_processing_pipe.augment_images(image_before_augment)\n",
        "print(\"Número de imagens aumentadas: \", len(augmented_images))\n",
        "\n",
        "for img in augmented_images:\n",
        "\t\tplt.imshow(img, cmap='gray')\n",
        "\t\tplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Process images**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "O teste abaixo visa verificar se a função process_images está funcionando corretamente.\n",
        "\n",
        "O input, é uma lista de imagens, como matrizes.\n",
        "\n",
        "O output é uma lista de imagens processadas, normalizadas, redimensionadas, cortadas, aumentadas e com contraste melhorado.\n",
        "\"\"\"\n",
        "\n",
        "image_processing_pipe = ImageProcessingPipeline([merged_image_mean])\n",
        "process_images = image_processing_pipe.process_images() \n",
        "\n",
        "# É esperado um conunto de imagens de 288: \n",
        "# 1 imagem -> Após ser recortada -> 36 imagens\n",
        "# 36 imagens -> Após ser rotacionado 4x -> 144 \n",
        "# 144 -> Após ser refletida horizontalmente -> 288\n",
        "print(\"Número de imagens processadas: \", len(process_images)) \n",
        "\n",
        "for img in process_images[:8]:  # Mostra as primeiras 8 imagens processadas\n",
        "    image_processing_pipe.show_image(img)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Show image**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "O teste abaixo visa verificar se a função show_image está funcionando corretamente.\n",
        "\n",
        "O input, é uma imagem, como uma matriz.\n",
        "\n",
        "O objetivo é poder visualizar a imagem.\n",
        "\"\"\"\n",
        "\n",
        "image = cv2.imread('../../data/dataset_inteli_test/tci_pngs/595_2019-8-14_S2L1C_21JYJ_TCI.png', cv2.IMREAD_UNCHANGED)\n",
        "image_processing_pipe = ImageProcessingPipeline([image])\n",
        "image_processing_pipe.show_image(image)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
