{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Data augmentation \n","\n","Este é um dos notebooks contidos na pasta [DATA AUGMENTATION](../DATA%20AUGMENTATION/). A fim de contemplarmos todos os testes e alterações, implementamos mais dois notebooks que possuem, além do Data Augmentation, os Pré-Processamentos de imagens criados nas duas sprints anteriores.\n","\n","Portanto, este é o notebook que tem e documenta as diversas manipulações de imagens, a partir das imagens encontradas em [tci_tifs](../../../../data/SPRINT%201/dataset_inteli/tci_tifs/) e [masks](../../../../data/SPRINT%201/dataset_inteli/masks/). Você pode encontrar os notebooks que contemplam o processo de Data Augmentation aplicado ao pré processamento de imagens nos outros colabs abaixo:\n","\n","- [Implementação de Data Augmentation no processamento de imagens tif]().\n","- [Implementação de Data Augmentation no processamento de imagens usando KMeans e Sharpen]()\n","\n","O artigo \"Automatic Rural Road Centerline Detection and Extraction from Aerial Images for a Forest Fire Decision Support System\" utilizou técnicas de data augmentation para aumentar o conjunto de dados inicial, que consistia em 486 imagens ortorretificadas. Para ampliar o tamanho do dataset e melhorar o treinamento do modelo, os seguintes métodos de data augmentation foram aplicados:\n","\n","1. **Rotação:** As imagens foram rotacionadas em noventa graus quatro vezes.\n","2. **Espelhamento:** A operação de espelhamento foi realizada.\n","\n","Além disso, implementamos o método de recorte (crop), onde a partir de imagens de 600x600, fazemos recortes de quadrantes de 200x200, inspirado no artigo \"Image Preprocessing for Computer Vision Tasks in Python Using OpenCV and Tensorflow\".\n","\n","Essas táticas foram cruciais para aumentar significativamente o tamanho do conjunto de dados e aprimorar o processo de treinamento do modelo, como descrito nos estudos.\n","\n","_Referências:_\n","AUTOMATIC Rural Road Centerline Detection and Extraction from Aerial Images for a Forest Fire Decision Support System. Remotesensing, 2024. Disponível em: <https://www.mdpi.com/2072-4292/15/1/271>. Acesso em: 24 maio 2024.\n","\n","BTD. Image Preprocessing for Computer Vision Tasks in Python Using OpenCV and Tensorflow. Medium, 2023. Disponível em: <https://medium.com/plans?source=upgrade_membership---post_counter--be5ddbeb6c09>. Acesso em: 24 maio 2024."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9827,"status":"ok","timestamp":1716066190218,"user":{"displayName":"Grupo 02","userId":"16973374906107079213"},"user_tz":180},"id":"RJ_-GF3XE9Vj","outputId":"e99a83cf-9c13-4e61-d6e4-4fc547109784"},"outputs":[],"source":["import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from google.colab import drive\n","import os\n","from PIL import Image\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Função auxiliar para criação de diretórios através de um caminho\n","def create_dirs(path):\n","    if not os.path.exists(path):\n","        os.makedirs(path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":27942,"status":"ok","timestamp":1716066316210,"user":{"displayName":"Grupo 02","userId":"16973374906107079213"},"user_tz":180},"id":"N5Y20_9xPI_E","outputId":"5a802778-bea8-4ba6-84fb-ca7de456ffb0"},"outputs":[],"source":["# Carregar máscaras correspondentes para as imagens mescladas e redimensionar para 600x600\n","def load_masks(masks_dir, target_size=(600, 600)):\n","    masks = []\n","    ordered_masks = sorted(os.listdir(masks_dir))\n","    mask_filenames = []\n","\n","    for mask_name in ordered_masks:\n","        mask_path = os.path.join(masks_dir, mask_name)\n","        mask = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)\n","    \n","        if mask is not None:\n","\n","            if mask.shape[:2] != target_size:\n","                mask = cv2.resize(mask, target_size[::-1])\n","            \n","            masks.append(mask)\n","            mask_filenames.append(os.path.splitext(mask_name)[0])\n","    \n","        else:\n","            print(f\"Falha ao carregar máscara: {mask_path}\")\n","    \n","    return masks, mask_filenames\n","\n","# Função para carregar imagens\n","def load_images(image_dir, target_size=(600, 600)):\n","    images = []\n","    ordered_images = sorted(os.listdir(image_dir))\n","    image_filenames = []\n","    for image_name in ordered_images:\n","        image_path = os.path.join(image_dir, image_name)\n","        image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n","        if image is not None:\n","            if image.shape[:2] != target_size:\n","                image = cv2.resize(image, target_size[::-1])\n","            images.append(image)\n","            image_filenames.append(os.path.splitext(image_name)[0])\n","        else:\n","            print(f\"Falha ao carregar imagem: {image_path}\")\n","    return images, image_filenames\n","\n","# Caminhos\n","masks_dir = '/content/drive/Shared drives/Grupo T de Tech/Data/dataset_inteli/masks'\n","image_dir = '/content/drive/Shared drives/Grupo T de Tech/Data/dataset_inteli/tci_tifs'\n","\n","# Carregar imagens e máscaras\n","masks, mask_filenames = load_masks(masks_dir)\n","images, image_filenames = load_images(image_dir)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# Garantir que as máscaras e as imagens estejam na mesma ordem\n","assert mask_filenames == image_filenames, \"A ordem das máscaras e imagens não corresponde!\"\n","\n","class ImageProcessingPipeline:\n","\tdef __init__(self, images, masks):\n","\t\tself.images = images\n","\t\tself.masks = masks\n","\n","\tdef crop_image(self, image, crop_size=(200, 200)):\n","\t\tcrops = []\n","\n","\t\tfor i in range(0, image.shape[0], crop_size[0]):\n","\t\t\tfor j in range(0, image.shape[1], crop_size[1]):\n","\t\t\t\tcrop = image[i:i+crop_size[0], j:j+crop_size[1]]\n","\t\t\t\tif crop.shape[0] == crop_size[0] and crop.shape[1] == crop_size[1]:\n","\t\t\t\t\tcrops.append(crop)\n","\n","\t\treturn crops\n","\n","\tdef augment_images(self, image):\n","\t\taug_images = []\n","\t\tfor angle in [0, 90, 180, 270]:\n","\t\t\trotated = self.rotate_image(image, angle)\n","\t\t\taug_images.append(rotated)\n","\t\t\taug_images.append(cv2.flip(rotated, 1))\n","\n","\t\treturn aug_images\n","\n","\t@staticmethod\n","\tdef rotate_image(image, angle):\n","\t\t(h, w) = image.shape[:2]\n","\t\tcenter = (w // 2, h // 2)\n","\t\tM = cv2.getRotationMatrix2D(center, angle, 1.0)\n","\t\treturn cv2.warpAffine(image, M, (w, h))\n","\n","\tdef process_and_save_images_and_masks(self, output_dir):\n","\t\tcreate_dirs(output_dir)\n","\t\tcount = 0\n","\t\t\n","\t\tfor img, mask in zip(self.images, self.masks):\n","\t\t\tcropped_images = self.crop_image(img)\n","\t\t\tcropped_masks = self.crop_image(mask)\n","\n","\t\t\tfor crop_img, crop_mask in zip(cropped_images, cropped_masks):\n","\t\t\t\taugmented_imgs = self.augment_images(crop_img)\n","\t\t\t\taugmented_masks = self.augment_images(crop_mask)\n","\t\t\n","\t\t\t\tfor aug_img, aug_mask in zip(augmented_imgs, augmented_masks):\n","\t\t\t\t\taug_img = Image.fromarray((aug_img * 255).astype(np.uint8))  # Converter de volta para uint8\n","\t\t\t\t\taug_mask = Image.fromarray(aug_mask)\n","\t\t\t\t\t\n","\t\t\t\t\taug_img.save(os.path.join(output_dir, f'processed_image_{count}.tif'))\n","\t\t\t\t\taug_mask.save(os.path.join(output_dir, f'processed_mask_{count}.png'))\n","\t\t\n","\t\t\t\t\tcount += 1\n","\n","\tdef show_image(self, image):\n","\t\tplt.imshow(image, cmap='gray')\n","\t\tplt.axis('off')\n","\t\tplt.show()\n","\n","# Processar e aumentar imagens e máscaras\n","output_dir = '/content/drive/Shared drives/Grupo T de Tech/Data/datasets_sprint3/dataset_inteli_processed'\n","pipeline = ImageProcessingPipeline(images, masks)\n","pipeline.process_and_save_images_and_masks(output_dir)\n","\n","# Mostrar algumas das imagens processadas\n","for img in images[:8]:  # Mostra as primeiras 8 imagens processadas\n","\tpipeline.show_image(img)"]},{"cell_type":"markdown","metadata":{},"source":["Caso haja necessidade de executar o código, devido ao peso dos datasets optamos por mante-los no google drive, contudo podem ser acessados através dos links abaixo:\n","\n","- [Conjunto de imagens geradas através de data augmentation](https://drive.google.com/drive/folders/1nblgJuT7ZmEZmh6qrF_cbdllCeZQswHM?usp=sharing)"]}],"metadata":{"colab":{"provenance":[{"file_id":"1CBMKgOCDlvOBgcef3L4fxBOckC99cPMK","timestamp":1715997823434}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":0}
