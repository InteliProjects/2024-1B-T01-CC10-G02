{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Data augmentation \n","\n","A seguir, estamos combinando o código gerado nas sprints anteriores com o processo de tratamento e pré processamento de imagens através da algoritmos,  dos pixels e com o processo de Data Augmentation, que foi atualizado desde a sprint 1. Removemos alguns filtros e implementamos códigos necessários para garantir que o conjunto de imagens seja eficaz.\n","\n","- [Pré Processamento de imagens utilizando Kmeans e Sharpen - SPRINT 1](../../SPRINT%201/20240425%20-%20Implementacao%20KMeans%20para%20Reducao%20de%20Cor.ipynb)\n","- [Data Augmentation SPRINT 3](../../SPRINT%203/DATA%20AUGMENTATION/20240524%20-%20Data%20Augmentation.ipynb)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":50176,"status":"ok","timestamp":1716461542388,"user":{"displayName":"Grupo 02","userId":"16973374906107079213"},"user_tz":180},"id":"RYiAf2kBJjDC","outputId":"74e83005-8a22-4f69-a9e4-d70f39c6a9e8"},"outputs":[],"source":["import cv2\n","import numpy as np\n","import os\n","import matplotlib.pyplot as plt\n","from sklearn.cluster import KMeans\n","import tqdm\n","from google.colab import drive\n","from PIL import Image\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":295,"status":"ok","timestamp":1716461590690,"user":{"displayName":"Grupo 02","userId":"16973374906107079213"},"user_tz":180},"id":"9r9HuYsIXWiP"},"outputs":[],"source":["\n","# Função auxiliar para criação de diretórios através de um caminho\n","def create_dirs(path):\n","    if not os.path.exists(path):\n","        os.makedirs(path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RJ_-GF3XE9Vj"},"outputs":[],"source":["\n","\n","class KMeansImageProcessingPipeline:\n","    def __init__(self, root_dir, output_dir, k=3, attempts=10):\n","        self.root_dir = root_dir\n","        self.output_dir = output_dir\n","        self.k = k\n","        self.attempts = attempts\n","        self.target_size = (600, 600)\n","\n","    def read_and_process_image(self, path):\n","        img = cv2.imread(path)\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        if img.shape[:2] != self.target_size:\n","            img = cv2.resize(img, self.target_size[::-1])\n","        return img\n","\n","    def kmeans_image(self, img):\n","        # Redimensionar a imagem para um vetor 1D\n","        vectorized_img = img.reshape((-1, 3))\n","        vectorized_img = np.float32(vectorized_img)\n","\n","        # Definir critérios para o algoritmo K-means\n","        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n","\n","        # Executar o algoritmo K-means\n","        _, label, center = cv2.kmeans(vectorized_img, self.k, None, criteria, self.attempts, cv2.KMEANS_PP_CENTERS)\n","        center = np.uint8(center)\n","\n","        # Recriar a imagem a partir dos clusters encontrados\n","        res = center[label.flatten()]\n","        result_image = res.reshape((img.shape))\n","\n","        return result_image\n","\n","    def sharpen_image(self, img):\n","        # Cria um kernel para afiar a imagem\n","        kernel = np.array([[-1, -1, -1],\n","                           [-1, 9, -1],\n","                           [-1, -1, -1]])\n","\n","        # Aplica o kernel na imagem usando filter2D\n","        sharpened_image = cv2.filter2D(img, -1, kernel)\n","\n","        return sharpened_image\n","\n","    def process_directory(self):\n","        create_dirs(self.output_dir)\n","        processed_images = []\n","        for subdir, _, files in os.walk(self.root_dir):\n","            tif_files = sorted([os.path.join(subdir, file) for file in files if file.endswith('_TCI.tif')])\n","            if tif_files:\n","                images = [(file, self.read_and_process_image(file)) for file in tif_files if self.read_and_process_image(file) is not None]\n","                if images:\n","                    for file, image in images:\n","                        kmeans_img = self.kmeans_image(image)\n","                        sharpened_img = self.sharpen_image(kmeans_img)\n","                        # Extrai o primeiro número antes do _ do nome do arquivo original\n","                        image_name = os.path.basename(file).split('_')[0]\n","                        # Converte para PIL e salva no diretório de saída\n","                        pil_img = Image.fromarray((sharpened_img).astype(np.uint8))\n","                        pil_img.save(os.path.join(self.output_dir, f\"{image_name}.png\"))\n","                        processed_images.append(sharpened_img)\n","        return processed_images\n","\n","# Paths\n","root_dir = '/content/drive/Shared drives/Grupo T de Tech/Data/dataset_inteli/tci_tifs'\n","output_dir = '/content/drive/Shared drives/Grupo T de Tech/Data/dataset_inteli/kmeans_processed_images'\n","\n","# Process images and save them\n","pipeline = KMeansImageProcessingPipeline(root_dir, output_dir)\n","processed_images = pipeline.process_directory()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":435},"executionInfo":{"elapsed":1128,"status":"ok","timestamp":1716405873434,"user":{"displayName":"Grupo 02","userId":"16973374906107079213"},"user_tz":180},"id":"u6wOikFTYQmb","outputId":"675406a6-a150-4778-e083-2aebc957212a"},"outputs":[],"source":["plt.imshow(processed_images[13])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1401,"status":"ok","timestamp":1716463406560,"user":{"displayName":"Grupo 02","userId":"16973374906107079213"},"user_tz":180},"id":"z075E_JsJlPZ"},"outputs":[],"source":["import os\n","import cv2\n","\n","# Function to load masks\n","def load_masks(masks_dir, target_size=(600, 600)):\n","    masks = []\n","    ordered_masks = sorted(os.listdir(masks_dir))\n","    mask_filenames = []\n","    for mask_name in ordered_masks:\n","        mask_path = os.path.join(masks_dir, mask_name)\n","        mask = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)\n","        if mask is not None:\n","            if mask.shape[:2] != target_size:\n","                mask = cv2.resize(mask, target_size[::-1])\n","            masks.append(mask)\n","            mask_filenames.append(os.path.splitext(mask_name)[0])\n","        else:\n","            print(f\"Failed to load mask: {mask_path}\")\n","    return masks, mask_filenames\n","\n","# Function to load images\n","def load_images(image_dir, target_size=(600, 600)):\n","    images = []\n","    ordered_images = sorted(os.listdir(image_dir))\n","    image_filenames = []\n","    for image_name in ordered_images:\n","        image_path = os.path.join(image_dir, image_name)\n","        image = cv2.imread(image_path)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        if image is not None:\n","            if image.shape[:2] != target_size:\n","                image = cv2.resize(image, target_size[::-1])\n","            images.append(image)\n","            # Extract the first segment of the filename before the underscore\n","            image_filenames.append(os.path.splitext(image_name)[0].split('_')[0])\n","        else:\n","            print(f\"Failed to load image: {image_path}\")\n","    return images, image_filenames\n","\n","# Paths\n","masks_dir = '/content/drive/Shared drives/Grupo T de Tech/Data/dataset_inteli/masks'\n","image_dir = '/content/drive/Shared drives/Grupo T de Tech/Data/dataset_inteli/tci_tifs'\n","\n","# Load images and masks\n","masks, mask_filenames = load_masks(masks_dir)\n","images, image_filenames = load_images(image_dir)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":435},"executionInfo":{"elapsed":1048,"status":"ok","timestamp":1716464239381,"user":{"displayName":"Grupo 02","userId":"16973374906107079213"},"user_tz":180},"id":"RGWZ5oO2K_3m","outputId":"5c623597-13f2-43b5-a174-8ef2bae4a3de"},"outputs":[],"source":["# Visualizando iamgem\n","plt.imshow(images[3])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1lzzpw0svU7k-QJBofJcZPJ77C1o5vmF8"},"executionInfo":{"elapsed":31498,"status":"ok","timestamp":1716463472203,"user":{"displayName":"Grupo 02","userId":"16973374906107079213"},"user_tz":180},"id":"jLpj4vi7K8pG","outputId":"4210062f-3763-4b5b-e0a2-a9c086ab10cb"},"outputs":[],"source":["# Garante que as máscaras e imagens estão na mesma ordem\n","assert mask_filenames == image_filenames, \"A ordem das máscaras e imagens não coincide!\"\n","\n","class ImageProcessingPipeline:\n","    def __init__(self, images, masks):\n","        # Inicializa a classe com as imagens e máscaras\n","        self.images = images\n","        self.masks = masks\n","\n","    def crop_image(self, image, crop_size=(200, 200)):\n","        # Método para recortar uma imagem em pedaços menores\n","        crops = []\n","        for i in range(0, image.shape[0], crop_size[0]):\n","            for j in range(0, image.shape[1], crop_size[1]):\n","                crop = image[i:i+crop_size[0], j:j+crop_size[1]]\n","                if crop.shape[0] == crop_size[0] and crop.shape[1] == crop_size[1]:\n","                    crops.append(crop)\n","        return crops\n","\n","    def augment_images(self, image):\n","        # Método para aumentar as imagens (rotação e espelhamento)\n","        aug_images = []\n","        for angle in [0, 90, 180, 270]:\n","            rotated = self.rotate_image(image, angle)\n","            aug_images.append(rotated)\n","            aug_images.append(cv2.flip(rotated, 1))\n","        return aug_images\n","\n","    @staticmethod\n","    def rotate_image(image, angle):\n","        # Método para rotacionar uma imagem\n","        (h, w) = image.shape[:2]\n","        center = (w // 2, h // 2)\n","        M = cv2.getRotationMatrix2D(center, angle, 1.0)\n","        return cv2.warpAffine(image, M, (w, h))\n","\n","    def process_and_save_images_and_masks(self, output_dir):\n","        # Processa e salva as imagens e máscaras em um diretório de saída\n","        create_dirs(output_dir)\n","        count = 0\n","        for img, mask in zip(self.images, self.masks):\n","            cropped_images = self.crop_image(img)\n","            cropped_masks = self.crop_image(mask)\n","            for crop_img, crop_mask in zip(cropped_images, cropped_masks):\n","                augmented_imgs = self.augment_images(crop_img)\n","                augmented_masks = self.augment_images(crop_mask)\n","                for aug_img, aug_mask in zip(augmented_imgs, augmented_masks):\n","                    aug_img = Image.fromarray((aug_img * 255).astype(np.uint8))  # Converte de volta para uint8\n","                    aug_mask = Image.fromarray(aug_mask)\n","                    output_img_path = os.path.join(output_dir, f'processed_image_{count}.tif')\n","                    output_mask_path = os.path.join(output_dir, f'processed_mask_{count}.png')\n","                    print(f\"Salvando imagem processada em {output_img_path}\")\n","                    print(f\"Salvando máscara processada em {output_mask_path}\")\n","                    aug_img.save(output_img_path)\n","                    aug_mask.save(output_mask_path)\n","                    count += 1\n","\n","    def show_image(self, image):\n","        # Método para exibir uma imagem\n","        plt.imshow(image, cmap='gray')\n","        plt.axis('off')\n","        plt.show()\n","\n","# Processa e aumenta imagens e máscaras\n","output_dir = '/content/drive/Shared drives/Grupo T de Tech/Data/dataset_inteli/clean_dataset'\n","pipeline = ImageProcessingPipeline(images, masks)\n","pipeline.process_and_save_images_and_masks(output_dir)\n","\n","# Mostra algumas das imagens processadas\n","for img in images[:8]:  # Mostra as primeiras 8 imagens processadas\n","    pipeline.show_image(img)"]},{"cell_type":"markdown","metadata":{},"source":["Caso haja necessidade de executar o código, devido ao peso dos datasets optamos por mante-los no google drive, contudo podem ser acessados através dos links abaixo:\n","\n","- [Conjunto de imagens geradas através de préprocessamento com KMeans, Sharpen e data augmentation ](https://drive.google.com/drive/folders/18V4LmUwD1im1LuOFRuzKta6hUgAZr5AW?usp=sharing)"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1X7koZJ4PlphW9ilHFDCtckdAs7nuqVWv","timestamp":1716296348798},{"file_id":"1CBMKgOCDlvOBgcef3L4fxBOckC99cPMK","timestamp":1715997823434}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":0}
