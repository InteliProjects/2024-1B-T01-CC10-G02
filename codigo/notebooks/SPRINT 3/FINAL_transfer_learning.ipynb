{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQl90jW20q1D"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmrOiTQ83EJf"
      },
      "source": [
        "Instalar dependências"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M97Z2Z1BTDYl",
        "outputId": "d18c21d7-4109-4fb9-dc23-7b830863f43d"
      },
      "outputs": [],
      "source": [
        "!pip install pyxlsb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmPbAITj3HzC"
      },
      "source": [
        "Importar dependências"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehPwUJLzSsLC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import gc\n",
        "from glob import glob\n",
        "import zipfile\n",
        "\n",
        "import pandas as pd\n",
        "from pyxlsb import open_workbook\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import MobileNetV2, VGG16\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "from google.colab import drive\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyydjomK3KRS"
      },
      "source": [
        "(Colab) Conectar com o google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibpCXTgmS_Hi",
        "outputId": "6eaedea3-40fa-4dec-fef0-2c5d51a7ba4e"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hr5xrV1i30IH"
      },
      "source": [
        "Variáveis de ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V12qGhf9334u"
      },
      "outputs": [],
      "source": [
        "DATA_PATH = '/content/drive/Shared drives/Grupo T de Tech/Data/dataset_inteli/cropped_images/*/*'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xSP-0NwWdAq"
      },
      "source": [
        "# Pré-processamento de dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaOi6E-q4Cfk"
      },
      "source": [
        "## **Carregamento dos Caminhos de Imagem**\n",
        "\n",
        "Carregar os caminhos das imagens e máscaras.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yz6Rn0h26UVx",
        "outputId": "aa16b865-a3b8-4f71-880b-7c8db3b5d1d9"
      },
      "outputs": [],
      "source": [
        "images = []\n",
        "masks = []\n",
        "\n",
        "for path in glob(DATA_PATH):\n",
        "    images.append(path + '/image.tif')\n",
        "    masks.append(path + '/mask.png')\n",
        "\n",
        "print(\"Caminhos das máscaras carregados:\", masks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5z8Gq10W4hlz"
      },
      "source": [
        "## **Pré-processamento de Imagens**\n",
        "Carrega e pré-processa uma imagem e sua máscara correspondente.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgFIh5hrObFb"
      },
      "outputs": [],
      "source": [
        "def load_and_preprocess_image(image_path, mask_path, target_size=(256, 256)):\n",
        "    \"\"\"\n",
        "    Carrega e pré-processa uma imagem e sua máscara correspondente.\n",
        "    Parâmetros:\n",
        "        image_path (str): Caminho para a imagem.\n",
        "        mask_path (str): Caminho para a máscara.\n",
        "        target_size (tuple): Dimensões para redimensionamento das imagens.\n",
        "    Retorna:\n",
        "        tuple: Uma tupla contendo a imagem e a máscara processadas.\n",
        "    \"\"\"\n",
        "    # Carregamento e normalização da imagem\n",
        "    image = load_img(image_path, target_size=target_size)\n",
        "    image = img_to_array(image) / 255.0\n",
        "\n",
        "    # Carregamento e normalização da máscara\n",
        "    mask = load_img(mask_path, target_size=target_size, color_mode='grayscale')\n",
        "    mask = img_to_array(mask) / 255.0\n",
        "\n",
        "    return image, mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-FFUlqY5E19"
      },
      "source": [
        "## **Processamento em Lote e Preparação dos Dados**\n",
        "Divisão em lotes para facilitar o processamento\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Qu_4ZJaKOTGF",
        "outputId": "9975dd1c-0f48-4e80-98a4-05cde9daf63e"
      },
      "outputs": [],
      "source": [
        "images_processed = []\n",
        "masks_processed = []\n",
        "count = 1\n",
        "\n",
        "for img_path, mask_path in zip(images, masks):\n",
        "    print(f'Processando imagem {count}')\n",
        "    img, mask = load_and_preprocess_image(img_path, mask_path)\n",
        "    images_processed.append(img)\n",
        "    masks_processed.append(mask)\n",
        "    count += 1\n",
        "\n",
        "# Conversão para arrays numpy para facilitar o processamento no TensorFlow/Keras\n",
        "images_processed = np.array(images_processed)\n",
        "masks_processed = np.array(masks_processed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghwdgg8Y5fhS"
      },
      "source": [
        "## **Divisão dos Dados para Treinamento e Validação**\n",
        "\n",
        "Prepara os dados processados para utilização no modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZAd-OD15gU2"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    X_train, X_val, y_train, y_val = train_test_split(images_processed, masks_processed, test_size=0.2, random_state=42)\n",
        "except Exception as e:\n",
        "    print(f'Erro ao dividir os dados: {e}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dApijRqyWk_n"
      },
      "source": [
        "# Definição dos modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAwQpL9H6uYi"
      },
      "source": [
        "## **Definição do Modelo U-Net com Encoder MobileNetV2**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJk0H6D6T9F1"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def Unet_with_MobileNetV2_encoder(input_shape=(256, 256, 3)):\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_tensor=inputs)\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # Intermediate layers for skip connections\n",
        "    skip1 = base_model.get_layer('block_1_expand_relu').output\n",
        "    skip2 = base_model.get_layer('block_3_expand_relu').output\n",
        "    encoder_output = base_model.get_layer('block_6_expand_relu').output\n",
        "\n",
        "    # Decoder\n",
        "    up1 = layers.Conv2DTranspose(96, (2, 2), strides=(2, 2), padding='same')(encoder_output)\n",
        "    merge1 = layers.concatenate([skip2, up1], axis=3)\n",
        "    conv1 = layers.Conv2D(96, 3, activation='relu', padding='same')(merge1)\n",
        "    conv1 = layers.Conv2D(96, 3, activation='relu', padding='same')(conv1)\n",
        "\n",
        "    up2 = layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv1)\n",
        "    merge2 = layers.concatenate([skip1, up2], axis=3)\n",
        "    conv2 = layers.Conv2D(32, 3, activation='relu', padding='same')(merge2)\n",
        "    conv2 = layers.Conv2D(32, 3, activation='relu', padding='same')(conv2)\n",
        "\n",
        "    up3 = layers.Conv2DTranspose(24, (2, 2), strides=(2, 2), padding='same')(conv2)\n",
        "    conv3 = layers.Conv2D(24, 3, activation='relu', padding='same')(up3)\n",
        "    conv3 = layers.Conv2D(24, 3, activation='relu', padding='same')(conv3)\n",
        "\n",
        "    outputs = layers.Conv2D(1, 1, activation='sigmoid')(conv3)\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tuy08qHQ7GP4"
      },
      "source": [
        "## **Definição do Modelo SegNet com Encoder VGG16**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayELeIwA7MiD"
      },
      "outputs": [],
      "source": [
        "def SegNet_with_VGG_encoder(input_shape=(256, 256, 3)):\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "    vgg16 = VGG16(include_top=False, weights='imagenet', input_tensor=inputs)\n",
        "    vgg16.trainable = False\n",
        "\n",
        "    # Layer outputs for skip connections\n",
        "    s1 = vgg16.get_layer('block1_pool').output\n",
        "    s2 = vgg16.get_layer('block2_pool').output\n",
        "    s3 = vgg16.get_layer('block3_pool').output\n",
        "    s4 = vgg16.get_layer('block4_pool').output\n",
        "    encoded = vgg16.get_layer('block5_pool').output\n",
        "\n",
        "    # Decoder using Conv2DTranspose\n",
        "    up1 = layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(encoded)\n",
        "    up1 = layers.BatchNormalization()(up1)\n",
        "    up1 = layers.Activation('relu')(up1)\n",
        "    merge1 = layers.concatenate([s4, up1], axis=3)\n",
        "\n",
        "    up2 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(merge1)\n",
        "    up2 = layers.BatchNormalization()(up2)\n",
        "    up2 = layers.Activation('relu')(up2)\n",
        "    merge2 = layers.concatenate([s3, up2], axis=3)\n",
        "\n",
        "    up3 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(merge2)\n",
        "    up3 = layers.BatchNormalization()(up3)\n",
        "    up3 = layers.Activation('relu')(up3)\n",
        "    merge3 = layers.concatenate([s2, up3], axis=3)\n",
        "\n",
        "    up4 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(merge3)\n",
        "    up4 = layers.BatchNormalization()(up4)\n",
        "    up4 = layers.Activation('relu')(up4)\n",
        "    merge4 = layers.concatenate([s1, up4], axis=3)\n",
        "\n",
        "    up5 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(merge4)\n",
        "    up5 = layers.BatchNormalization()(up5)\n",
        "    up5 = layers.Activation('relu')(up5)\n",
        "\n",
        "    outputs = layers.Conv2D(1, 1, activation='sigmoid')(up5)\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_K8INbM9Wpi8"
      },
      "source": [
        "# Treino do modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJaZVZ8A8FN8"
      },
      "source": [
        "## **Função para Criação e Treinamento de Modelos**\n",
        "\n",
        "Cria, compila, treina um modelo de rede neural e avalia no conjunto de validação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "MTLb8OpzUHrj"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate_model(model_function, input_shape, X_train, y_train, X_val, y_val):\n",
        "    \"\"\"\n",
        "    Cria, compila, treina um modelo de rede neural e avalia no conjunto de validação.\n",
        "    Parâmetros:\n",
        "        model_function (function): Função que retorna um modelo compilado.\n",
        "        input_shape (tuple): Dimensões da entrada do modelo.\n",
        "        X_train, y_train: Dados de treinamento.\n",
        "        X_val, y_val: Dados de validação.\n",
        "    Retorna:\n",
        "        dict: Histórico de treinamento do modelo e resultados de avaliação.\n",
        "    \"\"\"\n",
        "\n",
        "    # Criar e compilar o modelo\n",
        "    print('Criando e compilando o modelo...')\n",
        "    model = model_function(input_shape)\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Treinar o modelo\n",
        "    print('Treinando o modelo...')\n",
        "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=200, batch_size=32)\n",
        "\n",
        "    # Prever máscaras usando o modelo\n",
        "    print('Prevendo máscaras...')\n",
        "    predicted_masks = model.predict(X_val)\n",
        "\n",
        "    # Limpar a memória\n",
        "    print('Processo finalizado. Resultados armazenados e limpando memória')\n",
        "    tf.keras.backend.clear_session()\n",
        "    del model\n",
        "    gc.collect()\n",
        "\n",
        "    # Retornar o histórico de treinamento e os resultados de avaliação\n",
        "    return history.history, predicted_masks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEJdHKRg8Wu1"
      },
      "source": [
        "## **Treinamento Sequencial de Múltiplos Modelos**\n",
        "\n",
        "Como estamos utilizando múltiplos modelos, iremos treiná-los sequencialmente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "p_bs-TnP8StC",
        "outputId": "adf6e80a-afa7-42fb-ec22-3dde3e193f3e"
      },
      "outputs": [],
      "source": [
        "# Definir os parâmetros de entrada\n",
        "input_shape = (256, 256, 3)\n",
        "\n",
        "# Treinar o modelo U-Net com MobileNetV2\n",
        "history_unet, predicted_masks_unet = train_and_evaluate_model(Unet_with_MobileNetV2_encoder, input_shape, X_train, y_train, X_val, y_val)\n",
        "\n",
        "# Treinar o modelo SegNet com VGG\n",
        "history_segnet, predicted_masks_segnet = train_and_evaluate_model(SegNet_with_VGG_encoder, input_shape, X_train, y_train, X_val, y_val)\n",
        "\n",
        "# Exibir ou salvar os históricos para análise\n",
        "print(\"Histórico de treinamento U-Net com MobileNetV2:\", history_unet)\n",
        "print(\"Histórico de treinamento SegNet com VGG:\", history_segnet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_XrQw1fWtkp"
      },
      "source": [
        "# Avaliação do modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7Ssi2X3_SbC"
      },
      "source": [
        "## Visualização das máscaras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "NYEs05v7_VGO",
        "outputId": "b329ce06-329d-4fe5-8455-d3c05825ea7a"
      },
      "outputs": [],
      "source": [
        "# Visualizar comparações\n",
        "for i in range(len(X_val)):\n",
        "    img_entrada = X_val[i]\n",
        "    img_saida_real = y_val[i]\n",
        "    img_saida_unet = np.where(predicted_masks_unet[i] < 0.5, 0, 1)\n",
        "    img_saida_segnet = np.where(predicted_masks_segnet[i] < 0.5, 0, 1)\n",
        "\n",
        "    plt.figure(figsize=(16, 4))\n",
        "\n",
        "    plt.subplot(1, 5, 1)\n",
        "    plt.imshow(img_entrada)\n",
        "    plt.title('Entrada')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 5, 2)\n",
        "    plt.imshow(img_saida_real.squeeze(), cmap='gray')\n",
        "    plt.title('Saída Esperada')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 5, 3)\n",
        "    plt.imshow(img_saida_unet.squeeze(), cmap='gray')\n",
        "    plt.title('Saída U-Net')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 5, 4)\n",
        "    plt.imshow(img_saida_segnet.squeeze(), cmap='gray')\n",
        "    plt.title('Saída SegNet')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNgWQf9dANJT"
      },
      "source": [
        "## Comparação de métricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 961
        },
        "id": "3E-mOKTEWw90",
        "outputId": "f27e0631-372d-4457-cb03-a435c3615857"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Dados do histórico para o U-Net\n",
        "acc_unet = history_unet['accuracy']\n",
        "val_acc_unet = history_unet['val_accuracy']\n",
        "loss_unet = history_unet['loss']\n",
        "val_loss_unet = history_unet['val_loss']\n",
        "\n",
        "# Dados do histórico para o SegNet\n",
        "acc_segnet = history_segnet['accuracy']\n",
        "val_acc_segnet = history_segnet['val_accuracy']\n",
        "loss_segnet = history_segnet['loss']\n",
        "val_loss_segnet = history_segnet['val_loss']\n",
        "\n",
        "# Número de épocas baseado nos dados do U-Net (assumindo mesmo número de épocas para ambos)\n",
        "epochs = range(1, len(acc_unet) + 1)\n",
        "\n",
        "# Criar figura para subplots\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "# Subplot para precisão de U-Net\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, acc_unet, 'r', label='Precisão do Conjunto de Treino (U-Net)')\n",
        "plt.plot(epochs, val_acc_unet, 'b', label='Precisão do Conjunto de Validação (U-Net)')\n",
        "plt.title('Precisão do Treino e Validação - U-Net')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Precisão')\n",
        "plt.legend()\n",
        "\n",
        "# Subplot para precisão de SegNet\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, acc_segnet, 'r', label='Precisão do Conjunto de Treino (SegNet)')\n",
        "plt.plot(epochs, val_acc_segnet, 'b', label='Precisão do Conjunto de Validação (SegNet)')\n",
        "plt.title('Precisão do Treino e Validação - SegNet')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Precisão')\n",
        "plt.legend()\n",
        "\n",
        "# Mostrar os gráficos de precisão\n",
        "plt.show()\n",
        "\n",
        "# Criar figura para subplots de perda\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "# Subplot para perda de U-Net\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, loss_unet, 'r', label='Perda do Conjunto de Treino (U-Net)')\n",
        "plt.plot(epochs, val_loss_unet, 'b', label='Perda do Conjunto de Validação (U-Net)')\n",
        "plt.title('Perda do Treino e Validação - U-Net')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Perda')\n",
        "plt.legend()\n",
        "\n",
        "# Subplot para perda de SegNet\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, loss_segnet, 'r', label='Perda do Conjunto de Treino (SegNet)')\n",
        "plt.plot(epochs, val_loss_segnet, 'b', label='Perda do Conjunto de Validação (SegNet)')\n",
        "plt.title('Perda do Treino e Validação - SegNet')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Perda')\n",
        "plt.legend()\n",
        "\n",
        "# Mostrar os gráficos de perda\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WW0h1gyyGqdK"
      },
      "source": [
        "## Calculo de IoU e Covr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvW1iSGOGotO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_iou_and_coverage(y_val, predicted_masks, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Calcula o IoU e o Coverage Ratio das máscaras previstas em relação às verdadeiras.\n",
        "    \"\"\"\n",
        "    iou_scores = []\n",
        "    correct_predictions = 0\n",
        "\n",
        "    # Processar cada par de máscara verdadeira e prevista\n",
        "    for true_mask, pred_mask in zip(y_val, predicted_masks):\n",
        "        pred_mask = (pred_mask > threshold).astype(int)  # Aplicar limiarização\n",
        "\n",
        "        intersection = np.logical_and(true_mask, pred_mask)\n",
        "        union = np.logical_or(true_mask, pred_mask)\n",
        "        iou_score = np.sum(intersection) / np.sum(union) if np.sum(union) != 0 else 0\n",
        "\n",
        "        iou_scores.append(iou_score)\n",
        "\n",
        "        if iou_score >= threshold:\n",
        "            correct_predictions += 1\n",
        "\n",
        "    iou_mean = np.mean(iou_scores)\n",
        "    coverage_ratio = correct_predictions / len(iou_scores) if len(iou_scores) > 0 else 0\n",
        "\n",
        "    return iou_mean, coverage_ratio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "KYWFSlcyGzp0",
        "outputId": "8a9aa63c-4df0-4726-a294-83baf63c2a96"
      },
      "outputs": [],
      "source": [
        "# Calcular IoU e Coverage Ratio\n",
        "iou_mean_unet, coverage_ratio_unet = calculate_iou_and_coverage(y_val, predicted_masks_unet)\n",
        "iou_mean_segnet, coverage_ratio_segnet = calculate_iou_and_coverage(y_val, predicted_masks_segnet)\n",
        "\n",
        "# Plotar os resultados\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.bar(['U-Net', 'SegNet'], [iou_mean_unet, iou_mean_segnet], color=['red', 'blue'])\n",
        "plt.title('Comparação de IoU')\n",
        "plt.ylabel('IoU')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.bar(['U-Net', 'SegNet'], [coverage_ratio_unet, coverage_ratio_segnet], color=['red', 'blue'])\n",
        "plt.title('Comparação de Coverage Ratio')\n",
        "plt.ylabel('Coverage Ratio')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s05kqKpVRX4j"
      },
      "source": [
        "# Conclusão\n",
        "\n",
        "Tendo as análises acima em mente, é possível afirmar que a melhor escolha dentre os dois é o U-Net; visto que suas perdas na validação compensam o \"tradeoff\" de um coverage ratio levemente menor e uma precisão menor em treino.\n",
        "\n",
        "Ao inspecionar visualmente as saídas, também é possível notar a qualidade das imagens, especialmente quando comparadas as da Segnet."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Tj46nKsJid3y"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
