{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQl90jW20q1D"
      },
      "source": [
        "# Obter dados no drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehPwUJLzSsLC"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "from PIL import Image, ImageDraw\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, Callback\n",
        "from glob import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras import layers, models, Input, regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibpCXTgmS_Hi",
        "outputId": "5b01110d-cf93-44f6-e9c0-3160240a1ff4"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xSP-0NwWdAq"
      },
      "source": [
        "# Divisão de imagens e masks em amostras de treino e teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yz6Rn0h26UVx"
      },
      "outputs": [],
      "source": [
        "images = []\n",
        "masks = []\n",
        "\n",
        "for path in glob('/content/drive/Shared drives/Grupo T de Tech/Data/dataset_inteli/cropped_images/*/*'):\n",
        "  images.append(path + '/image.tif')\n",
        "  masks.append(path + '/mask.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgFIh5hrObFb"
      },
      "outputs": [],
      "source": [
        "# Função para carregar e pré-processar uma imagem e sua máscara\n",
        "def load_and_preprocess_image(image_path, mask_path, target_size):\n",
        "\n",
        "    image = load_img(image_path, target_size=target_size)\n",
        "    image = img_to_array(image) / 255.0  # Normalização entre 0 e 1\n",
        "\n",
        "    mask = load_img(mask_path, target_size=target_size, color_mode='grayscale')\n",
        "    mask = img_to_array(mask) / 255.0  # Normalização entre 0 e 1\n",
        "\n",
        "    return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Qu_4ZJaKOTGF",
        "outputId": "329caf8d-b011-4a81-e01b-8fcd50295cce"
      },
      "outputs": [],
      "source": [
        "# Lista para armazenar imagens e máscaras pré-processadas\n",
        "images_processed = []\n",
        "masks_processed = []\n",
        "\n",
        "count = 1\n",
        "# Carregar e pré-processar todas as imagens e máscaras\n",
        "for img_path, mask_path in zip(images, masks):\n",
        "    print(count)\n",
        "    count += 1\n",
        "    img, mask = load_and_preprocess_image(img_path, mask_path, target_size=(256, 256))\n",
        "    images_processed.append(img)\n",
        "    masks_processed.append(mask)\n",
        "\n",
        "# Converter para arrays numpy\n",
        "images_processed = np.array(images_processed)\n",
        "masks_processed = np.array(masks_processed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kRApOxtFQ3IX",
        "outputId": "24b45c5d-a13d-4111-a0a0-f6d0e9b5eca6"
      },
      "outputs": [],
      "source": [
        "images_processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xtU7CLmDfqL"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(images_processed, masks_processed, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dApijRqyWk_n"
      },
      "source": [
        "# Definição do modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JcNGKwDxX94"
      },
      "outputs": [],
      "source": [
        "class CyclicLR(Callback):\n",
        "    def __init__(self, base_lr=1e-4, max_lr=1e-3, step_size=2000., mode='triangular'):\n",
        "        super(CyclicLR, self).__init__()\n",
        "\n",
        "        self.base_lr = base_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.step_size = step_size\n",
        "        self.mode = mode\n",
        "        self.iterations = 0\n",
        "        self.history = {}\n",
        "\n",
        "    def clr(self):\n",
        "        cycle = np.floor(1 + self.iterations / (2 * self.step_size))\n",
        "        x = np.abs(self.iterations / self.step_size - 2 * cycle + 1)\n",
        "        lr = self.base_lr + (self.max_lr - self.base_lr) * max(0, (1 - x))\n",
        "        if self.mode == 'triangular2':\n",
        "            lr = lr / float(2 ** (cycle - 1))\n",
        "        elif self.mode == 'exp_range':\n",
        "            lr = lr * (0.999 ** self.iterations)\n",
        "        return lr\n",
        "\n",
        "    def on_train_begin(self, logs=None):\n",
        "        logs = logs or {}\n",
        "        tf.keras.backend.set_value(self.model.optimizer.lr, self.base_lr)\n",
        "\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        self.iterations += 1\n",
        "        lr = self.clr()\n",
        "        tf.keras.backend.set_value(self.model.optimizer.lr, lr)\n",
        "        self.history.setdefault('lr', []).append(lr)\n",
        "        for k, v in logs.items():\n",
        "            self.history.setdefault(k, []).append(v)\n",
        "\n",
        "# Função de callbacks\n",
        "def get_callbacks():\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
        "    clr = CyclicLR(base_lr=1e-4, max_lr=1e-3, step_size=2000., mode='triangular2')\n",
        "    return [early_stopping, reduce_lr, clr]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZMBQc7JL15q"
      },
      "outputs": [],
      "source": [
        "# Função para calcular a sigmoide e converter para 0 ou 1 o output\n",
        "class ThresholdLayer(tf.keras.layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        return tf.where(inputs < 0.5, 0.0, 1.0)\n",
        "\n",
        "# Função para calcular o Dice Coefficient\n",
        "def dice_coefficient(y_train, y_val):\n",
        "    smooth = 1e-6\n",
        "    intersection = tf.reduce_sum(y_train * y_val)\n",
        "    dice_coefficient = (2. * intersection + smooth) / (tf.reduce_sum(y_train) + tf.reduce_sum(y_val) + smooth)\n",
        "    return dice_coefficient\n",
        "\n",
        "# Função de perda de Dice\n",
        "def dice_loss(y_train, y_val):\n",
        "    return 1 - dice_coefficient(y_train, y_val)\n",
        "\n",
        "# Função para calcular a penalidade adicional\n",
        "def penalty_loss(y_train, y_val, penalty_weight):\n",
        "    # Calcular a penalidade considerando a diferença entre y_train e y_val\n",
        "    penalty = tf.reduce_sum(tf.abs(y_train - y_val))\n",
        "    # Multiplicar a penalidade pelo peso da penalidade\n",
        "    weighted_penalty = penalty_weight * penalty\n",
        "    return weighted_penalty\n",
        "\n",
        "# Função de perda combinada\n",
        "def combined_loss(y_train, y_val, penalty_weight):\n",
        "    # Perda padrão (por exemplo, perda de entropia cruzada binária)\n",
        "    standard_loss = tf.keras.losses.binary_crossentropy(y_train, y_val)\n",
        "    # Dice Loss\n",
        "    dice = dice_loss(y_train, y_val)\n",
        "    # Penalidade adicional\n",
        "    penalty = penalty_loss(y_train, y_val, penalty_weight)\n",
        "    # Perda total = perda padrão + penalidade + Dice Loss\n",
        "    total_loss = standard_loss + penalty + dice\n",
        "    return total_loss\n",
        "\n",
        "# Métrica de acurácia customizada\n",
        "def custom_accuracy(y_train, y_val):\n",
        "    # Calcular a acurácia considerando uma tolerância de 0.5 na predição\n",
        "    y_val_binary = tf.round(y_val)\n",
        "    accuracy = tf.reduce_mean(tf.cast(tf.equal(y_train, y_val_binary), tf.float32))\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJk0H6D6T9F1"
      },
      "outputs": [],
      "source": [
        "def Unet(input_shape):\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "    # Encoder (contraction path)\n",
        "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
        "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
        "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
        "    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
        "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    # Decoder (expansion path)\n",
        "    up3 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv2)\n",
        "    merge3 = layers.concatenate([conv1, up3], axis=3)\n",
        "    conv3 = layers.Conv2D(64, 3, activation='relu', padding='same')(merge3)\n",
        "    conv3 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv3)\n",
        "\n",
        "    outputs = layers.Conv2D(1, 1, activation='sigmoid')(conv3)  # Saída com um canal (máscara binária)\n",
        "\n",
        "    threshold_output = ThresholdLayer()(outputs)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIxkz9tyUEb8",
        "outputId": "b2c2381a-4b43-415e-d0de-2693304dacac"
      },
      "outputs": [],
      "source": [
        "# Criar modelo U-Net\n",
        "model = Unet(input_shape=(256, 256, 3))\n",
        "#model = UNet(output_channels=1)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_K8INbM9Wpi8"
      },
      "source": [
        "# Treino do modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTLb8OpzUHrj",
        "outputId": "1657a22e-1e3f-4922-e73b-0babe8faba5d"
      },
      "outputs": [],
      "source": [
        "callbacks = get_callbacks()\n",
        "\n",
        "# Compilar o modelo\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss=lambda y_train, y_val: combined_loss(y_train, y_val, 0.001), metrics=[custom_accuracy])\n",
        "\n",
        "# Treinar o modelo\n",
        "H = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=200, batch_size=16, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_XrQw1fWtkp"
      },
      "source": [
        "# Avaliação do modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "IpbWkEwibEV2",
        "outputId": "b761038b-d3e5-4c25-acf0-c90392b8133b"
      },
      "outputs": [],
      "source": [
        "# Avaliando o modelo\n",
        "loss, accuracy = model.evaluate(X_val, y_val)\n",
        "print(f'Acurácia do modelo: {accuracy}')\n",
        "\n",
        "# Mostrando resultados\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(H.epoch, H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(H.epoch, H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(H.epoch, H.history[\"custom_accuracy\"], label=\"train_acc\")\n",
        "plt.plot(H.epoch, H.history[\"val_custom_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXe7NUljUoKH",
        "outputId": "ed2fa818-3979-417c-e354-018649442ceb"
      },
      "outputs": [],
      "source": [
        "# Avaliar o modelo nos dados de teste\n",
        "results = model.evaluate(X_val, y_val)\n",
        "print(\"Test Loss:\", results[0])\n",
        "print(\"Test Accuracy:\", results[1])\n",
        "\n",
        "# Prever máscaras usando o modelo\n",
        "predicted_masks = model.predict(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        },
        "id": "3E-mOKTEWw90",
        "outputId": "eead0afa-6a22-449b-d138-237594ef8589"
      },
      "outputs": [],
      "source": [
        "# Obter métricas de precisão e perda do histórico de treinamento\n",
        "acc = H.history['custom_accuracy']\n",
        "val_acc = H.history['val_custom_accuracy']\n",
        "loss = H.history['loss']\n",
        "val_loss = H.history['val_loss']\n",
        "\n",
        "# Número de épocas\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# Plotar precisão do conjunto de treino e validação\n",
        "plt.plot(epochs, acc, 'r', label='Precisão do Conjunto de Treino')\n",
        "plt.plot(epochs, val_acc, 'b', label='Precisão do Conjunto de Validação')\n",
        "plt.title('Precisão do Conjunto de Treino e Validação')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Precisão')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plotar perda do conjunto de treino e validação\n",
        "plt.plot(epochs, loss, 'r', label='Perda do Conjunto de Treino')\n",
        "plt.plot(epochs, val_loss, 'b', label='Perda do Conjunto de Validação')\n",
        "plt.title('Perda do Conjunto de Treino e Validação')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Perda')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "50cPtSMOWIqb",
        "outputId": "1d9c0da3-44e7-4b83-8468-cd740be01b87"
      },
      "outputs": [],
      "source": [
        "# Gerar as saídas do modelo para um conjunto de entradas de teste\n",
        "saidas_modelo = model.predict(X_val)\n",
        "\n",
        "# Iterar sobre cada saída do modelo\n",
        "for i in range(len(X_val)):\n",
        "    # Obter a entrada correspondente e a saída real\n",
        "    img_entrada = X_val[i]\n",
        "    img_saida_real = y_val[i]\n",
        "\n",
        "    # Obter a saída gerada pelo modelo\n",
        "    img_saida_modelo = saidas_modelo[i]\n",
        "\n",
        "    # Mostrar as imagens\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(img_entrada.squeeze(), cmap='gray')\n",
        "    plt.title('Entrada')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(img_saida_real.squeeze(), cmap='gray')\n",
        "    plt.title('Saída Esperada')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(img_saida_modelo.squeeze(), cmap='gray')\n",
        "    plt.title('Saída do Modelo')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8o4pT9GJiYqw",
        "outputId": "b0d09b29-a1c4-442f-b181-2a38e73133dc"
      },
      "outputs": [],
      "source": [
        "# Implementando as outras métricas\n",
        "\n",
        "# Lista para armazenar os scores de IoU\n",
        "iou_scores = []\n",
        "# Calcular IoUs e determinar predições corretas\n",
        "correct_predictions = 0\n",
        "iou_threshold = 0.5\n",
        "for mask, result in zip(y_val, img_saida_modelo):\n",
        "    intersection = np.logical_and(mask, result)\n",
        "    union = np.logical_or(mask, result)\n",
        "    iou_score = np.sum(intersection) / np.sum(union) if np.sum(union) != 0 else 0\n",
        "    iou_scores.append(iou_score)\n",
        "    # Verificar se a predição é considerada correta (IoU >= threshold)\n",
        "    if iou_score >= iou_threshold:\n",
        "        correct_predictions += 1\n",
        "    print('IoU é: ' + str(iou_score))\n",
        "# Calcular a média dos IoUs\n",
        "iou_mean = np.mean(iou_scores)\n",
        "print('Média dos IoU:', iou_mean)\n",
        "# Calcular Coverage Ratio (CovR)\n",
        "total_predictions = len(iou_scores)\n",
        "covr = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
        "print('Coverage Ratio (CovR):', covr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxRzXSJGfymO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
