{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQl90jW20q1D"
      },
      "source": [
        "# Obter dados no drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehPwUJLzSsLC"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "import time\n",
        "from PIL import Image, ImageDraw\n",
        "import matplotlib.pyplot as plt\n",
        "tf.config.run_functions_eagerly(True)\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, Callback\n",
        "from glob import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras import layers, models, Input, regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibpCXTgmS_Hi",
        "outputId": "f7fb103a-4379-4e04-bf44-047c15b08772"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xSP-0NwWdAq"
      },
      "source": [
        "# Carregamento de dados - Sem Data Augmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yz6Rn0h26UVx"
      },
      "outputs": [],
      "source": [
        "images = []\n",
        "masks = []\n",
        "\n",
        "for path in glob('/content/drive/Shared drives/Grupo T de Tech/Data/dataset_inteli/cropped_images/*/*'):\n",
        "  images.append(path + '/image.tif')\n",
        "  masks.append(path + '/mask.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgFIh5hrObFb"
      },
      "outputs": [],
      "source": [
        "# Função para carregar e pré-processar uma imagem e sua máscara\n",
        "def load_and_preprocess_image(image_path, mask_path, target_size):\n",
        "\n",
        "    image = load_img(image_path, target_size=target_size)\n",
        "    image = img_to_array(image) / 255.0  # Normalização entre 0 e 1\n",
        "\n",
        "    mask = load_img(mask_path, target_size=target_size, color_mode='grayscale')\n",
        "    mask = img_to_array(mask) / 255.0  # Normalização entre 0 e 1\n",
        "\n",
        "    return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Qu_4ZJaKOTGF",
        "outputId": "74e3da03-5acc-4e9e-b05d-a9f9b8b2f73b"
      },
      "outputs": [],
      "source": [
        "# Lista para armazenar imagens e máscaras pré-processadas\n",
        "images_processed = []\n",
        "masks_processed = []\n",
        "\n",
        "count = 1\n",
        "# Carregar e pré-processar todas as imagens e máscaras\n",
        "for img_path, mask_path in zip(images, masks):\n",
        "    print(count)\n",
        "    count += 1\n",
        "    img, mask = load_and_preprocess_image(img_path, mask_path, target_size=(256, 256))\n",
        "    images_processed.append(img)\n",
        "    masks_processed.append(mask)\n",
        "\n",
        "# Converter para arrays numpy\n",
        "images_processed = np.array(images_processed)\n",
        "masks_processed = np.array(masks_processed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kRApOxtFQ3IX",
        "outputId": "aced02a7-7800-45ba-8af1-e24b7eb4f203"
      },
      "outputs": [],
      "source": [
        "images_processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1XJsmj6Iu1W"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(images_processed, masks_processed, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dApijRqyWk_n"
      },
      "source": [
        "# Definição de parâmetros e modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JcNGKwDxX94"
      },
      "outputs": [],
      "source": [
        "class CyclicLR(Callback):\n",
        "    def __init__(self, base_lr=1e-4, max_lr=1e-3, step_size=2000., mode='triangular'):\n",
        "        super(CyclicLR, self).__init__()\n",
        "\n",
        "        self.base_lr = base_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.step_size = step_size\n",
        "        self.mode = mode\n",
        "        self.iterations = 0\n",
        "        self.history = {}\n",
        "\n",
        "    def clr(self):\n",
        "        cycle = np.floor(1 + self.iterations / (2 * self.step_size))\n",
        "        x = np.abs(self.iterations / self.step_size - 2 * cycle + 1)\n",
        "        lr = self.base_lr + (self.max_lr - self.base_lr) * max(0, (1 - x))\n",
        "        if self.mode == 'triangular2':\n",
        "            lr = lr / float(2 ** (cycle - 1))\n",
        "        elif self.mode == 'exp_range':\n",
        "            lr = lr * (0.999 ** self.iterations)\n",
        "        return lr\n",
        "\n",
        "    def on_train_begin(self, logs=None):\n",
        "        logs = logs or {}\n",
        "        tf.keras.backend.set_value(self.model.optimizer.lr, self.base_lr)\n",
        "\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        self.iterations += 1\n",
        "        lr = self.clr()\n",
        "        tf.keras.backend.set_value(self.model.optimizer.lr, lr)\n",
        "        self.history.setdefault('lr', []).append(lr)\n",
        "        for k, v in logs.items():\n",
        "            self.history.setdefault(k, []).append(v)\n",
        "\n",
        "# Função de callbacks\n",
        "def get_callbacks():\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
        "    clr = CyclicLR(base_lr=1e-4, max_lr=1e-3, step_size=2000., mode='triangular2')\n",
        "    return [early_stopping, reduce_lr, clr]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZMBQc7JL15q"
      },
      "outputs": [],
      "source": [
        "# Função para calcular a sigmoide e converter para 0 ou 1 o output\n",
        "class ThresholdLayer(tf.keras.layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        return tf.where(inputs < 0.5, 0.0, 1.0)\n",
        "\n",
        "# Função para calcular o Dice Coefficient\n",
        "def dice_coefficient(y_train, y_val):\n",
        "    smooth = 1e-6\n",
        "    intersection = tf.reduce_sum(y_train * y_val)\n",
        "    dice_coefficient = (2. * intersection + smooth) / (tf.reduce_sum(y_train) + tf.reduce_sum(y_val) + smooth)\n",
        "    return dice_coefficient\n",
        "\n",
        "# Função de perda de Dice\n",
        "def dice_loss(y_train, y_val):\n",
        "    return 1 - dice_coefficient(y_train, y_val)\n",
        "\n",
        "# Função para calcular a penalidade adicional\n",
        "def penalty_loss(y_train, y_val, penalty_weight):\n",
        "    # Calcular a penalidade considerando a diferença entre y_train e y_val\n",
        "    penalty = tf.reduce_sum(tf.abs(y_train - y_val))\n",
        "    # Multiplicar a penalidade pelo peso da penalidade\n",
        "    weighted_penalty = penalty_weight * penalty\n",
        "    return weighted_penalty\n",
        "\n",
        "# Função de perda combinada\n",
        "def combined_loss(y_train, y_val, penalty_weight):\n",
        "    # Perda padrão (por exemplo, perda de entropia cruzada binária)\n",
        "    standard_loss = tf.keras.losses.binary_crossentropy(y_train, y_val)\n",
        "    # Dice Loss\n",
        "    dice = dice_loss(y_train, y_val)\n",
        "    # Penalidade adicional\n",
        "    penalty = penalty_loss(y_train, y_val, penalty_weight)\n",
        "    # Perda total = perda padrão + penalidade + Dice Loss\n",
        "    total_loss = standard_loss + penalty + dice\n",
        "    return total_loss\n",
        "\n",
        "# Métrica de acurácia customizada\n",
        "def custom_accuracy(y_train, y_val):\n",
        "    # Calcular a acurácia considerando uma tolerância de 0.5 na predição\n",
        "    y_val_binary = tf.round(y_val)\n",
        "    accuracy = tf.reduce_mean(tf.cast(tf.equal(y_train, y_val_binary), tf.float32))\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJk0H6D6T9F1"
      },
      "outputs": [],
      "source": [
        "def Unet(input_shape):\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "    reg = regularizers.L2(0.001)\n",
        "\n",
        "    # Encoder (contraction path)\n",
        "    conv1 = layers.Conv2D(16, 3, activation='relu', padding='same', kernel_regularizer=reg)(inputs)\n",
        "    conv1 = layers.Conv2D(16, 3, activation='relu', padding='same', kernel_regularizer=reg)(conv1)\n",
        "    drop1 = layers.Dropout(0.3)(conv1)\n",
        "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(drop1)\n",
        "\n",
        "    conv2 = layers.Conv2D(32, 3, activation='relu', padding='same', kernel_regularizer=reg)(pool1)\n",
        "    conv2 = layers.Conv2D(32, 3, activation='relu', padding='same', kernel_regularizer=reg)(conv2)\n",
        "    drop2 = layers.Dropout(0.3)(conv2)\n",
        "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(drop2)\n",
        "\n",
        "    conv3 = layers.Conv2D(64, 3, activation='relu', padding='same', kernel_regularizer=reg)(pool2)\n",
        "    conv3 = layers.Conv2D(64, 3, activation='relu', padding='same', kernel_regularizer=reg)(conv3)\n",
        "    drop3 = layers.Dropout(0.3)(conv3)\n",
        "    pool3 = layers.MaxPooling2D(pool_size=(2, 2))(drop3)\n",
        "\n",
        "    # Bottleneck\n",
        "    conv4 = layers.Conv2D(128, 3, activation='relu', padding='same', kernel_regularizer=reg)(pool3)\n",
        "    conv4 = layers.Conv2D(128, 3, activation='relu', padding='same', kernel_regularizer=reg)(conv4)\n",
        "    drop4 = layers.Dropout(0.3)(conv4)\n",
        "\n",
        "    # Decoder (expansion path)\n",
        "    up5 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(drop4)\n",
        "    merge5 = layers.concatenate([conv3, up5], axis=3)\n",
        "    conv5 = layers.Conv2D(64, 3, activation='relu', padding='same', kernel_regularizer=reg)(merge5)\n",
        "    conv5 = layers.Conv2D(64, 3, activation='relu', padding='same', kernel_regularizer=reg)(conv5)\n",
        "\n",
        "    up6 = layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv5)\n",
        "    merge6 = layers.concatenate([conv2, up6], axis=3)\n",
        "    conv6 = layers.Conv2D(32, 3, activation='relu', padding='same', kernel_regularizer=reg)(merge6)\n",
        "    conv6 = layers.Conv2D(32, 3, activation='relu', padding='same', kernel_regularizer=reg)(conv6)\n",
        "\n",
        "    up7 = layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(conv6)\n",
        "    merge7 = layers.concatenate([conv1, up7], axis=3)\n",
        "    conv7 = layers.Conv2D(16, 3, activation='relu', padding='same', kernel_regularizer=reg)(merge7)\n",
        "    conv7 = layers.Conv2D(16, 3, activation='relu', padding='same', kernel_regularizer=reg)(conv7)\n",
        "\n",
        "    outputs = layers.Conv2D(1, 1, activation='sigmoid')(conv7)  # Saída com um canal (máscara binária)\n",
        "\n",
        "    threshold_output = ThresholdLayer()(outputs)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIxkz9tyUEb8",
        "outputId": "5d776afb-a1b7-4fd0-afa7-fa9ed4e863d9"
      },
      "outputs": [],
      "source": [
        "# Criar modelo U-Net\n",
        "model = Unet(input_shape=(256, 256, 3))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_K8INbM9Wpi8"
      },
      "source": [
        "# Treino do modelo - GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTLb8OpzUHrj",
        "outputId": "292cfded-75bb-4e92-c1d2-e8fe57a8e476"
      },
      "outputs": [],
      "source": [
        "callbacks = get_callbacks()\n",
        "with tf.device('/gpu:0'):\n",
        "    # Compilar o modelo\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss=lambda y_train, y_val: combined_loss(y_train, y_val, 0.001), metrics=[custom_accuracy])\n",
        "\n",
        "    # Calcula o tempo de treino\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Definições\n",
        "    max_epochs = 200\n",
        "    batch_size = 16\n",
        "\n",
        "    # Treinar o modelo\n",
        "    H = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=max_epochs, batch_size=batch_size, callbacks=callbacks)\n",
        "\n",
        "    # Para o cronômetro e salva o tempo de treino\n",
        "    training_time_gpu = time.time() - start_time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_XrQw1fWtkp"
      },
      "source": [
        "## Avaliação do modelo - GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "IpbWkEwibEV2",
        "outputId": "2837efa3-a643-462b-b5c1-4afb442a641b"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    # Mostrando resultados\n",
        "    plt.style.use(\"ggplot\")\n",
        "    plt.figure()\n",
        "    plt.plot(H.epoch, H.history[\"loss\"], label=\"train_loss\")\n",
        "    plt.plot(H.epoch, H.history[\"val_loss\"], label=\"val_loss\")\n",
        "    plt.plot(H.epoch, H.history[\"custom_accuracy\"], label=\"train_acc\")\n",
        "    plt.plot(H.epoch, H.history[\"val_custom_accuracy\"], label=\"val_acc\")\n",
        "    plt.title(\"Training Loss and Accuracy - GPU\")\n",
        "    plt.xlabel(\"Epoch #\")\n",
        "    plt.ylabel(\"Loss/Accuracy\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXe7NUljUoKH",
        "outputId": "fe860588-7716-458d-974b-e635d74c2e4a"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    # Calcula o tempo de inferência\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Avaliar o modelo nos dados de teste\n",
        "    results = model.evaluate(X_val, y_val)\n",
        "\n",
        "    # Para o cronômetro e salva o tempo de treino\n",
        "    inference_time_gpu = time.time() - start_time\n",
        "\n",
        "    print(\"Test Loss - GPU:\", results[0])\n",
        "    print(\"Test Accuracy - GPU:\", results[1])\n",
        "\n",
        "    # Prever máscaras usando o modelo\n",
        "    predicted_masks = model.predict(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        },
        "id": "3E-mOKTEWw90",
        "outputId": "19391be7-eac3-4ebd-c3ae-ccd46e7a8255"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    # Obter métricas de precisão e perda do histórico de treinamento\n",
        "    acc = H.history['custom_accuracy']\n",
        "    val_acc = H.history['val_custom_accuracy']\n",
        "    loss = H.history['loss']\n",
        "    val_loss = H.history['val_loss']\n",
        "\n",
        "    # Número de épocas\n",
        "    epochs = range(1, len(acc) + 1)\n",
        "\n",
        "    # Plotar precisão do conjunto de treino e validação\n",
        "    plt.plot(epochs, acc, 'r', label='Precisão do Conjunto de Treino')\n",
        "    plt.plot(epochs, val_acc, 'b', label='Precisão do Conjunto de Validação')\n",
        "    plt.title('Precisão do Conjunto de Treino e Validação - GPU')\n",
        "    plt.xlabel('Épocas')\n",
        "    plt.ylabel('Precisão')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Plotar perda do conjunto de treino e validação\n",
        "    plt.plot(epochs, loss, 'r', label='Perda do Conjunto de Treino')\n",
        "    plt.plot(epochs, val_loss, 'b', label='Perda do Conjunto de Validação')\n",
        "    plt.title('Perda do Conjunto de Treino e Validação - GPU')\n",
        "    plt.xlabel('Épocas')\n",
        "    plt.ylabel('Perda')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        },
        "id": "9diaOF4DmnGr",
        "outputId": "960c4928-2588-4132-aaef-b8ed6496c3f9"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    print(epochs)\n",
        "    print('Tempo de treino GPU (segundos): ', training_time_gpu)\n",
        "    print('Tempo de treino GPU por época (segundos): ', training_time_gpu / max_epochs)\n",
        "    print('Tempo de inferência GPU (segundos): ', inference_time_gpu)\n",
        "\n",
        "    # Plotando o tempo de treinamento e inferência\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.bar(['GPU Training'], [training_time_gpu], color=['orange'])\n",
        "    plt.bar(['GPU Inference'], [inference_time_gpu], color=['orange'])\n",
        "    plt.ylabel('Time (seconds)')\n",
        "    plt.title('Training and Inference Time - GPU')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50cPtSMOWIqb"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    # Gerar as saídas do modelo para um conjunto de entradas de teste\n",
        "    saidas_modelo = model.predict(X_val)\n",
        "\n",
        "    # Iterar sobre cada saída do modelo\n",
        "    for i in range(len(X_val)):\n",
        "        # Obter a entrada correspondente e a saída real\n",
        "        img_entrada = X_val[i]\n",
        "        img_saida_real = y_val[i]\n",
        "\n",
        "        # Obter a saída gerada pelo modelo\n",
        "        img_saida_modelo = saidas_modelo[i]\n",
        "\n",
        "        # Mostrar as imagens\n",
        "        plt.figure(figsize=(12, 4))\n",
        "\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.imshow(img_entrada.squeeze(), cmap='gray')\n",
        "        plt.title('Entrada')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.imshow(img_saida_real.squeeze(), cmap='gray')\n",
        "        plt.title('Saída Esperada')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(img_saida_modelo.squeeze(), cmap='gray')\n",
        "        plt.title('Saída do Modelo - GPU')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8o4pT9GJiYqw",
        "outputId": "ffec7f3f-d772-4757-eeda-7a3ffa5fe5bc"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    # Métricas do parceiro de Projeto:\n",
        "\n",
        "    # Lista para armazenar os scores de IoU\n",
        "    iou_scores = []\n",
        "    # Calcular IoUs e determinar predições corretas\n",
        "    correct_predictions = 0\n",
        "    iou_threshold = 0.5\n",
        "    for mask, result in zip(y_val, img_saida_modelo):\n",
        "        intersection = np.logical_and(mask, result)\n",
        "        union = np.logical_or(mask, result)\n",
        "        iou_score = np.sum(intersection) / np.sum(union) if np.sum(union) != 0 else 0\n",
        "        iou_scores.append(iou_score)\n",
        "        # Verificar se a predição é considerada correta (IoU >= threshold)\n",
        "        if iou_score >= iou_threshold:\n",
        "            correct_predictions += 1\n",
        "        print('IoU é: ' + str(iou_score))\n",
        "    # Calcular a média dos IoUs\n",
        "    iou_mean = np.mean(iou_scores)\n",
        "    print('Média dos IoU - GPU:', iou_mean)\n",
        "    # Calcular Coverage Ratio (CovR)\n",
        "    total_predictions = len(iou_scores)\n",
        "    covr = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
        "    print('Coverage Ratio (CovR) - GPU:', covr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOUyygDLvAWU"
      },
      "source": [
        "# Treino do modelo - CPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d44pwWEo1jB_",
        "outputId": "64a5b43b-04e1-427e-ea76-0939fc2ac11d"
      },
      "outputs": [],
      "source": [
        "# Criar modelo U-Net\n",
        "model = Unet(input_shape=(256, 256, 3))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbamiV8NvAWU",
        "outputId": "684c3d43-d416-4038-f89e-6996d6e106cf"
      },
      "outputs": [],
      "source": [
        "callbacks = get_callbacks()\n",
        "with tf.device('/cpu:0'):\n",
        "    # Compilar o modelo\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss=lambda y_train, y_val: combined_loss(y_train, y_val, 0.001), metrics=[custom_accuracy])\n",
        "\n",
        "    # Calcula o tempo de treino\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Definições\n",
        "    max_epochs = 30\n",
        "    batch_size = 16\n",
        "\n",
        "    # Treinar o modelo\n",
        "    H = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=max_epochs, batch_size=batch_size, callbacks=callbacks)\n",
        "\n",
        "    # Para o cronômetro e salva o tempo de treino\n",
        "    training_time_cpu = time.time() - start_time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRMH1XP3vAWV"
      },
      "source": [
        "## Avaliação do modelo - CPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "TYcvRZdgvAWV",
        "outputId": "5ca50f4d-147b-4cbe-c305-80a8023f5a19"
      },
      "outputs": [],
      "source": [
        "with tf.device('/cpu:0'):\n",
        "    # Mostrando resultados\n",
        "    plt.style.use(\"ggplot\")\n",
        "    plt.figure()\n",
        "    plt.plot(H.epoch, H.history[\"loss\"], label=\"train_loss\")\n",
        "    plt.plot(H.epoch, H.history[\"val_loss\"], label=\"val_loss\")\n",
        "    plt.plot(H.epoch, H.history[\"custom_accuracy\"], label=\"train_acc\")\n",
        "    plt.plot(H.epoch, H.history[\"val_custom_accuracy\"], label=\"val_acc\")\n",
        "    plt.title(\"Training Loss and Accuracy - CPU\")\n",
        "    plt.xlabel(\"Epoch #\")\n",
        "    plt.ylabel(\"Loss/Accuracy\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rw10L6HfvAWV",
        "outputId": "48b0ca5d-7154-4b06-9242-be14ccbaed31"
      },
      "outputs": [],
      "source": [
        "with tf.device('/cpu:0'):\n",
        "    # Calcula o tempo de inferência\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Avaliar o modelo nos dados de teste\n",
        "    results = model.evaluate(X_val, y_val)\n",
        "\n",
        "    # Para o cronômetro e salva o tempo de treino\n",
        "    inference_time_cpu = time.time() - start_time\n",
        "\n",
        "    print(\"Test Loss - CPU:\", results[0])\n",
        "    print(\"Test Accuracy - CPU:\", results[1])\n",
        "\n",
        "    # Prever máscaras usando o modelo\n",
        "    predicted_masks = model.predict(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        },
        "id": "G12SueApvAWV",
        "outputId": "f33d6d00-3cd1-4304-f6de-f0eb16e84c2d"
      },
      "outputs": [],
      "source": [
        "with tf.device('/cpu:0'):\n",
        "    # Obter métricas de precisão e perda do histórico de treinamento\n",
        "    acc = H.history['custom_accuracy']\n",
        "    val_acc = H.history['val_custom_accuracy']\n",
        "    loss = H.history['loss']\n",
        "    val_loss = H.history['val_loss']\n",
        "\n",
        "    # Número de épocas\n",
        "    epochs = range(1, len(acc) + 1)\n",
        "\n",
        "    # Plotar precisão do conjunto de treino e validação\n",
        "    plt.plot(epochs, acc, 'r', label='Precisão do Conjunto de Treino')\n",
        "    plt.plot(epochs, val_acc, 'b', label='Precisão do Conjunto de Validação')\n",
        "    plt.title('Precisão do Conjunto de Treino e Validação - CPU')\n",
        "    plt.xlabel('Épocas')\n",
        "    plt.ylabel('Precisão')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Plotar perda do conjunto de treino e validação\n",
        "    plt.plot(epochs, loss, 'r', label='Perda do Conjunto de Treino')\n",
        "    plt.plot(epochs, val_loss, 'b', label='Perda do Conjunto de Validação')\n",
        "    plt.title('Perda do Conjunto de Treino e Validação - CPU')\n",
        "    plt.xlabel('Épocas')\n",
        "    plt.ylabel('Perda')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "RsIak_mHvAWW",
        "outputId": "34b84fae-0272-48e2-81c7-394a3ff23b4e"
      },
      "outputs": [],
      "source": [
        "with tf.device('/cpu:0'):\n",
        "    print('Tempo de treino CPU (segundos): ', training_time_cpu)\n",
        "    print('Tempo de treino CPU por época (segundos): ', training_time_cpu / max_epochs)\n",
        "    print('Tempo de inferência CPU (segundos): ', inference_time_cpu)\n",
        "\n",
        "    # Plotando o tempo de treinamento e inferência\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.bar(['CPU Training'], [training_time_cpu], color=['orange'])\n",
        "    plt.bar(['CPU Inference'], [inference_time_cpu], color=['orange'])\n",
        "    plt.ylabel('Time (seconds)')\n",
        "    plt.title('Training and Inference Time')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3oO76UvvAWW"
      },
      "outputs": [],
      "source": [
        "with tf.device('/cpu:0'):\n",
        "    # Gerar as saídas do modelo para um conjunto de entradas de teste\n",
        "    saidas_modelo = model.predict(X_val)\n",
        "\n",
        "    # Iterar sobre cada saída do modelo\n",
        "    for i in range(len(X_val)):\n",
        "        # Obter a entrada correspondente e a saída real\n",
        "        img_entrada = X_val[i]\n",
        "        img_saida_real = y_val[i]\n",
        "\n",
        "        # Obter a saída gerada pelo modelo\n",
        "        img_saida_modelo = saidas_modelo[i]\n",
        "\n",
        "        # Mostrar as imagens\n",
        "        plt.figure(figsize=(12, 4))\n",
        "\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.imshow(img_entrada.squeeze(), cmap='gray')\n",
        "        plt.title('Entrada')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.imshow(img_saida_real.squeeze(), cmap='gray')\n",
        "        plt.title('Saída Esperada')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(img_saida_modelo.squeeze(), cmap='gray')\n",
        "        plt.title('Saída do Modelo - CPU')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKU6Fs55vAWW",
        "outputId": "0b9ea49d-2379-47c8-9695-c070059b9764"
      },
      "outputs": [],
      "source": [
        "with tf.device('/cpu:0'):\n",
        "    # Métricas do parceiro de Projeto:\n",
        "\n",
        "    # Lista para armazenar os scores de IoU\n",
        "    iou_scores = []\n",
        "    # Calcular IoUs e determinar predições corretas\n",
        "    correct_predictions = 0\n",
        "    iou_threshold = 0.5\n",
        "    for mask, result in zip(y_val, img_saida_modelo):\n",
        "        intersection = np.logical_and(mask, result)\n",
        "        union = np.logical_or(mask, result)\n",
        "        iou_score = np.sum(intersection) / np.sum(union) if np.sum(union) != 0 else 0\n",
        "        iou_scores.append(iou_score)\n",
        "        # Verificar se a predição é considerada correta (IoU >= threshold)\n",
        "        if iou_score >= iou_threshold:\n",
        "            correct_predictions += 1\n",
        "        print('IoU é: ' + str(iou_score))\n",
        "    # Calcular a média dos IoUs\n",
        "    iou_mean = np.mean(iou_scores)\n",
        "    print('Média dos IoU - CPU:', iou_mean)\n",
        "    # Calcular Coverage Ratio (CovR)\n",
        "    total_predictions = len(iou_scores)\n",
        "    covr = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
        "    print('Coverage Ratio (CovR) - CPU:', covr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OMjPq-V-Ahs"
      },
      "source": [
        "# Carregamento de Dados - Com Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smrXgRpZ9_t8",
        "outputId": "3b595da8-1337-4a15-c928-47f64a1db6db"
      },
      "outputs": [],
      "source": [
        "# Paths\n",
        "dataset_dir = '/content/drive/Shared drives/Grupo T de Tech/Data/datasets_sprint3/dataset_inteli_processed'\n",
        "\n",
        "# Função para carregar e pré-processar uma imagem e sua máscara\n",
        "def load_and_preprocess_image(image_path, mask_path, target_size=(256, 256)):\n",
        "    image = load_img(image_path, target_size=target_size)\n",
        "    image = img_to_array(image) / 255.0  # Normalização entre 0 e 1\n",
        "\n",
        "    mask = load_img(mask_path, target_size=target_size, color_mode='grayscale')\n",
        "    mask = img_to_array(mask) / 255.0  # Normalização entre 0 e 1\n",
        "\n",
        "    return image, mask\n",
        "\n",
        "# Listas para armazenar imagens e máscaras pré-processadas\n",
        "images_processed = []\n",
        "masks_processed = []\n",
        "\n",
        "# Obter lista de todos os arquivos de imagens e máscaras\n",
        "image_files = sorted(glob(os.path.join(dataset_dir, 'processed_image_*.tif')))\n",
        "mask_files = sorted(glob(os.path.join(dataset_dir, 'processed_mask_*.png')))\n",
        "\n",
        "# Verificar se temos o mesmo número de arquivos de imagem e máscara\n",
        "assert len(image_files) == len(mask_files), \"O número de imagens e máscaras não corresponde!\"\n",
        "\n",
        "# Carregar e pré-processar todas as imagens e máscaras\n",
        "for img_path, mask_path in zip(image_files, mask_files):\n",
        "    img, mask = load_and_preprocess_image(img_path, mask_path, target_size=(256, 256))\n",
        "    images_processed.append(img)\n",
        "    masks_processed.append(mask)\n",
        "\n",
        "# Converter para arrays numpy\n",
        "images_processed = np.array(images_processed)\n",
        "masks_processed = np.array(masks_processed)\n",
        "\n",
        "# Dividir em conjuntos de treinamento e validação\n",
        "X_train, X_val, y_train, y_val = train_test_split(images_processed, masks_processed, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Number of training samples: {len(X_train)}\")\n",
        "print(f\"Number of validation samples: {len(X_val)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1BqGAu8-veW",
        "outputId": "8f048bf3-a645-4f8e-d39f-c0d854fc4382"
      },
      "outputs": [],
      "source": [
        "images_processed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDxZfL6B7bUm"
      },
      "source": [
        "# Treino do modelo - GPU - Com Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzijK1ROBmoQ",
        "outputId": "87f0ef94-f93c-41fa-91ad-f8ee6835b79f"
      },
      "outputs": [],
      "source": [
        "# Criar modelo U-Net\n",
        "model = Unet(input_shape=(256, 256, 3))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0pUkRC-7bUn",
        "outputId": "07942547-7ca6-4023-c864-2f9bac0d8439"
      },
      "outputs": [],
      "source": [
        "callbacks = get_callbacks()\n",
        "with tf.device('/gpu:0'):\n",
        "    # Compilar o modelo\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss=lambda y_train, y_val: combined_loss(y_train, y_val, 0.001), metrics=[custom_accuracy])\n",
        "\n",
        "    # Calcula o tempo de treino\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Definições\n",
        "    max_epochs = 200\n",
        "    batch_size = 16\n",
        "\n",
        "    # Treinar o modelo\n",
        "    H = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=max_epochs, batch_size=batch_size, callbacks=callbacks)\n",
        "\n",
        "    # Para o cronômetro e salva o tempo de treino\n",
        "    training_time_gpu_data_augmentation = time.time() - start_time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IUoEApA7bUp"
      },
      "source": [
        "## Avaliação do modelo - GPU - Com Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "0MkQVx8l7bUp",
        "outputId": "5605b8cd-bec6-4063-876f-d882a77b15ea"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    # Mostrando resultados\n",
        "    plt.style.use(\"ggplot\")\n",
        "    plt.figure()\n",
        "    plt.plot(H.epoch, H.history[\"loss\"], label=\"train_loss\")\n",
        "    plt.plot(H.epoch, H.history[\"val_loss\"], label=\"val_loss\")\n",
        "    plt.plot(H.epoch, H.history[\"custom_accuracy\"], label=\"train_acc\")\n",
        "    plt.plot(H.epoch, H.history[\"val_custom_accuracy\"], label=\"val_acc\")\n",
        "    plt.title(\"Training Loss and Accuracy - GPU - Data Augmentation\")\n",
        "    plt.xlabel(\"Epoch #\")\n",
        "    plt.ylabel(\"Loss/Accuracy\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UI0MZiKY7bUq",
        "outputId": "cb85983e-9d6e-45ad-a768-0cf76774044b"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    # Calcula o tempo de inferência\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Avaliar o modelo nos dados de teste\n",
        "    results = model.evaluate(X_val, y_val)\n",
        "\n",
        "    # Para o cronômetro e salva o tempo de treino\n",
        "    inference_time_gpu_data_augmentation = time.time() - start_time\n",
        "\n",
        "    print(\"Test Loss - GPU - Com Data Augmentation:\", results[0])\n",
        "    print(\"Test Accuracy - GPU - Com Data Augmentation:\", results[1])\n",
        "\n",
        "    # Prever máscaras usando o modelo\n",
        "    predicted_masks = model.predict(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        },
        "id": "R-XPqykm7bUq",
        "outputId": "a94fc6b3-f59d-4d2b-8834-20812ec803e3"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    # Obter métricas de precisão e perda do histórico de treinamento\n",
        "    acc = H.history['custom_accuracy']\n",
        "    val_acc = H.history['val_custom_accuracy']\n",
        "    loss = H.history['loss']\n",
        "    val_loss = H.history['val_loss']\n",
        "\n",
        "    # Número de épocas\n",
        "    epochs = range(1, len(acc) + 1)\n",
        "\n",
        "    # Plotar precisão do conjunto de treino e validação\n",
        "    plt.plot(epochs, acc, 'r', label='Precisão do Conjunto de Treino')\n",
        "    plt.plot(epochs, val_acc, 'b', label='Precisão do Conjunto de Validação')\n",
        "    plt.title('Precisão do Conjunto de Treino e Validação - GPU - Com Data Augmentation')\n",
        "    plt.xlabel('Épocas')\n",
        "    plt.ylabel('Precisão')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Plotar perda do conjunto de treino e validação\n",
        "    plt.plot(epochs, loss, 'r', label='Perda do Conjunto de Treino')\n",
        "    plt.plot(epochs, val_loss, 'b', label='Perda do Conjunto de Validação')\n",
        "    plt.title('Perda do Conjunto de Treino e Validação - GPU - Com Data Augmentation')\n",
        "    plt.xlabel('Épocas')\n",
        "    plt.ylabel('Perda')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        },
        "id": "sykgZ2f27bUr",
        "outputId": "fd1c0784-5661-4e96-8150-2cba31ae11ab"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    print(epochs)\n",
        "    print('Tempo de treino GPU (segundos): ', training_time_gpu_data_augmentation)\n",
        "    print('Tempo de treino GPU por época (segundos): ', training_time_gpu_data_augmentation / max_epochs)\n",
        "    print('Tempo de inferência GPU (segundos): ', inference_time_gpu_data_augmentation)\n",
        "\n",
        "    # Plotando o tempo de treinamento e inferência\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.bar(['GPU Training'], [training_time_gpu], color=['orange'])\n",
        "    plt.bar(['GPU Inference'], [inference_time_gpu], color=['orange'])\n",
        "    plt.ylabel('Time (seconds)')\n",
        "    plt.title('Training and Inference Time - GPU - Com Data Augmentation')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ie8olVfW7bUr"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    # Gerar as saídas do modelo para um conjunto de entradas de teste\n",
        "    saidas_modelo = model.predict(X_val)\n",
        "\n",
        "    # Iterar sobre cada saída do modelo\n",
        "    for i in range(len(X_val)):\n",
        "        # Obter a entrada correspondente e a saída real\n",
        "        img_entrada = X_val[i]\n",
        "        img_saida_real = y_val[i]\n",
        "\n",
        "        # Obter a saída gerada pelo modelo\n",
        "        img_saida_modelo = saidas_modelo[i]\n",
        "\n",
        "        # Mostrar as imagens\n",
        "        plt.figure(figsize=(12, 4))\n",
        "\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.imshow(img_entrada.squeeze(), cmap='gray')\n",
        "        plt.title('Entrada')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.imshow(img_saida_real.squeeze(), cmap='gray')\n",
        "        plt.title('Saída Esperada')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(img_saida_modelo.squeeze(), cmap='gray')\n",
        "        plt.title('Saída do Modelo - GPU - Com Data Augmentation')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9BOPfYL7bUr",
        "outputId": "b04d1eeb-afde-4612-f179-a6a96e43de67"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    # Métricas do parceiro de Projeto:\n",
        "\n",
        "    # Lista para armazenar os scores de IoU\n",
        "    iou_scores = []\n",
        "    # Calcular IoUs e determinar predições corretas\n",
        "    correct_predictions = 0\n",
        "    iou_threshold = 0.5\n",
        "    for mask, result in zip(y_val, img_saida_modelo):\n",
        "        intersection = np.logical_and(mask, result)\n",
        "        union = np.logical_or(mask, result)\n",
        "        iou_score = np.sum(intersection) / np.sum(union) if np.sum(union) != 0 else 0\n",
        "        iou_scores.append(iou_score)\n",
        "        # Verificar se a predição é considerada correta (IoU >= threshold)\n",
        "        if iou_score >= iou_threshold:\n",
        "            correct_predictions += 1\n",
        "        print('IoU é: ' + str(iou_score))\n",
        "    # Calcular a média dos IoUs\n",
        "    iou_mean = np.mean(iou_scores)\n",
        "    print('Média dos IoU - GPU - Com Data Augmentation:', iou_mean)\n",
        "    # Calcular Coverage Ratio (CovR)\n",
        "    total_predictions = len(iou_scores)\n",
        "    covr = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
        "    print('Coverage Ratio (CovR) - GPU - Com Data Augmentation:', covr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKL2Pop3BrKy"
      },
      "source": [
        "# Treino do modelo - CPU - Com Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ra43fjNdBrKz",
        "outputId": "92428750-375e-4268-b64c-d6f74d023205"
      },
      "outputs": [],
      "source": [
        "# Criar modelo U-Net\n",
        "model = Unet(input_shape=(256, 256, 3))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiTd-Ao2BrK0",
        "outputId": "520f085b-2604-463a-d3cf-796898839aeb"
      },
      "outputs": [],
      "source": [
        "callbacks = get_callbacks()\n",
        "with tf.device('/cpu:0'):\n",
        "    # Compilar o modelo\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss=lambda y_train, y_val: combined_loss(y_train, y_val, 0.001), metrics=[custom_accuracy])\n",
        "\n",
        "    # Calcula o tempo de treino\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Definições\n",
        "    max_epochs = 30\n",
        "    batch_size = 16\n",
        "\n",
        "    # Treinar o modelo\n",
        "    H = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=max_epochs, batch_size=batch_size, callbacks=callbacks)\n",
        "\n",
        "    # Para o cronômetro e salva o tempo de treino\n",
        "    training_time_cpu_data_augmentation = time.time() - start_time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2zogG_YBrK0"
      },
      "source": [
        "## Avaliação do modelo - CPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "gixc6dl3BrK0",
        "outputId": "ca648690-7dd5-4ea4-e288-09f906a24512"
      },
      "outputs": [],
      "source": [
        "with tf.device('/cpu:0'):\n",
        "    # Mostrando resultados\n",
        "    plt.style.use(\"ggplot\")\n",
        "    plt.figure()\n",
        "    plt.plot(H.epoch, H.history[\"loss\"], label=\"train_loss\")\n",
        "    plt.plot(H.epoch, H.history[\"val_loss\"], label=\"val_loss\")\n",
        "    plt.plot(H.epoch, H.history[\"custom_accuracy\"], label=\"train_acc\")\n",
        "    plt.plot(H.epoch, H.history[\"val_custom_accuracy\"], label=\"val_acc\")\n",
        "    plt.title(\"Training Loss and Accuracy - CPU - Com Data Augmentation\")\n",
        "    plt.xlabel(\"Epoch #\")\n",
        "    plt.ylabel(\"Loss/Accuracy\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riYQCvuEBrK1",
        "outputId": "a4701663-dc80-47c0-b281-7336661e1407"
      },
      "outputs": [],
      "source": [
        "with tf.device('/cpu:0'):\n",
        "    # Calcula o tempo de inferência\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Avaliar o modelo nos dados de teste\n",
        "    results = model.evaluate(X_val, y_val)\n",
        "\n",
        "    # Para o cronômetro e salva o tempo de treino\n",
        "    inference_time_cpu_data_augmentation = time.time() - start_time\n",
        "\n",
        "    print(\"Test Loss - CPU - Com Data Augmentation:\", results[0])\n",
        "    print(\"Test Accuracy - CPU - Com Data Augmentation:\", results[1])\n",
        "\n",
        "    # Prever máscaras usando o modelo\n",
        "    predicted_masks = model.predict(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        },
        "id": "yyDcaCH8BrK1",
        "outputId": "2c23a5a9-e052-463d-84f7-8576e001e7a9"
      },
      "outputs": [],
      "source": [
        "with tf.device('/cpu:0'):\n",
        "    # Obter métricas de precisão e perda do histórico de treinamento\n",
        "    acc = H.history['custom_accuracy']\n",
        "    val_acc = H.history['val_custom_accuracy']\n",
        "    loss = H.history['loss']\n",
        "    val_loss = H.history['val_loss']\n",
        "\n",
        "    # Número de épocas\n",
        "    epochs = range(1, len(acc) + 1)\n",
        "\n",
        "    # Plotar precisão do conjunto de treino e validação\n",
        "    plt.plot(epochs, acc, 'r', label='Precisão do Conjunto de Treino')\n",
        "    plt.plot(epochs, val_acc, 'b', label='Precisão do Conjunto de Validação')\n",
        "    plt.title('Precisão do Conjunto de Treino e Validação - CPU - Com Data Augmentation')\n",
        "    plt.xlabel('Épocas')\n",
        "    plt.ylabel('Precisão')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Plotar perda do conjunto de treino e validação\n",
        "    plt.plot(epochs, loss, 'r', label='Perda do Conjunto de Treino')\n",
        "    plt.plot(epochs, val_loss, 'b', label='Perda do Conjunto de Validação')\n",
        "    plt.title('Perda do Conjunto de Treino e Validação - CPU - Com Data Augmentation')\n",
        "    plt.xlabel('Épocas')\n",
        "    plt.ylabel('Perda')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "HU6qWtH0BrK1",
        "outputId": "68d75686-5e32-4a64-b139-caf3c1a77828"
      },
      "outputs": [],
      "source": [
        "with tf.device('/cpu:0'):\n",
        "    print('Tempo de treino CPU - Com Data Augmentation (segundos): ', training_time_cpu_data_augmentation)\n",
        "    print('Tempo de treino CPU por época (segundos): ', training_time_cpu_data_augmentation / max_epochs)\n",
        "    print('Tempo de inferência CPU - Com Data Augmentation (segundos): ', inference_time_cpu_data_augmentation)\n",
        "\n",
        "    # Plotando o tempo de treinamento e inferência\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.bar(['CPU Training'], [training_time_cpu], color=['orange'])\n",
        "    plt.bar(['CPU Inference'], [inference_time_cpu], color=['orange'])\n",
        "    plt.ylabel('Time (seconds)')\n",
        "    plt.title('Training and Inference Time')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EBKgMfguBrK2"
      },
      "outputs": [],
      "source": [
        "with tf.device('/cpu:0'):\n",
        "    # Gerar as saídas do modelo para um conjunto de entradas de teste\n",
        "    saidas_modelo = model.predict(X_val)\n",
        "\n",
        "    # Iterar sobre cada saída do modelo\n",
        "    for i in range(len(X_val)):\n",
        "        # Obter a entrada correspondente e a saída real\n",
        "        img_entrada = X_val[i]\n",
        "        img_saida_real = y_val[i]\n",
        "\n",
        "        # Obter a saída gerada pelo modelo\n",
        "        img_saida_modelo = saidas_modelo[i]\n",
        "\n",
        "        # Mostrar as imagens\n",
        "        plt.figure(figsize=(12, 4))\n",
        "\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.imshow(img_entrada.squeeze(), cmap='gray')\n",
        "        plt.title('Entrada')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.imshow(img_saida_real.squeeze(), cmap='gray')\n",
        "        plt.title('Saída Esperada')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(img_saida_modelo.squeeze(), cmap='gray')\n",
        "        plt.title('Saída do Modelo - CPU - Com Data Augmentation')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NQDrrainBrK2",
        "outputId": "c2289c6a-6a01-4219-ba00-faf6bc080ac5"
      },
      "outputs": [],
      "source": [
        "with tf.device('/cpu:0'):\n",
        "    # Métricas do parceiro de Projeto:\n",
        "\n",
        "    # Lista para armazenar os scores de IoU\n",
        "    iou_scores = []\n",
        "    # Calcular IoUs e determinar predições corretas\n",
        "    correct_predictions = 0\n",
        "    iou_threshold = 0.5\n",
        "    for mask, result in zip(y_val, img_saida_modelo):\n",
        "        intersection = np.logical_and(mask, result)\n",
        "        union = np.logical_or(mask, result)\n",
        "        iou_score = np.sum(intersection) / np.sum(union) if np.sum(union) != 0 else 0\n",
        "        iou_scores.append(iou_score)\n",
        "        # Verificar se a predição é considerada correta (IoU >= threshold)\n",
        "        if iou_score >= iou_threshold:\n",
        "            correct_predictions += 1\n",
        "        print('IoU é: ' + str(iou_score))\n",
        "    # Calcular a média dos IoUs\n",
        "    iou_mean = np.mean(iou_scores)\n",
        "    print('Média dos IoU - CPU:', iou_mean)\n",
        "    # Calcular Coverage Ratio (CovR)\n",
        "    total_predictions = len(iou_scores)\n",
        "    covr = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
        "    print('Coverage Ratio (CovR) - CPU:', covr)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "cQl90jW20q1D",
        "3xSP-0NwWdAq",
        "dApijRqyWk_n",
        "_K8INbM9Wpi8",
        "p_XrQw1fWtkp",
        "mOUyygDLvAWU",
        "6OMjPq-V-Ahs"
      ],
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
