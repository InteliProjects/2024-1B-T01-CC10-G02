{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQl90jW20q1D"
      },
      "source": [
        "# Obter dados no drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xMX0kYMziwp",
        "outputId": "1bfff27e-22d2-4a66-a987-6ce92b7c28da"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow_model_optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehPwUJLzSsLC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.config.run_functions_eagerly(True)\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "import time\n",
        "from PIL import Image, ImageDraw\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, Callback\n",
        "from glob import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from keras import layers, regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow_model_optimization.sparsity import keras as sparsity\n",
        "from tensorflow.keras.applications import MobileNetV2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibpCXTgmS_Hi",
        "outputId": "fde8bcf1-e2a1-406c-c901-518309c320b7"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xSP-0NwWdAq"
      },
      "source": [
        "# Carregamento de dados - Sem Data Augmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yz6Rn0h26UVx"
      },
      "outputs": [],
      "source": [
        "images = []\n",
        "masks = []\n",
        "\n",
        "for path in glob('/content/drive/Shared drives/Grupo T de Tech/Data/dataset_inteli/cropped_images/*/*'):\n",
        "  images.append(path + '/image.tif')\n",
        "  masks.append(path + '/mask.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgFIh5hrObFb"
      },
      "outputs": [],
      "source": [
        "# Função para carregar e pré-processar uma imagem e sua máscara\n",
        "def load_and_preprocess_image(image_path, mask_path, target_size):\n",
        "\n",
        "    image = load_img(image_path, target_size=target_size)\n",
        "    image = img_to_array(image) / 255.0  # Normalização entre 0 e 1\n",
        "\n",
        "    mask = load_img(mask_path, target_size=target_size, color_mode='grayscale')\n",
        "    mask = img_to_array(mask) / 255.0  # Normalização entre 0 e 1\n",
        "\n",
        "    return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Qu_4ZJaKOTGF"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    # Lista para armazenar imagens e máscaras pré-processadas\n",
        "    images_processed = []\n",
        "    masks_processed = []\n",
        "\n",
        "    # Carregar e pré-processar todas as imagens e máscaras\n",
        "    for img_path, mask_path in zip(images, masks):\n",
        "        img, mask = load_and_preprocess_image(img_path, mask_path, target_size=(256, 256))\n",
        "        images_processed.append(img)\n",
        "        masks_processed.append(mask)\n",
        "\n",
        "    # Converter para arrays numpy\n",
        "    images_processed = np.array(images_processed)\n",
        "    masks_processed = np.array(masks_processed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kRApOxtFQ3IX",
        "outputId": "4be299fc-b42b-475b-b12d-d102557483f3"
      },
      "outputs": [],
      "source": [
        "images_processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1XJsmj6Iu1W"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(images_processed, masks_processed, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plOtPTyjYugt",
        "outputId": "c7f29c91-6967-4e5f-98b8-f7a44069ad37"
      },
      "outputs": [],
      "source": [
        "images_processed.shape, masks_processed.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dApijRqyWk_n"
      },
      "source": [
        "# Definição de parâmetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JcNGKwDxX94"
      },
      "outputs": [],
      "source": [
        "class CyclicLR(Callback):\n",
        "    def __init__(self, base_lr=1e-4, max_lr=1e-3, step_size=2000., mode='triangular'):\n",
        "        super(CyclicLR, self).__init__()\n",
        "\n",
        "        self.base_lr = base_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.step_size = step_size\n",
        "        self.mode = mode\n",
        "        self.iterations = 0\n",
        "        self.history = {}\n",
        "\n",
        "    def clr(self):\n",
        "        cycle = np.floor(1 + self.iterations / (2 * self.step_size))\n",
        "        x = np.abs(self.iterations / self.step_size - 2 * cycle + 1)\n",
        "        lr = self.base_lr + (self.max_lr - self.base_lr) * max(0, (1 - x))\n",
        "        if self.mode == 'triangular2':\n",
        "            lr = lr / float(2 ** (cycle - 1))\n",
        "        elif self.mode == 'exp_range':\n",
        "            lr = lr * (0.999 ** self.iterations)\n",
        "        return lr\n",
        "\n",
        "    def on_train_begin(self, logs=None):\n",
        "        logs = logs or {}\n",
        "        tf.keras.backend.set_value(self.model.optimizer.lr, self.base_lr)\n",
        "\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        self.iterations += 1\n",
        "        lr = self.clr()\n",
        "        tf.keras.backend.set_value(self.model.optimizer.lr, lr)\n",
        "        self.history.setdefault('lr', []).append(lr)\n",
        "        for k, v in logs.items():\n",
        "            self.history.setdefault(k, []).append(v)\n",
        "\n",
        "# Função de callbacks\n",
        "def get_callbacks():\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
        "    clr = CyclicLR(base_lr=1e-4, max_lr=1e-3, step_size=2000., mode='triangular2')\n",
        "    return [early_stopping, reduce_lr, clr]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZMBQc7JL15q"
      },
      "outputs": [],
      "source": [
        "# Função para calcular a sigmoide e converter para 0 ou 1 o output\n",
        "class ThresholdLayer(tf.keras.layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        return tf.where(inputs < 0.5, 0.0, 1.0)\n",
        "\n",
        "# Função para calcular o Dice Coefficient\n",
        "def dice_coefficient(y_train, y_val):\n",
        "    smooth = 1e-6\n",
        "    intersection = tf.reduce_sum(y_train * y_val)\n",
        "    dice_coefficient = (2. * intersection + smooth) / (tf.reduce_sum(y_train) + tf.reduce_sum(y_val) + smooth)\n",
        "    return dice_coefficient\n",
        "\n",
        "# Função de perda de Dice\n",
        "def dice_loss(y_train, y_val):\n",
        "    return 1 - dice_coefficient(y_train, y_val)\n",
        "\n",
        "# Função para calcular a penalidade adicional\n",
        "def penalty_loss(y_train, y_val, penalty_weight):\n",
        "    # Calcular a penalidade considerando a diferença entre y_train e y_val\n",
        "    penalty = tf.reduce_sum(tf.abs(y_train - y_val))\n",
        "    # Multiplicar a penalidade pelo peso da penalidade\n",
        "    weighted_penalty = penalty_weight * penalty\n",
        "    return weighted_penalty\n",
        "\n",
        "# Função de perda combinada\n",
        "def combined_loss(y_train, y_val, alpha, beta, gamma, penalty_weight):\n",
        "    # Perda padrão (por exemplo, perda de entropia cruzada binária)\n",
        "    standard_loss = tf.keras.losses.binary_crossentropy(y_train, y_val)\n",
        "    dice = dice_loss(y_train, y_val) # Dice Loss\n",
        "    penalty = penalty_loss(y_train, y_val, penalty_weight) # Penalidade adicional\n",
        "    # Perda total = perda padrão + penalidade + Dice Loss\n",
        "    total_loss = alpha * standard_loss + beta * dice + gamma * penalty\n",
        "    return total_loss\n",
        "\n",
        "# Métrica de acurácia customizada\n",
        "def custom_accuracy(y_train, y_val):\n",
        "    # Calcular a acurácia considerando uma tolerância de 0.5 na predição\n",
        "    y_val_binary = tf.round(y_val)\n",
        "    accuracy = tf.reduce_mean(tf.cast(tf.equal(y_train, y_val_binary), tf.float32))\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5btDL6KcqLR8"
      },
      "source": [
        "# Modelo Pré-treinado MobileNetV2\n",
        "\n",
        "O modelo que utilizamos para fazer o transfer learning é o MobileNetV2, que pode ser encontrado o artigo de sua publicação no link:\n",
        "https://doi.org/10.48550/arXiv.1801.04381"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "V6otxFOrpik_",
        "outputId": "555569a3-e370-41c5-f1ef-d98fc1c9eb9a"
      },
      "outputs": [],
      "source": [
        "# Carregar o modelo MobileNetV2 pré-treinado\n",
        "pre_trained_model = MobileNetV2(weights='imagenet', include_top=False)\n",
        "\n",
        "# Visualizar a estrutura do modelo\n",
        "pre_trained_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQzJkyv7qVyy"
      },
      "outputs": [],
      "source": [
        "class UNet:\n",
        "    def __init__(self, input_shape, num_filters, kernel_size, dropout_rate, val_reg):\n",
        "        self.input_shape = input_shape\n",
        "        self.num_filters = num_filters\n",
        "        self.kernel_size = kernel_size\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.val_reg = val_reg\n",
        "\n",
        "    def build_model(self):\n",
        "        inputs = tf.keras.Input(shape=self.input_shape)\n",
        "        reg = regularizers.L2(self.val_reg)\n",
        "\n",
        "        # Encoder (contraction path)\n",
        "        base_model = MobileNetV2(weights='imagenet', include_top=False, input_tensor=inputs)\n",
        "        base_model.trainable = False\n",
        "\n",
        "        # Extract specific layers for connections\n",
        "        conv2 = base_model.get_layer('block_1_expand').output\n",
        "        conv3 = base_model.get_layer('block_3_expand').output\n",
        "        decoded = base_model.get_layer('block_6_expand').output\n",
        "\n",
        "        # Decoder (expansion path)\n",
        "        up5 = layers.Conv2DTranspose(self.num_filters[2], (2, 2), strides=(2, 2), padding='same')(decoded)\n",
        "        merge5 = layers.concatenate([conv3, up5], axis=3)\n",
        "        conv5 = layers.Conv2D(self.num_filters[2], self.kernel_size, activation='relu', padding='same')(merge5)\n",
        "        conv5 = layers.Conv2D(self.num_filters[2], self.kernel_size, activation='relu', padding='same')(conv5)\n",
        "\n",
        "        up6 = layers.Conv2DTranspose(self.num_filters[1], (2, 2), strides=(2, 2), padding='same')(conv5)\n",
        "        merge6 = layers.concatenate([conv2, up6], axis=3)\n",
        "        conv6 = layers.Conv2D(self.num_filters[1], self.kernel_size, activation='relu', padding='same')(merge6)\n",
        "        conv6 = layers.Conv2D(self.num_filters[1], self.kernel_size, activation='relu', padding='same')(conv6)\n",
        "\n",
        "        up7 = layers.Conv2DTranspose(self.num_filters[0], (2, 2), strides=(2, 2), padding='same')(conv6)\n",
        "        conv7 = layers.Conv2D(self.num_filters[0], self.kernel_size, activation='relu', padding='same')(up7)\n",
        "        conv7 = layers.Conv2D(self.num_filters[0], self.kernel_size, activation='relu', padding='same')(conv7)\n",
        "\n",
        "        outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(conv7)  # Saída com um canal (máscara binária)\n",
        "\n",
        "        threshold_output = ThresholdLayer()(outputs)\n",
        "\n",
        "        model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "        return model\n",
        "\n",
        "    def compile_and_train(self, X_train, y_train, X_val, y_val, max_epochs, batch_size, alpha, beta, gamma, penalty_weight):\n",
        "        model = self.build_model()\n",
        "        callbacks = get_callbacks()\n",
        "\n",
        "        # Compilar o modelo\n",
        "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "                      loss=lambda y_train, y_val: combined_loss(y_train, y_val, alpha, beta, gamma, penalty_weight),\n",
        "                      metrics=[custom_accuracy])\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Treinar o modelo\n",
        "        H = model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
        "                      epochs=max_epochs, batch_size=batch_size, callbacks=callbacks)\n",
        "\n",
        "        # Salvar o tempo de treino\n",
        "        training_time_gpu = time.time() - start_time\n",
        "\n",
        "        return H, training_time_gpu, model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loNPT4OttA8L"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, X_val, y_val, H, training_time_gpu, max_epochs):\n",
        "    plt.style.use(\"ggplot\")\n",
        "    plt.figure(figsize=(12, 10))\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    results = model.evaluate(X_val, y_val)\n",
        "\n",
        "    inference_time_gpu = time.time() - start_time\n",
        "\n",
        "    print(\"Test Loss:\", results[0])\n",
        "    print(\"Test Accuracy:\", results[1])\n",
        "\n",
        "    # Prever máscaras usando o modelo\n",
        "    predicted_masks = model.predict(X_val)\n",
        "\n",
        "    # Obter métricas de precisão e perda do treinamento\n",
        "    acc = H.history['custom_accuracy']\n",
        "    val_acc = H.history['val_custom_accuracy']\n",
        "    loss = H.history['loss']\n",
        "    val_loss = H.history['val_loss']\n",
        "\n",
        "    epochs = range(1, len(acc) + 1)\n",
        "\n",
        "    # Plotar precisão do conjunto\n",
        "    plt.subplot(2, 2, 3)\n",
        "    plt.plot(epochs, acc, 'r', label='Precisão do Conjunto de Treino')\n",
        "    plt.plot(epochs, val_acc, 'b', label='Precisão do Conjunto de Validação')\n",
        "    plt.title('Precisão do Conjunto de Treino e Validação')\n",
        "    plt.xlabel('Épocas')\n",
        "    plt.ylabel('Precisão')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plotar perda do conjunto\n",
        "    plt.subplot(2, 2, 4)\n",
        "    plt.plot(epochs, loss, 'r', label='Perda do Conjunto de Treino')\n",
        "    plt.plot(epochs, val_loss, 'b', label='Perda do Conjunto de Validação')\n",
        "    plt.title('Perda do Conjunto de Treino e Validação')\n",
        "    plt.xlabel('Épocas')\n",
        "    plt.ylabel('Perda')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print('Tempo de treino (segundos): ', training_time_gpu)\n",
        "    print('Tempo de treino por época (segundos): ', training_time_gpu / max_epochs)\n",
        "    print('Tempo de inferência (segundos): ', inference_time_gpu)\n",
        "\n",
        "    return predicted_masks, inference_time_gpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hcl0QGvnZjd7"
      },
      "source": [
        "# Estudo de Hiperparâmetros - Função de Perda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KffCqDVWZsbD"
      },
      "source": [
        "Tendo em vista a possibilidade de gerar um treino mais estável e que foque precisamente na tarefa de segmentar talhões, foi conduzido um estudo com Grid Search para encontrar os melhores valores de alfa, beta, gama e penalty_weight, valores estes que compõem a função de perda combinada, sendo alfa o fator multiplicativo da função de perda binary_crossentropy, beta o fator da dice loss e gama o fator da penalidade adicional (penalty_weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "RGkYbGK_Uzt3",
        "outputId": "35c505fb-a283-40aa-caed-7e48550ce61f"
      },
      "outputs": [],
      "source": [
        "# Grid de parâmetros para busca\n",
        "param_grid = {\n",
        "    'alpha': [0.1, 1.0, 10.0],\n",
        "    'beta': [0.1, 1.0],\n",
        "    'gamma': [0.0001, 0.001, 0.01],\n",
        "    'penalty_weight': [0.0001, 0.001]\n",
        "}\n",
        "\n",
        "grid = ParameterGrid(param_grid)\n",
        "\n",
        "max_epochs = 30\n",
        "results = []\n",
        "\n",
        "test_counter = 1\n",
        "H_dict = {}\n",
        "training_time_dict = {}\n",
        "model_dict = {}\n",
        "\n",
        "for params in grid:\n",
        "    print(f'Teste {test_counter}: Testando com parâmetros: {params}')\n",
        "    model = UNet(input_shape=(256, 256, 3),\n",
        "                 num_filters=(16, 32, 64, 128),\n",
        "                 kernel_size = 3,\n",
        "                 dropout_rate=0.1,\n",
        "                 val_reg=0.01)\n",
        "\n",
        "    # Compilar e treinar o modelo com os parâmetros do grid search\n",
        "    H, training_time_gpu, model = model.compile_and_train(X_train, y_train, X_val, y_val,\n",
        "                                                          max_epochs=max_epochs,\n",
        "                                                          batch_size=16,\n",
        "                                                          alpha=params['alpha'],\n",
        "                                                          beta=params['beta'],\n",
        "                                                          gamma=params['gamma'],\n",
        "                                                          penalty_weight=params['penalty_weight'])\n",
        "\n",
        "    H_dict[f'H{test_counter}'] = H\n",
        "    training_time_dict[f'training_time_gpu{test_counter}'] = training_time_gpu\n",
        "    model_dict[f'model{test_counter}'] = model\n",
        "\n",
        "    predicted_masks, inference_time_gpu = evaluate_model(model, X_val, y_val, H, training_time_gpu, max_epochs=max_epochs)\n",
        "    val_loss = H.history['val_loss'][-1]\n",
        "    val_acc = H.history['val_custom_accuracy'][-1]\n",
        "    results.append((params, val_loss, val_acc))\n",
        "    test_counter += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25AWLXwIcogm"
      },
      "source": [
        "Dessa forma, é possível compreender que o teste número 32 possui a maior acurácia, próximo a 84%, com um treinamento estável. As imagens resultantes da predição do modelo podem ser encontradas na seção a seguir.\n",
        "Cabe ressaltar que, com esse teste, a configuração da função de perda será:\n",
        "\n",
        "Teste 32: Testando com parâmetros: {'alpha': 10.0, 'beta': 1.0, 'gamma': 0.0001, 'penalty_weight': 0.001}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUkKiT3jmoXB"
      },
      "source": [
        "# Modelo Final com Transfer Learning - MobileNetV2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RL7cem_ne5is"
      },
      "source": [
        "## Treino e inferência com CPU\n",
        "\n",
        "Para esse teste com a CPU, é preciso apenas alocar uma máquina qualquer no colab, executar as células do início do notebook até o código abaixo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SiaeXSGcmoXJ",
        "outputId": "493ecf37-7a45-42e7-f6ba-e16f48b3d251"
      },
      "outputs": [],
      "source": [
        "max_epochs = 100\n",
        "\n",
        "model = UNet(input_shape=(256, 256, 3),\n",
        "                num_filters=(16, 32, 64, 128),\n",
        "                kernel_size = 3,\n",
        "                dropout_rate=0.1,\n",
        "                val_reg=0.01)\n",
        "\n",
        "# Compilar e treinar o modelo\n",
        "H, training_time_gpu, model = model.compile_and_train(X_train, y_train, X_val, y_val,\n",
        "                                                        max_epochs=max_epochs,\n",
        "                                                        batch_size=16,\n",
        "                                                        alpha=10.0,\n",
        "                                                        beta=1.0,\n",
        "                                                        gamma=0.0001,\n",
        "                                                        penalty_weight=0.001)\n",
        "\n",
        "predicted_masks, inference_time_gpu = evaluate_model(model, X_val, y_val, H, training_time_gpu, max_epochs=max_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNt2sNQFfu4f"
      },
      "source": [
        "## Treino e inferência com GPU\n",
        "Para fazer esse teste conecte uma máquina do colab que possua GPU. Embaixo de compartilhar, no canto superior direito está escrito \"Conect\". Clique na seta para baixo ao lado de conectar. Selecione \"Change runtime type\" e selecione uma máquina que tenha GPU no nome. A que utilizamos foi a T4 GPU. Após isso, execute as células do início do notebook até o código abaixo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mM7vOJJNgZrY"
      },
      "outputs": [],
      "source": [
        "max_epochs = 100\n",
        "\n",
        "model = UNet(input_shape=(256, 256, 3),\n",
        "                num_filters=(16, 32, 64, 128),\n",
        "                kernel_size = 3,\n",
        "                dropout_rate=0.1,\n",
        "                val_reg=0.01)\n",
        "\n",
        "with tf.device('/gpu:0'):\n",
        "    # Compilar e treinar o modelo\n",
        "    H, training_time_gpu, model = model.compile_and_train(X_train, y_train, X_val, y_val,\n",
        "                                                            max_epochs=max_epochs,\n",
        "                                                            batch_size=16,\n",
        "                                                            alpha=10.0,\n",
        "                                                            beta=1.0,\n",
        "                                                            gamma=0.0001,\n",
        "                                                            penalty_weight=0.001)\n",
        "\n",
        "    predicted_masks, inference_time_gpu = evaluate_model(model, X_val, y_val, H, training_time_gpu, max_epochs=max_epochs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sy1DRMN9moXJ"
      },
      "source": [
        "## Amostragem das máscaras e IoU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7F4F5gFY4r6f",
        "outputId": "4d3ac14c-f42d-4b3d-d5ae-83ccecabec90"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    # Gerar as saídas do modelo para um conjunto de entradas de teste\n",
        "    saidas_modelo = model.predict(X_val)\n",
        "\n",
        "    # Iterar sobre cada saída do modelo\n",
        "    for i in range(len(X_val)):\n",
        "        # Obter a entrada correspondente e a saída real\n",
        "        img_entrada = X_val[i]\n",
        "        img_saida_real = y_val[i]\n",
        "\n",
        "        # Obter a saída gerada pelo modelo\n",
        "        #img_saida_modelo1Net = saidas_modelo1Net[i]\n",
        "        img_saida_modelo = np.where(saidas_modelo[i] < 0.5, 0, 1)\n",
        "\n",
        "        # Mostrar as imagens\n",
        "        plt.figure(figsize=(12, 4))\n",
        "\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.imshow(img_entrada.squeeze(), cmap='gray')\n",
        "        plt.title('Entrada')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.imshow(img_saida_real.squeeze(), cmap='gray')\n",
        "        plt.title('Saída Esperada')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(img_saida_modelo.squeeze(), cmap='gray')\n",
        "        plt.title('Saída do Modelo - GPU')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMZy6GoO4r6g",
        "outputId": "a5a9c801-3ae4-4a8d-ab92-97ac0977c9c8"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    # Métricas do parceiro de Projeto:\n",
        "\n",
        "    # Lista para armazenar os scores de IoU\n",
        "    iou_scores = []\n",
        "    # Calcular IoUs e determinar predições corretas\n",
        "    correct_predictions = 0\n",
        "    iou_threshold = 0.5\n",
        "    for mask, result in zip(y_val, saidas_modelo):\n",
        "        intersection = np.logical_and(mask, result)\n",
        "        union = np.logical_or(mask, result)\n",
        "        iou_score = np.sum(intersection) / np.sum(union) if np.sum(union) != 0 else 0\n",
        "        iou_scores.append(iou_score)\n",
        "        # Verificar se a predição é considerada correta (IoU >= threshold)\n",
        "        if iou_score >= iou_threshold:\n",
        "            correct_predictions += 1\n",
        "        print('IoU é: ' + str(iou_score))\n",
        "    # Calcular a média dos IoUs\n",
        "    iou_mean = np.mean(iou_scores)\n",
        "    print('Média dos IoU - GPU:', iou_mean)\n",
        "    # Calcular Coverage Ratio (CovR)\n",
        "    total_predictions = len(iou_scores)\n",
        "    covr = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
        "    print('Coverage Ratio (CovR) - GPU:', covr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IN4iOjzRyQf"
      },
      "source": [
        "# Testes com novas imagens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHX41Bq3R0IH",
        "outputId": "f2081878-2b48-46a1-9355-a097d0d51711"
      },
      "outputs": [],
      "source": [
        "print(\"ola\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSZXJZ0cSBj-"
      },
      "source": [
        "## Importando as imagens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fyAjsjcR2Xm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def load_masks(masks_dir, target_size=(600, 600), crop_size=(200, 200), final_size=(256, 256)):\n",
        "    masks = []\n",
        "    mask_filenames = []\n",
        "    ordered_masks = sorted(os.listdir(masks_dir))\n",
        "    for mask_name in ordered_masks:\n",
        "        mask_path = os.path.join(masks_dir, mask_name)\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if mask is not None:\n",
        "            if mask.shape[:2] != target_size:\n",
        "                mask = cv2.resize(mask, target_size[::-1], interpolation=cv2.INTER_NEAREST)\n",
        "            cropped_masks = crop_image(mask, crop_size)\n",
        "            resized_masks = [cv2.resize(crop, final_size[::-1], interpolation=cv2.INTER_NEAREST) for crop in cropped_masks]\n",
        "            normalized_masks = [crop / 255.0 for crop in resized_masks]\n",
        "            masks.extend(normalized_masks)\n",
        "            mask_filenames.extend([f\"{os.path.splitext(mask_name)[0]}_crop_{i}\" for i in range(len(normalized_masks))])\n",
        "        else:\n",
        "            print(f\"Failed to load mask: {mask_path}\")\n",
        "    return masks, mask_filenames\n",
        "\n",
        "def load_images(image_dir, target_size=(600, 600), crop_size=(200, 200), final_size=(256, 256)):\n",
        "    images = []\n",
        "    image_filenames = []\n",
        "    ordered_images = sorted(os.listdir(image_dir))\n",
        "    for image_name in ordered_images:\n",
        "        image_path = os.path.join(image_dir, image_name)\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is not None:\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            if image.shape[:2] != target_size:\n",
        "                image = cv2.resize(image, target_size[::-1])\n",
        "            cropped_images = crop_image(image, crop_size)\n",
        "            resized_images = [cv2.resize(crop, final_size[::-1]) for crop in cropped_images]\n",
        "            normalized_images = [crop / 255.0 for crop in resized_images]\n",
        "            images.extend(normalized_images)\n",
        "            image_filenames.extend([f\"{os.path.splitext(image_name)[0]}_crop_{i}\" for i in range(len(normalized_images))])\n",
        "        else:\n",
        "            print(f\"Failed to load image: {image_path}\")\n",
        "    return images, image_filenames\n",
        "\n",
        "def crop_image(image, crop_size=(200, 200)):\n",
        "    crops = []\n",
        "    for i in range(0, image.shape[0], crop_size[0]):\n",
        "        for j in range(0, image.shape[1], crop_size[1]):\n",
        "            crop = image[i:i+crop_size[0], j:j+crop_size[1]]\n",
        "            if crop.shape[0] == crop_size[0] and crop.shape[1] == crop_size[1]:\n",
        "                crops.append(crop)\n",
        "    return crops\n",
        "\n",
        "# Paths\n",
        "masks_dir = '/content/drive/Shared drives/Grupo T de Tech/Data/dataset_inteli_test/masks'\n",
        "image_dir = '/content/drive/Shared drives/Grupo T de Tech/Data/dataset_inteli_test/tci_tifs'\n",
        "\n",
        "# Load images and masks\n",
        "masks_test, mask_filenames = load_masks(masks_dir)\n",
        "images_test, image_filenames = load_images(image_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34LhLotgSFBX",
        "outputId": "a70e0ec1-900b-420c-c9c8-c8dfa27218f4"
      },
      "outputs": [],
      "source": [
        "# verificando o tamanho correto\n",
        "len(images_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRDGi9SFSJm-",
        "outputId": "a5393825-e65d-4b98-b4dd-b77cb57250d8"
      },
      "outputs": [],
      "source": [
        "# Ensure the images are in the correct format for model prediction\n",
        "images_test = np.array(images_test)\n",
        "\n",
        "# Gerar as saídas do modelo para um conjunto de entradas de teste\n",
        "saidas_novas_imagens_modelo = model.predict(images_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ttfBzu7USPMR",
        "outputId": "7a7229da-04c5-4c47-afe1-4ce8cdfa60a3"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    # Iterar sobre cada saída do modelo\n",
        "    for i in range(len(images_test)):\n",
        "        # Obter a entrada correspondente e a saída real\n",
        "        img_entrada = images_test[i]\n",
        "        img_saida_real = masks_test[i]\n",
        "\n",
        "        # Obter a saída gerada pelo modelo\n",
        "        img_saida_modelo = saidas_novas_imagens_modelo[i]\n",
        "\n",
        "        # Mostrar as imagens\n",
        "        plt.figure(figsize=(12, 4))\n",
        "\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.imshow(img_entrada.squeeze(), cmap='gray')\n",
        "        plt.title('Entrada')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.imshow(img_saida_real.squeeze(), cmap='gray')\n",
        "        plt.title('Saída Esperada')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(img_saida_modelo.squeeze(), cmap='gray')\n",
        "        plt.title('Saída do Modelo - GPU')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FOtR6fVmL0U",
        "outputId": "2b136312-4645-453c-aa59-8a33f5655d30"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    # Métricas do parceiro de Projeto:\n",
        "\n",
        "    # Lista para armazenar os scores de IoU\n",
        "    iou_scores = []\n",
        "    # Calcular IoUs e determinar predições corretas\n",
        "    correct_predictions = 0\n",
        "    iou_threshold = 0.5\n",
        "    for mask, result in zip(masks_test, saidas_novas_imagens_modelo):\n",
        "        intersection = np.logical_and(mask, result)\n",
        "        union = np.logical_or(mask, result)\n",
        "        iou_score = np.sum(intersection) / np.sum(union) if np.sum(union) != 0 else 0\n",
        "        iou_scores.append(iou_score)\n",
        "        # Verificar se a predição é considerada correta (IoU >= threshold)\n",
        "        if iou_score >= iou_threshold:\n",
        "            correct_predictions += 1\n",
        "        print('IoU é: ' + str(iou_score))\n",
        "    # Calcular a média dos IoUs\n",
        "    iou_mean = np.mean(iou_scores)\n",
        "    print('Média dos IoU - GPU:', iou_mean)\n",
        "    # Calcular Coverage Ratio (CovR)\n",
        "    total_predictions = len(iou_scores)\n",
        "    covr = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
        "    print('Coverage Ratio (CovR) - GPU:', covr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "171dxVAnmZfi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXXRZSPUSwTS"
      },
      "source": [
        "# Avaliação do Modelo com Imagens Desconhecidas\n",
        "\n",
        "Esta seção apresenta os resultados da avaliação do modelo utilizando um conjunto de imagens inéditas, ou seja, imagens que não foram utilizadas durante o treinamento. O objetivo principal é analisar o desempenho e comportamento do modelo frente a dados desconhecidos.\n",
        "\n",
        "A métrica principal utilizada nesta etapa inicial é a Intersection over Union (IoU), a qual será complementada com métricas adicionais na próxima sprint, proporcionando uma análise mais abrangente da performance do modelo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Y9IihD8Sv8Q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def load_masks(masks_dir, target_size=(600, 600), crop_size=(200, 200), final_size=(256, 256)):\n",
        "    \"\"\"\n",
        "    Carrega as máscaras (masks) de segmentação a partir de um diretório.\n",
        "\n",
        "    Args:\n",
        "    masks_dir (str): O diretório contendo as máscaras.\n",
        "    target_size (tuple): Tamanho alvo para redimensionamento inicial.\n",
        "    crop_size (tuple): Tamanho do recorte para segmentação.\n",
        "    final_size (tuple): Tamanho final após redimensionamento.\n",
        "\n",
        "    Returns:\n",
        "    list: Lista de máscaras normalizadas.\n",
        "    list: Lista de nomes de arquivo de máscara correspondentes.\n",
        "    \"\"\"\n",
        "    masks = []\n",
        "    mask_filenames = []\n",
        "    ordered_masks = sorted(os.listdir(masks_dir))\n",
        "    for mask_name in ordered_masks:\n",
        "        mask_path = os.path.join(masks_dir, mask_name)\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if mask is not None:\n",
        "            if mask.shape[:2] != target_size:\n",
        "                mask = cv2.resize(mask, target_size[::-1], interpolation=cv2.INTER_NEAREST)\n",
        "            cropped_masks = crop_image(mask, crop_size)\n",
        "            resized_masks = [cv2.resize(crop, final_size[::-1], interpolation=cv2.INTER_NEAREST) for crop in cropped_masks]\n",
        "            normalized_masks = [crop / 255.0 for crop in resized_masks]\n",
        "            masks.extend(normalized_masks)\n",
        "            mask_filenames.extend([f\"{os.path.splitext(mask_name)[0]}_crop_{i}\" for i in range(len(normalized_masks))])\n",
        "        else:\n",
        "            print(f\"Falha ao carregar a máscara: {mask_path}\")\n",
        "    return masks, mask_filenames\n",
        "\n",
        "def load_images(image_dir, target_size=(600, 600), crop_size=(200, 200), final_size=(256, 256)):\n",
        "    \"\"\"\n",
        "    Carrega as imagens a partir de um diretório.\n",
        "\n",
        "    Args:\n",
        "    image_dir (str): O diretório contendo as imagens.\n",
        "    target_size (tuple): Tamanho alvo para redimensionamento inicial.\n",
        "    crop_size (tuple): Tamanho do recorte para segmentação.\n",
        "    final_size (tuple): Tamanho final após redimensionamento.\n",
        "\n",
        "    Returns:\n",
        "    list: Lista de imagens normalizadas.\n",
        "    list: Lista de nomes de arquivo de imagem correspondentes.\n",
        "    \"\"\"\n",
        "    images = []\n",
        "    image_filenames = []\n",
        "    ordered_images = sorted(os.listdir(image_dir))\n",
        "    for image_name in ordered_images:\n",
        "        image_path = os.path.join(image_dir, image_name)\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is not None:\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            if image.shape[:2] != target_size:\n",
        "                image = cv2.resize(image, target_size[::-1])\n",
        "            cropped_images = crop_image(image, crop_size)\n",
        "            resized_images = [cv2.resize(crop, final_size[::-1]) for crop in cropped_images]\n",
        "            normalized_images = [crop / 255.0 for crop in resized_images]\n",
        "            images.extend(normalized_images)\n",
        "            image_filenames.extend([f\"{os.path.splitext(image_name)[0]}_crop_{i}\" for i in range(len(normalized_images))])\n",
        "        else:\n",
        "            print(f\"Falha ao carregar a imagem: {image_path}\")\n",
        "    return images, image_filenames\n",
        "\n",
        "def crop_image(image, crop_size=(200, 200)):\n",
        "    \"\"\"\n",
        "    Realiza o recorte da imagem em múltiplas partes.\n",
        "\n",
        "    Args:\n",
        "    image (np.array): A imagem a ser recortada.\n",
        "    crop_size (tuple): Tamanho do recorte.\n",
        "\n",
        "    Returns:\n",
        "    list: Lista de partes recortadas da imagem.\n",
        "    \"\"\"\n",
        "    crops = []\n",
        "    for i in range(0, image.shape[0], crop_size[0]):\n",
        "        for j in range(0, image.shape[1], crop_size[1]):\n",
        "            crop = image[i:i+crop_size[0], j:j+crop_size[1]]\n",
        "            if crop.shape[0] == crop_size[0] and crop.shape[1] == crop_size[1]:\n",
        "                crops.append(crop)\n",
        "    return crops\n",
        "\n",
        "# Diretórios\n",
        "masks_dir = '/content/drive/Shared drives/Grupo T de Tech/Data/dataset_inteli_test/masks'\n",
        "image_dir = '/content/drive/Shared drives/Grupo T de Tech/Data/dataset_inteli_test/tci_tifs'\n",
        "\n",
        "# Carregar imagens e máscaras\n",
        "masks_test, mask_filenames = load_masks(masks_dir)\n",
        "images_test, image_filenames = load_images(image_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfSEeFHgUq_B",
        "outputId": "139f933e-7edf-40c8-d30d-af7b1f3d6a90"
      },
      "outputs": [],
      "source": [
        "# Certificando que o conjunto possui o tamanho correto, 3 imagens divididas em 9 partes cada.\n",
        "len(images_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZQh3dacVNJE",
        "outputId": "3675ad31-438d-467b-dda8-322f37e23989"
      },
      "outputs": [],
      "source": [
        "# Converter a lista de imagens em um array numpy para ser usado como entrada para o modelo\n",
        "images_test = np.array(images_test)\n",
        "\n",
        "# Gerar as saídas do modelo para um conjunto de entradas de teste\n",
        "saidas_modelo = model.predict(images_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7ctNDeiiZD3i",
        "outputId": "44094999-7404-4ded-913c-62076f0b84ef"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    # Iterar sobre cada saída do modelo\n",
        "    for i in range(len(images_test)):\n",
        "        # Obter a entrada correspondente e a saída real\n",
        "        img_entrada = images_test[i]\n",
        "        img_saida_real = masks_test[i]\n",
        "\n",
        "        # Obter a saída gerada pelo modelo\n",
        "        img_saida_modelo = saidas_modelo[i]\n",
        "\n",
        "        # Mostrar as imagens\n",
        "        plt.figure(figsize=(12, 4))\n",
        "\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.imshow(img_entrada.squeeze(), cmap='gray')\n",
        "        plt.title('Entrada')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.imshow(img_saida_real.squeeze(), cmap='gray')\n",
        "        plt.title('Saída Esperada')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(img_saida_modelo.squeeze(), cmap='gray')\n",
        "        plt.title('Saída do Modelo - GPU')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlB1PhdEcXe7"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    # Métricas do parceiro de Projeto:\n",
        "\n",
        "    # Lista para armazenar os scores de IoU\n",
        "    iou_scores = []\n",
        "    # Calcular IoUs e determinar predições corretas\n",
        "    correct_predictions = 0\n",
        "    iou_threshold = 0.5\n",
        "    for mask, result in zip(masks_test, saidas_modelo):\n",
        "        intersection = np.logical_and(mask, result)\n",
        "        union = np.logical_or(mask, result)\n",
        "        iou_score = np.sum(intersection) / np.sum(union) if np.sum(union) != 0 else 0\n",
        "        iou_scores.append(iou_score)\n",
        "        # Verificar se a predição é considerada correta (IoU >= threshold)\n",
        "        if iou_score >= iou_threshold:\n",
        "            correct_predictions += 1\n",
        "        print('IoU é: ' + str(iou_score))\n",
        "    # Calcular a média dos IoUs\n",
        "    iou_mean = np.mean(iou_scores)\n",
        "    print('Média dos IoU - GPU:', iou_mean)\n",
        "    # Calcular Coverage Ratio (CovR)\n",
        "    total_predictions = len(iou_scores)\n",
        "    covr = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
        "    print('Coverage Ratio (CovR) - GPU:', covr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HIdTkYwaTSC"
      },
      "source": [
        "Podemos observar que o conjunto de imagens novo teve um ganho relativo até se comparado com as de validação e treino. Cerca de um crescimento de 7 pontos percentuais."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zbr9ZHsdDNcT"
      },
      "source": [
        "# Pós-processamento de Imagens: Operações Morfológicas e CRFs\n",
        "\n",
        "No pós-processamento de imagens, buscamos aprimorar os resultados de segmentação inicial, tornando-os mais precisos e visualmente coerentes. Duas técnicas comuns utilizadas para esse fim são as **operações morfológicas** e os **Campos Aleatórios Condicionais (CRFs)**. Este documento explora essas técnicas, seus fundamentos teóricos, benefícios e aplicações.\n",
        "\n",
        "## Operações Morfológicas\n",
        "\n",
        "Operações morfológicas são técnicas de processamento de imagem que se baseiam na forma ou estrutura de objetos dentro de uma imagem. Utilizando um elemento estruturante, essas operações podem modificar a geometria de regiões binárias da imagem para eliminar ruídos ou destacar características específicas.\n",
        "\n",
        "### Tipos de Operações\n",
        "\n",
        "1. **Erosão**: Remove pixels nas bordas dos objetos.\n",
        "2. **Dilatação**: Adiciona pixels às bordas dos objetos.\n",
        "3. **Abertura**: Erosão seguida de dilatação, útil para remover pequenos objetos.\n",
        "4. **Fechamento**: Dilatação seguida de erosão, útil para fechar pequenos buracos.\n",
        "\n",
        "### Benefícios\n",
        "\n",
        "- **Redução de Ruído**: Abertura e fechamento são eficazes na eliminação de pequenos ruídos sem alterar significativamente a forma dos objetos.\n",
        "- **Suavização de Bordas**: Dilatação e erosão podem suavizar bordas irregulares, melhorando a qualidade visual da segmentação.\n",
        "  \n",
        "Para mais detalhes sobre operações morfológicas, consulte o artigo que utilizamos como base: [Understanding Morphological Image Processing and its Operations](https://towardsdatascience.com/understanding-morphological-image-processing-and-its-operations-7bcf1ed11756).\n",
        "\n",
        "## Campos Aleatórios Condicionais (CRFs)\n",
        "\n",
        "Os CRFs são modelos gráficos não direcionados que consideram as dependências entre pixels vizinhos para melhorar a segmentação de imagens. Diferente de outros classificadores, os CRFs são discriminativos e consideram as relações espaciais entre os pixels.\n",
        "\n",
        "### Tipos de CRFs\n",
        "\n",
        "1. **Linear CRF**: Adequado para sequências lineares, como texto.\n",
        "2. **Grid CRF**: Conecta cada pixel aos seus vizinhos imediatos em uma grade.\n",
        "3. **Dense CRF**: Conecta cada pixel a todos os outros pixels, ideal para capturar relações de longo alcance.\n",
        "\n",
        "### Benefícios\n",
        "\n",
        "- **Aprimoramento de Bordas**: CRFs são eficazes na recuperação de bordas suaves e contornos detalhados em imagens segmentadas.\n",
        "- **Redução de Ambiguidade**: Considerando a vizinhança, os CRFs ajudam a resolver ambiguidades na classificação de pixels.\n",
        "\n",
        "O uso de CRFs densos é particularmente notável pela sua eficiência e precisão, conforme descrito no artigo \"Efficient Inference in Fully Connected CRFs with Gaussian Edge Potentials\" por Krähenbühl e Koltun. Para um estudo detalhado, consulte o artigo: [Dense Conditional Random Field](https://medium.com/lis-computer-vision-blogs/dense-conditional-random-field-dfdeb6655005).\n",
        "\n",
        "### Referências\n",
        "\n",
        "- DHAWAN, Aashish; BODANI, Pankaj; GARG, Vishal. Post Processing of Image Segmentation using Conditional Random Fields. 2019. Disponível em: [ResearchGate](https://www.researchgate.net/publication/355020007_Post_Processing_of_Image_Segmentation_using_Conditional_Random_Fields).\n",
        "- Towards Data Science. Understanding Morphological Image Processing and its Operations. Disponível em: [Medium](https://towardsdatascience.com/understanding-morphological-image-processing-and-its-operations-7bcf1ed11756).\n",
        "- LIS Computer Vision Blogs. Dense Conditional Random Field. Disponível em: [Medium](https://medium.com/lis-computer-vision-blogs/dense-conditional-random-field-dfdeb6655005)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9GHwiagDP2x",
        "outputId": "f3f0f8c6-a244-47fe-fe7f-f8ef8562e85e"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/lucasb-eyer/pydensecrf.git\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import jaccard_score\n",
        "import pydensecrf.densecrf as dcrf\n",
        "from pydensecrf.utils import unary_from_softmax, create_pairwise_bilateral"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohZYL836aTSC"
      },
      "source": [
        "## GridSerach\n",
        "\n",
        "\n",
        "Abaixo, implementamos uma técnica de GridSearch para encontrar os melhores parâmetros para o algoritmo de CRF e para as operações morfológicas. Utilizamos a métrica de **Jaccard Score**, também conhecida como **Intersection Over Union (IoU)**, para avaliar os hiperparâmetros que proporcionam os melhores resultados.\n",
        "\n",
        "### Métrica de Avaliação: Jaccard Score (IoU)\n",
        "A métrica **Jaccard Score** é amplamente utilizada na avaliação de segmentação de imagens, pois mede a similaridade entre os conjuntos previstos e os conjuntos reais. É calculada como a razão entre a interseção e a união dos conjuntos, proporcionando uma medida clara de precisão.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6tnniH2EJ6D",
        "outputId": "60a707d3-5196-4689-962d-4f7db7d35f20"
      },
      "outputs": [],
      "source": [
        "pip install tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6iWFujqaTSD"
      },
      "source": [
        "### Gridsearch para encontrar os melhores parâmetros de CRF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qk2_ZxvvqDQi"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def postprocess_mask_with_crf(image, mask, crf_params):\n",
        "    softmax = np.stack([1 - mask, mask], axis=-1)\n",
        "    softmax = np.ascontiguousarray(softmax.transpose(2, 0, 1))\n",
        "    image = np.ascontiguousarray(image)\n",
        "    image_uint8 = (image * 255).astype(np.uint8)\n",
        "    d = dcrf.DenseCRF2D(image.shape[1], image.shape[0], 2)\n",
        "    unary = unary_from_softmax(softmax)\n",
        "    d.setUnaryEnergy(unary)\n",
        "    d.addPairwiseGaussian(sxy=crf_params['sxy'], compat=crf_params['compat'])\n",
        "    d.addPairwiseBilateral(sxy=crf_params['sxy_bilateral'], srgb=crf_params['srgb'], rgbim=image_uint8, compat=crf_params['compat_bilateral'])\n",
        "    Q = d.inference(5)\n",
        "    refined_mask = np.argmax(Q, axis=0).reshape((image.shape[0], image.shape[1]))\n",
        "    return refined_mask / 255.0\n",
        "\n",
        "def calculate_iou(true_mask, pred_mask):\n",
        "    true_mask_bin = (true_mask > 0).astype(np.uint8)\n",
        "    pred_mask_bin = (pred_mask > 0).astype(np.uint8)\n",
        "    return jaccard_score(true_mask_bin.flatten(), pred_mask_bin.flatten(), average='binary')\n",
        "\n",
        "# Espaço de busca de hiperparâmetros do CRF\n",
        "# crf_param_grid = {\n",
        "#     'sxy': [1, 3, 5],\n",
        "#     'compat': [3, 5, 10],\n",
        "#     'sxy_bilateral': [49, 81],\n",
        "#     'srgb': [3, 10, 13],\n",
        "#     'compat_bilateral': [3, 10, 20]\n",
        "# }\n",
        "\n",
        "# best_iou_crf = 0\n",
        "# best_crf_params = None\n",
        "\n",
        "# # Calcular o número total de iterações para CRF\n",
        "# total_iterations_crf = (len(crf_param_grid['sxy']) * len(crf_param_grid['compat']) *\n",
        "#                         len(crf_param_grid['sxy_bilateral']) * len(crf_param_grid['srgb']) *\n",
        "#                         len(crf_param_grid['compat_bilateral']))\n",
        "\n",
        "# # Realizar busca em grade para encontrar os melhores hiperparâmetros do CRF\n",
        "# with tqdm(total=total_iterations_crf, desc=\"Grid Search CRF\") as pbar:\n",
        "#     for sxy in crf_param_grid['sxy']:\n",
        "#         for compat in crf_param_grid['compat']:\n",
        "#             for sxy_bilateral in crf_param_grid['sxy_bilateral']:\n",
        "#                 for srgb in crf_param_grid['srgb']:\n",
        "#                     for compat_bilateral in crf_param_grid['compat_bilateral']:\n",
        "#                         crf_params = {\n",
        "#                             'sxy': sxy,\n",
        "#                             'compat': compat,\n",
        "#                             'sxy_bilateral': sxy_bilateral,\n",
        "#                             'srgb': srgb,\n",
        "#                             'compat_bilateral': compat_bilateral\n",
        "#                         }\n",
        "#                         # Aplicar pós-processamento e calcular IoU\n",
        "#                         iou_scores = []\n",
        "#                         for i in range(len(saidas_modelo)):\n",
        "#                             refined_mask = postprocess_mask_with_crf(images_test[i], saidas_modelo[i].squeeze(), crf_params)\n",
        "#                             iou = calculate_iou(masks_test[i], refined_mask)\n",
        "#                             iou_scores.append(iou)\n",
        "#                         avg_iou = np.mean(iou_scores)\n",
        "#                         if avg_iou > best_iou_crf:\n",
        "#                             best_iou_crf = avg_iou\n",
        "#                             best_crf_params = crf_params\n",
        "#                         pbar.update(1)\n",
        "\n",
        "# print(\"Melhores parâmetros CRF:\", best_crf_params)\n",
        "# print(\"Melhor IoU CRF:\", best_iou_crf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SQ_ebz8RkS_"
      },
      "source": [
        "#### Aplicando apenas CRF e comparando a qualidade da imagem\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHF1GMouRqeQ"
      },
      "outputs": [],
      "source": [
        "best_crf_params = {\n",
        "    'sxy': 5,\n",
        "    'compat': 3,\n",
        "    'sxy_bilateral': 81,\n",
        "    'srgb': 10,\n",
        "    'compat_bilateral': 20\n",
        "}\n",
        "\n",
        "# Pós-processar as máscaras preditas com CRF denso\n",
        "saidas_modelo_postprocessed_with_best_crf = np.array([postprocess_mask_with_crf(images_test[i], saidas_modelo[i].squeeze(), best_crf_params) for i in range(len(saidas_modelo))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0f16P35SgcB",
        "outputId": "a36d362c-3091-4124-97dc-2914633ee2f8"
      },
      "outputs": [],
      "source": [
        "# Converter as máscaras de teste para binário (0 e 1)\n",
        "masks_test_binary = (np.array(masks_test) > 0).astype(np.uint8)\n",
        "saidas_modelo_postprocessed_with_best_crf_binary = (saidas_modelo_postprocessed_with_best_crf > 0).astype(np.uint8)\n",
        "\n",
        "# Calcular Jaccard Score\n",
        "jaccard_scores = [jaccard_score(masks_test_binary[i].flatten(), saidas_modelo_postprocessed_with_best_crf_binary[i].flatten(), average='binary') for i in range(len(masks_test))]\n",
        "print(f\"Jaccard Score: {np.mean(jaccard_scores)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xQ6S5lY2T1fH",
        "outputId": "555a70e5-1f67-4509-d9c7-9bf7b0ae0752"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    # Iterar sobre cada saída do modelo\n",
        "    for i in range(len(images_test)):\n",
        "        # Obter a entrada correspondente e a saída real\n",
        "        img_entrada = masks_test[i]\n",
        "        img_saida_real = saidas_modelo[i]\n",
        "\n",
        "        # Obter a saída gerada pelo modelo\n",
        "        img_saida_modelo = saidas_modelo_postprocessed_with_best_crf[i]\n",
        "\n",
        "        # Mostrar as imagens\n",
        "        plt.figure(figsize=(12, 4))\n",
        "\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.imshow(img_entrada.squeeze(), cmap='gray')\n",
        "        plt.title('saida real')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.imshow(img_saida_real.squeeze(), cmap='gray')\n",
        "        plt.title('Saída modelo')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(img_saida_modelo.squeeze(), cmap='gray')\n",
        "        plt.title('Saída do Modelo - pós')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4B0ueNrIaTSE"
      },
      "source": [
        "### Gridsearch para encontrar os melhores operações morfológicas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjFNo_6dvERW"
      },
      "outputs": [],
      "source": [
        "from skimage.morphology import erosion, dilation, opening, closing, remove_small_objects, disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fyIyL8o7zli",
        "outputId": "8d61b6c0-f528-477b-9451-6170f8a864e3"
      },
      "outputs": [],
      "source": [
        "# Cálculo para operações morfológicas\n",
        "def postprocess_mask_with_morphology(mask, morph_params):\n",
        "    refined_mask = (mask * 255).astype(np.uint8)\n",
        "    kernel = cv2.getStructuringElement(morph_params['shape'], morph_params['kernel_size'])\n",
        "\n",
        "    if morph_params['operation'] == 'open':\n",
        "        refined_mask = cv2.morphologyEx(refined_mask, cv2.MORPH_OPEN, kernel, iterations=morph_params['iterations'])\n",
        "    elif morph_params['operation'] == 'close':\n",
        "        refined_mask = cv2.morphologyEx(refined_mask, cv2.MORPH_CLOSE, kernel, iterations=morph_params['iterations'])\n",
        "    elif morph_params['operation'] == 'dilate':\n",
        "        refined_mask = cv2.dilate(refined_mask, kernel, iterations=morph_params['iterations'])\n",
        "    elif morph_params['operation'] == 'erode':\n",
        "        refined_mask = cv2.erode(refined_mask, kernel, iterations=morph_params['iterations'])\n",
        "\n",
        "    # Remover pequenos componentes conectados\n",
        "    refined_mask = remove_small_objects(refined_mask > 0, min_size=64).astype(np.uint8)\n",
        "\n",
        "    return refined_mask / 255.0\n",
        "\n",
        "def calculate_iou(true_mask, pred_mask):\n",
        "    true_mask_bin = (true_mask > 0).astype(np.uint8)\n",
        "    pred_mask_bin = (pred_mask > 0).astype(np.uint8)\n",
        "    return jaccard_score(true_mask_bin.flatten(), pred_mask_bin.flatten(), average='binary')\n",
        "\n",
        "# Espaço de busca de hiperparâmetros das operações morfológicas\n",
        "morph_param_grid = {\n",
        "    'kernel_size': [(3, 3), (5, 5), (7, 7)],\n",
        "    'iterations': [1, 2, 3],\n",
        "    'operation': ['open', 'close', 'dilate', 'erode'],\n",
        "    'shape': [cv2.MORPH_RECT, cv2.MORPH_ELLIPSE, cv2.MORPH_CROSS]\n",
        "}\n",
        "\n",
        "# best_iou_morph = 0\n",
        "# best_morph_params = None\n",
        "\n",
        "# # Calcular o número total de iterações para operações morfológicas\n",
        "# total_iterations_morph = (len(morph_param_grid['kernel_size']) * len(morph_param_grid['iterations']) *\n",
        "#                           len(morph_param_grid['operation']) * len(morph_param_grid['shape']))\n",
        "\n",
        "# # Realizar busca em grade para encontrar os melhores hiperparâmetros das operações morfológicas\n",
        "# with tqdm(total=total_iterations_morph, desc=\"Grid Search Morph\") as pbar:\n",
        "#     for kernel_size in morph_param_grid['kernel_size']:\n",
        "#         for iterations in morph_param_grid['iterations']:\n",
        "#             for operation in morph_param_grid['operation']:\n",
        "#                 for shape in morph_param_grid['shape']:\n",
        "#                     morph_params = {\n",
        "#                         'kernel_size': kernel_size,\n",
        "#                         'iterations': iterations,\n",
        "#                         'operation': operation,\n",
        "#                         'shape': shape\n",
        "#                     }\n",
        "#                     # Aplicar pós-processamento e calcular IoU\n",
        "#                     iou_scores = []\n",
        "#                     for i in range(len(saidas_modelo)):\n",
        "#                         refined_mask_crf = postprocess_mask_with_crf(images_test[i], saidas_modelo[i].squeeze(), best_crf_params)\n",
        "#                         refined_mask = postprocess_mask_with_morphology(refined_mask_crf, morph_params)\n",
        "#                         iou = calculate_iou(masks_test[i], refined_mask)\n",
        "#                         iou_scores.append(iou)\n",
        "#                     avg_iou = np.mean(iou_scores)\n",
        "#                     if avg_iou > best_iou_morph:\n",
        "#                         best_iou_morph = avg_iou\n",
        "#                         best_morph_params = morph_params\n",
        "#                     pbar.update(1)\n",
        "\n",
        "# print(\"Melhores parâmetros de Morfologia:\", best_morph_params)\n",
        "# print(\"Melhor IoU Morph:\", best_iou_morph)\n",
        "\n",
        "# Teste: Operação Morfológica Antes ou Depois do CRF\n",
        "iou_scores_before_crf = []\n",
        "iou_scores_after_crf = []\n",
        "\n",
        "for i in range(len(saidas_modelo)):\n",
        "    # Aplicar operação morfológica antes do CRF\n",
        "    morph_mask_before_crf = postprocess_mask_with_morphology(saidas_modelo[i].squeeze(), best_morph_params)\n",
        "    refined_mask_before_crf = postprocess_mask_with_crf(images_test[i], morph_mask_before_crf, best_crf_params)\n",
        "    iou_before_crf = calculate_iou(masks_test[i], refined_mask_before_crf)\n",
        "    iou_scores_before_crf.append(iou_before_crf)\n",
        "\n",
        "    # Aplicar operação morfológica depois do CRF\n",
        "    refined_mask_crf = postprocess_mask_with_crf(images_test[i], saidas_modelo[i].squeeze(), best_crf_params)\n",
        "    morph_mask_after_crf = postprocess_mask_with_morphology(refined_mask_crf, best_morph_params)\n",
        "    iou_after_crf = calculate_iou(masks_test[i], morph_mask_after_crf)\n",
        "    iou_scores_after_crf.append(iou_after_crf)\n",
        "\n",
        "avg_iou_before_crf = np.mean(iou_scores_before_crf)\n",
        "avg_iou_after_crf = np.mean(iou_scores_after_crf)\n",
        "\n",
        "print(\"IoU Médio - Operação Morfológica Antes do CRF:\", avg_iou_before_crf)\n",
        "print(\"IoU Médio - Operação Morfológica Depois do CRF:\", avg_iou_after_crf)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIzaVhJmjJYZ"
      },
      "outputs": [],
      "source": [
        "# Definições das funções adicionais para melhorias\n",
        "def apply_median_filter(mask, kernel_size=3):\n",
        "    return cv2.medianBlur((mask * 255).astype(np.uint8), kernel_size) / 255.0\n",
        "\n",
        "def apply_canny_edge_detection(image):\n",
        "    edges = cv2.Canny((image * 255).astype(np.uint8), 100, 200)\n",
        "    return edges / 255.0\n",
        "\n",
        "def apply_threshold(mask, threshold=0.5):\n",
        "    return (mask > threshold).astype(np.uint8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoZL0OC2WqFH"
      },
      "source": [
        "#### Avaliando operações morfológicas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AOf6DxLWy1S"
      },
      "outputs": [],
      "source": [
        "best_morph_params = {\n",
        "    'kernel_size': (3,3),\n",
        "    'iterations': 1,\n",
        "    'operation': 'erode',\n",
        "    'shape': cv2.MORPH_CROSS\n",
        "}\n",
        "\n",
        "# Pós-processar as máscaras preditas com CRF denso\n",
        "saidas_modelo_postprocessed_with_morphology = np.array([postprocess_mask_with_morphology(saidas_modelo[i].squeeze(), best_morph_params) for i in range(len(saidas_modelo))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RG7MmIL-Wy1c",
        "outputId": "d3c22b57-f390-4abe-d4e9-a5660341330a"
      },
      "outputs": [],
      "source": [
        "# Converter as máscaras de teste para binário (0 e 1)\n",
        "saidas_modelo_postprocessed_with_morphology_binary = (saidas_modelo_postprocessed_with_morphology > 0).astype(np.uint8)\n",
        "\n",
        "# Calcular Jaccard Score\n",
        "jaccard_scores = [jaccard_score(masks_test_binary[i].flatten(), saidas_modelo_postprocessed_with_morphology_binary[i].flatten(), average='binary') for i in range(len(masks_test))]\n",
        "print(f\"Jaccard Score: {np.mean(jaccard_scores)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCnXQ9vaZT7A"
      },
      "source": [
        "## Pós processamento completo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQgErWgMZXLR"
      },
      "outputs": [],
      "source": [
        "def morphology_then_crf(image, mask, morph_params, crf_params):\n",
        "    morph_mask = postprocess_mask_with_morphology(mask, morph_params)\n",
        "    refined_mask = postprocess_mask_with_crf(image, morph_mask, crf_params)\n",
        "    return refined_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkwNOACRZxwj"
      },
      "outputs": [],
      "source": [
        "# Pós-processar as máscaras preditas com CRF denso\n",
        "saidas_modelo_postprocessed = np.array([morphology_then_crf(images_test[i], saidas_modelo[i].squeeze(), best_morph_params, best_crf_params) for i in range(len(saidas_modelo))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOzY53pjaEqz",
        "outputId": "efedbb83-e823-4e75-8ed6-dd004b1d9aec"
      },
      "outputs": [],
      "source": [
        "# Converter as máscaras de teste para binário (0 e 1)\n",
        "saidas_modelo_postprocessed_binary = (saidas_modelo_postprocessed > 0).astype(np.uint8)\n",
        "\n",
        "# Calcular Jaccard Score\n",
        "jaccard_scores = [jaccard_score(masks_test_binary[i].flatten(), saidas_modelo_postprocessed_binary[i].flatten(), average='binary') for i in range(len(masks_test))]\n",
        "print(f\"Jaccard Score: {np.mean(jaccard_scores)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqGzVT2gaTSF"
      },
      "source": [
        "Ao avaliarmos a saída das imagens do modelo, percebemos que, para as próximas sprints, há necessidade de um refinamento maior do algoritmo de CRF e uma melhora circunstancial da máscara predita pelo modelo, permitindo alcançarmos um maior nível de generalização para o modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "U4JQ2b0nqNnW",
        "outputId": "4d3b7317-1f84-4e1b-afe4-570ca777c56c"
      },
      "outputs": [],
      "source": [
        "# Aplicar melhorias adicionais após CRF e operações morfológicas\n",
        "improved_masks = [apply_median_filter(mask) for mask in saidas_modelo_postprocessed]\n",
        "improved_masks = [apply_canny_edge_detection(mask) for mask in improved_masks]\n",
        "improved_masks = [apply_threshold(mask) for mask in improved_masks]\n",
        "\n",
        "# Visualizar resultados\n",
        "for i in range(len(images_test)):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(images_test[i].squeeze(), cmap='gray')\n",
        "    plt.title('Entrada')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(masks_test[i].squeeze(), cmap='gray')\n",
        "    plt.title('Saída Esperada')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(improved_masks[i].squeeze(), cmap='gray')\n",
        "    plt.title('Saída Pós-processada')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjEWVkaajUPZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Visualizar resultados\n",
        "overlaid_images = [overlay_mask(images_test[i], improved_masks[i]) for i in range(len(images_test))]\n",
        "\n",
        "for i in range(len(images_test)):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(images_test[i].squeeze(), cmap='gray')\n",
        "    plt.title('Entrada')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(masks_test[i].squeeze(), cmap='gray')\n",
        "    plt.title('Saída Esperada')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(overlaid_images[i])\n",
        "    plt.title('Saída Pós-processada')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XydFhgJQaPpc"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    # Iterar sobre cada saída do modelo\n",
        "    for i in range(len(images_test)):\n",
        "        # Obter a entrada correspondente e a saída real\n",
        "        img_entrada = masks_test[i]\n",
        "        img_saida_real = saidas_modelo[i]\n",
        "\n",
        "        # Obter a saída gerada pelo modelo\n",
        "        img_saida_modelo = saidas_modelo_postprocessed[i]\n",
        "\n",
        "        # Mostrar as imagens\n",
        "        plt.figure(figsize=(12, 4))\n",
        "\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.imshow(img_entrada.squeeze(), cmap='gray')\n",
        "        plt.title('saida real')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.imshow(img_saida_real.squeeze(), cmap='gray')\n",
        "        plt.title('Saída modelo')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(img_saida_modelo.squeeze(), cmap='gray')\n",
        "        plt.title('Saída do Modelo - pós')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6Oxp8I9cibS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1fNtBmKk1nD"
      },
      "source": [
        "## TESTE COM MODELOS DE TREINO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2BNmSfGQk3eD"
      },
      "outputs": [],
      "source": [
        "# Gerar as saídas do modelo para um conjunto de entradas de teste\n",
        "saidas_modelo_treino = model.predict(X_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NCx6XT1k-nq"
      },
      "outputs": [],
      "source": [
        "# Pós-processar as máscaras preditas com CRF denso\n",
        "imagens_treino_postprocessed = np.array([morphology_then_crf(X_val[i], saidas_modelo_treino[i].squeeze(), best_morph_params, best_crf_params) for i in range(len(saidas_modelo_treino))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrH-CslJk-n0"
      },
      "outputs": [],
      "source": [
        "# Converter as máscaras de teste para binário (0 e 1)\n",
        "masks_treino = (np.array(y_val) > 0).astype(np.uint8)\n",
        "imagens_treino_postprocessed_binary = (np.array(X_val) > 0).astype(np.uint8)\n",
        "\n",
        "# Calcular Jaccard Score\n",
        "jaccard_scores = [jaccard_score(masks_treino[i].flatten(), imagens_treino_postprocessed_binary[i].flatten(), average='binary') for i in range(len(masks_treino))]\n",
        "print(f\"Jaccard Score: {np.mean(jaccard_scores)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHSk6asZnGbr"
      },
      "outputs": [],
      "source": [
        "X_val.shape, y_val.shape, imagens_treino_postprocessed.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hB3-Vtw0k-n1"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    # Iterar sobre cada saída do modelo\n",
        "    for i in range(len(X_val)):\n",
        "        # Obter a entrada correspondente e a saída real\n",
        "        img_entrada = X_val[i]\n",
        "        img_saida_real = y_val[i]\n",
        "\n",
        "        # Obter a saída gerada pelo modelo\n",
        "        img_saida_modelo = saidas_modelo_treino[i]\n",
        "        img_saida_modelo_post = imagens_treino_postprocessed[i]\n",
        "\n",
        "        # Mostrar as imagens\n",
        "        plt.figure(figsize=(12, 4))\n",
        "\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.imshow(img_saida_real.squeeze(), cmap='gray')\n",
        "        plt.title('Saída Esperada')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.imshow(img_saida_modelo.squeeze(), cmap='gray')\n",
        "        plt.title('Saída Modelo')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(img_saida_modelo_post.squeeze(), cmap='gray')\n",
        "        plt.title('Saída do Modelo - PÓS')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgFlBHyUk-n1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "cQl90jW20q1D",
        "3xSP-0NwWdAq"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
