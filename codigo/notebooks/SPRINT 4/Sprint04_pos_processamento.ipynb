{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modelo implantado na sprint 3 \n",
        "\n",
        "Abaixo estamos executando o mesmo modelo que a Sprint 3. A ideia principal é predizer novas imagens com o dataset novo [dataset_inteli_test]()."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQl90jW20q1D"
      },
      "source": [
        "\n",
        "## Obter dados no drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehPwUJLzSsLC"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "import time\n",
        "from PIL import Image, ImageDraw\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "tf.config.run_functions_eagerly(True)\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, Callback\n",
        "from glob import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from keras import layers, models, Input, regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibpCXTgmS_Hi",
        "outputId": "f3dbe420-0d87-40da-dd74-e5b05170bab6"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xSP-0NwWdAq"
      },
      "source": [
        "## Carregamento de dados - Sem Data Augmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yz6Rn0h26UVx"
      },
      "outputs": [],
      "source": [
        "images = []\n",
        "masks = []\n",
        "\n",
        "for path in glob('/content/drive/Shared drives/Grupo T de Tech/Data/dataset_inteli/cropped_images/*/*'):\n",
        "  images.append(path + '/image.tif')\n",
        "  masks.append(path + '/mask.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgFIh5hrObFb"
      },
      "outputs": [],
      "source": [
        "# Função para carregar e pré-processar uma imagem e sua máscara\n",
        "def load_and_preprocess_image(image_path, mask_path, target_size):\n",
        "\n",
        "    image = load_img(image_path, target_size=target_size)\n",
        "    image = img_to_array(image) / 255.0  # Normalização entre 0 e 1\n",
        "\n",
        "    mask = load_img(mask_path, target_size=target_size, color_mode='grayscale')\n",
        "    mask = img_to_array(mask) / 255.0  # Normalização entre 0 e 1\n",
        "\n",
        "    return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Qu_4ZJaKOTGF",
        "outputId": "d7658194-a7b5-44a1-d835-ee22c05bba94"
      },
      "outputs": [],
      "source": [
        "# Lista para armazenar imagens e máscaras pré-processadas\n",
        "images_processed = []\n",
        "masks_processed = []\n",
        "\n",
        "count = 1\n",
        "# Carregar e pré-processar todas as imagens e máscaras\n",
        "for img_path, mask_path in zip(images, masks):\n",
        "    print(count)\n",
        "    count += 1\n",
        "    img, mask = load_and_preprocess_image(img_path, mask_path, target_size=(256, 256))\n",
        "    images_processed.append(img)\n",
        "    masks_processed.append(mask)\n",
        "\n",
        "# Converter para arrays numpy\n",
        "images_processed = np.array(images_processed)\n",
        "masks_processed = np.array(masks_processed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kRApOxtFQ3IX",
        "outputId": "1df6ea28-3cea-42e8-e17c-0803f19b563d"
      },
      "outputs": [],
      "source": [
        "images_processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1XJsmj6Iu1W"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(images_processed, masks_processed, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dApijRqyWk_n"
      },
      "source": [
        "## Definição de parâmetros e modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JcNGKwDxX94"
      },
      "outputs": [],
      "source": [
        "class CyclicLR(Callback):\n",
        "    def __init__(self, base_lr=1e-4, max_lr=1e-3, step_size=2000., mode='triangular'):\n",
        "        super(CyclicLR, self).__init__()\n",
        "\n",
        "        self.base_lr = base_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.step_size = step_size\n",
        "        self.mode = mode\n",
        "        self.iterations = 0\n",
        "        self.history = {}\n",
        "\n",
        "    def clr(self):\n",
        "        cycle = np.floor(1 + self.iterations / (2 * self.step_size))\n",
        "        x = np.abs(self.iterations / self.step_size - 2 * cycle + 1)\n",
        "        lr = self.base_lr + (self.max_lr - self.base_lr) * max(0, (1 - x))\n",
        "        if self.mode == 'triangular2':\n",
        "            lr = lr / float(2 ** (cycle - 1))\n",
        "        elif self.mode == 'exp_range':\n",
        "            lr = lr * (0.999 ** self.iterations)\n",
        "        return lr\n",
        "\n",
        "    def on_train_begin(self, logs=None):\n",
        "        logs = logs or {}\n",
        "        tf.keras.backend.set_value(self.model.optimizer.lr, self.base_lr)\n",
        "\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        self.iterations += 1\n",
        "        lr = self.clr()\n",
        "        tf.keras.backend.set_value(self.model.optimizer.lr, lr)\n",
        "        self.history.setdefault('lr', []).append(lr)\n",
        "        for k, v in logs.items():\n",
        "            self.history.setdefault(k, []).append(v)\n",
        "\n",
        "# Função de callbacks\n",
        "def get_callbacks():\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
        "    clr = CyclicLR(base_lr=1e-4, max_lr=1e-3, step_size=2000., mode='triangular2')\n",
        "    return [early_stopping, reduce_lr, clr]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZMBQc7JL15q"
      },
      "outputs": [],
      "source": [
        "# Função para calcular a sigmoide e converter para 0 ou 1 o output\n",
        "class ThresholdLayer(tf.keras.layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        return tf.where(inputs < 0.5, 0.0, 1.0)\n",
        "\n",
        "# Função para calcular o Dice Coefficient\n",
        "def dice_coefficient(y_train, y_val):\n",
        "    smooth = 1e-6\n",
        "    intersection = tf.reduce_sum(y_train * y_val)\n",
        "    dice_coefficient = (2. * intersection + smooth) / (tf.reduce_sum(y_train) + tf.reduce_sum(y_val) + smooth)\n",
        "    return dice_coefficient\n",
        "\n",
        "# Função de perda de Dice\n",
        "def dice_loss(y_train, y_val):\n",
        "    return 1 - dice_coefficient(y_train, y_val)\n",
        "\n",
        "# Função para calcular a penalidade adicional\n",
        "def penalty_loss(y_train, y_val, penalty_weight):\n",
        "    # Calcular a penalidade considerando a diferença entre y_train e y_val\n",
        "    penalty = tf.reduce_sum(tf.abs(y_train - y_val))\n",
        "    # Multiplicar a penalidade pelo peso da penalidade\n",
        "    weighted_penalty = penalty_weight * penalty\n",
        "    return weighted_penalty\n",
        "\n",
        "# Função de perda combinada\n",
        "def combined_loss(y_train, y_val, penalty_weight):\n",
        "    # Perda padrão (por exemplo, perda de entropia cruzada binária)\n",
        "    standard_loss = tf.keras.losses.binary_crossentropy(y_train, y_val)\n",
        "    # Dice Loss\n",
        "    dice = dice_loss(y_train, y_val)\n",
        "    # Penalidade adicional\n",
        "    penalty = penalty_loss(y_train, y_val, penalty_weight)\n",
        "    # Perda total = perda padrão + penalidade + Dice Loss\n",
        "    total_loss = standard_loss + penalty + dice\n",
        "    return total_loss\n",
        "\n",
        "# Métrica de acurácia customizada\n",
        "def custom_accuracy(y_train, y_val):\n",
        "    # Calcular a acurácia considerando uma tolerância de 0.5 na predição\n",
        "    y_val_binary = tf.round(y_val)\n",
        "    accuracy = tf.reduce_mean(tf.cast(tf.equal(y_train, y_val_binary), tf.float32))\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJk0H6D6T9F1"
      },
      "outputs": [],
      "source": [
        "def Unet(input_shape):\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "    reg = regularizers.L2(0.001)\n",
        "\n",
        "    # Encoder (contraction path)\n",
        "    conv1 = layers.Conv2D(16, 3, activation='relu', padding='same', kernel_regularizer=reg)(inputs)\n",
        "    conv1 = layers.Conv2D(16, 3, activation='relu', padding='same', kernel_regularizer=reg)(conv1)\n",
        "    drop1 = layers.Dropout(0.3)(conv1)\n",
        "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(drop1)\n",
        "\n",
        "    conv2 = layers.Conv2D(32, 3, activation='relu', padding='same', kernel_regularizer=reg)(pool1)\n",
        "    conv2 = layers.Conv2D(32, 3, activation='relu', padding='same', kernel_regularizer=reg)(conv2)\n",
        "    drop2 = layers.Dropout(0.3)(conv2)\n",
        "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(drop2)\n",
        "\n",
        "    conv3 = layers.Conv2D(64, 3, activation='relu', padding='same', kernel_regularizer=reg)(pool2)\n",
        "    conv3 = layers.Conv2D(64, 3, activation='relu', padding='same', kernel_regularizer=reg)(conv3)\n",
        "    drop3 = layers.Dropout(0.3)(conv3)\n",
        "    pool3 = layers.MaxPooling2D(pool_size=(2, 2))(drop3)\n",
        "\n",
        "    # Bottleneck\n",
        "    conv4 = layers.Conv2D(128, 3, activation='relu', padding='same', kernel_regularizer=reg)(pool3)\n",
        "    conv4 = layers.Conv2D(128, 3, activation='relu', padding='same', kernel_regularizer=reg)(conv4)\n",
        "    drop4 = layers.Dropout(0.3)(conv4)\n",
        "\n",
        "    # Decoder (expansion path)\n",
        "    up5 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(drop4)\n",
        "    merge5 = layers.concatenate([conv3, up5], axis=3)\n",
        "    conv5 = layers.Conv2D(64, 3, activation='relu', padding='same', kernel_regularizer=reg)(merge5)\n",
        "    conv5 = layers.Conv2D(64, 3, activation='relu', padding='same', kernel_regularizer=reg)(conv5)\n",
        "\n",
        "    up6 = layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv5)\n",
        "    merge6 = layers.concatenate([conv2, up6], axis=3)\n",
        "    conv6 = layers.Conv2D(32, 3, activation='relu', padding='same', kernel_regularizer=reg)(merge6)\n",
        "    conv6 = layers.Conv2D(32, 3, activation='relu', padding='same', kernel_regularizer=reg)(conv6)\n",
        "\n",
        "    up7 = layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(conv6)\n",
        "    merge7 = layers.concatenate([conv1, up7], axis=3)\n",
        "    conv7 = layers.Conv2D(16, 3, activation='relu', padding='same', kernel_regularizer=reg)(merge7)\n",
        "    conv7 = layers.Conv2D(16, 3, activation='relu', padding='same', kernel_regularizer=reg)(conv7)\n",
        "\n",
        "    outputs = layers.Conv2D(1, 1, activation='sigmoid')(conv7)  # Saída com um canal (máscara binária)\n",
        "\n",
        "    threshold_output = ThresholdLayer()(outputs)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIxkz9tyUEb8",
        "outputId": "44b4508a-8afd-4113-cc6d-37b987e84b64"
      },
      "outputs": [],
      "source": [
        "# Criar modelo U-Net\n",
        "model = Unet(input_shape=(256, 256, 3))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_K8INbM9Wpi8"
      },
      "source": [
        "## Treino do modelo - GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTLb8OpzUHrj",
        "outputId": "4e32d3f4-cc85-40a0-cc8e-33f1e10f8aed"
      },
      "outputs": [],
      "source": [
        "callbacks = get_callbacks()\n",
        "with tf.device('/gpu:0'):\n",
        "    model = Unet(input_shape=(256, 256, 3))\n",
        "    # Compilar o modelo\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss=lambda y_train, y_val: combined_loss(y_train, y_val, 0.001), metrics=[custom_accuracy])\n",
        "\n",
        "    # Calcula o tempo de treino\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Definições\n",
        "    max_epochs = 200\n",
        "    batch_size = 16\n",
        "\n",
        "    # Treinar o modelo\n",
        "    H = model.fit(X_train, y_train, validation_data=(X_val, y_val), steps_per_epoch=30, epochs=max_epochs, batch_size=batch_size, callbacks=callbacks)\n",
        "\n",
        "    # Para o cronômetro e salva o tempo de treino\n",
        "    training_time_gpu = time.time() - start_time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_XrQw1fWtkp"
      },
      "source": [
        "# Avaliação do modelo - GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "IpbWkEwibEV2",
        "outputId": "f1b5fd62-bb5a-4f31-a51c-e3359a88516c"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    # Mostrando resultados\n",
        "    plt.style.use(\"ggplot\")\n",
        "    plt.figure()\n",
        "    plt.plot(H.epoch, H.history[\"loss\"], label=\"train_loss\")\n",
        "    plt.plot(H.epoch, H.history[\"val_loss\"], label=\"val_loss\")\n",
        "    plt.plot(H.epoch, H.history[\"custom_accuracy\"], label=\"train_acc\")\n",
        "    plt.plot(H.epoch, H.history[\"val_custom_accuracy\"], label=\"val_acc\")\n",
        "    plt.title(\"Training Loss and Accuracy - GPU\")\n",
        "    plt.xlabel(\"Epoch #\")\n",
        "    plt.ylabel(\"Loss/Accuracy\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXe7NUljUoKH",
        "outputId": "af773292-96d1-4b25-c794-0b455a1d92e8"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    # Calcula o tempo de inferência\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Avaliar o modelo nos dados de teste\n",
        "    results = model.evaluate(X_val, y_val)\n",
        "\n",
        "    # Para o cronômetro e salva o tempo de treino\n",
        "    inference_time_gpu = time.time() - start_time\n",
        "\n",
        "    print(\"Test Loss - GPU:\", results[0])\n",
        "    print(\"Test Accuracy - GPU:\", results[1])\n",
        "\n",
        "    # Prever máscaras usando o modelo\n",
        "    predicted_masks = model.predict(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        },
        "id": "3E-mOKTEWw90",
        "outputId": "ec1d0626-f1f5-4668-e103-8163db60ae9a"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    # Obter métricas de precisão e perda do histórico de treinamento\n",
        "    acc = H.history['custom_accuracy']\n",
        "    val_acc = H.history['val_custom_accuracy']\n",
        "    loss = H.history['loss']\n",
        "    val_loss = H.history['val_loss']\n",
        "\n",
        "    # Número de épocas\n",
        "    epochs = range(1, len(acc) + 1)\n",
        "\n",
        "    # Plotar precisão do conjunto de treino e validação\n",
        "    plt.plot(epochs, acc, 'r', label='Precisão do Conjunto de Treino')\n",
        "    plt.plot(epochs, val_acc, 'b', label='Precisão do Conjunto de Validação')\n",
        "    plt.title('Precisão do Conjunto de Treino e Validação - GPU')\n",
        "    plt.xlabel('Épocas')\n",
        "    plt.ylabel('Precisão')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Plotar perda do conjunto de treino e validação\n",
        "    plt.plot(epochs, loss, 'r', label='Perda do Conjunto de Treino')\n",
        "    plt.plot(epochs, val_loss, 'b', label='Perda do Conjunto de Validação')\n",
        "    plt.title('Perda do Conjunto de Treino e Validação - GPU')\n",
        "    plt.xlabel('Épocas')\n",
        "    plt.ylabel('Perda')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "9diaOF4DmnGr",
        "outputId": "3bb76fb5-5e45-4dec-8f79-98db4a268512"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    print(epochs)\n",
        "    print('Tempo de treino GPU (segundos): ', training_time_gpu)\n",
        "    print('Tempo de treino GPU por época (segundos): ', training_time_gpu / max_epochs)\n",
        "    print('Tempo de inferência GPU (segundos): ', inference_time_gpu)\n",
        "\n",
        "    # Plotando o tempo de treinamento e inferência\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.bar(['GPU Training'], [training_time_gpu], color=['orange'])\n",
        "    plt.bar(['GPU Inference'], [inference_time_gpu], color=['orange'])\n",
        "    plt.ylabel('Time (seconds)')\n",
        "    plt.title('Training and Inference Time - GPU')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "50cPtSMOWIqb",
        "outputId": "9d0251ae-12a6-4cb5-f157-c14e65098ab5"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    # Gerar as saídas do modelo para um conjunto de entradas de teste\n",
        "    saidas_modelo = model.predict(X_val)\n",
        "\n",
        "    # Iterar sobre cada saída do modelo\n",
        "    for i in range(len(X_val)):\n",
        "        # Obter a entrada correspondente e a saída real\n",
        "        img_entrada = X_val[i]\n",
        "        img_saida_real = y_val[i]\n",
        "\n",
        "        # Obter a saída gerada pelo modelo\n",
        "        img_saida_modelo = saidas_modelo[i]\n",
        "\n",
        "        # Mostrar as imagens\n",
        "        plt.figure(figsize=(12, 4))\n",
        "\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.imshow(img_entrada.squeeze(), cmap='gray')\n",
        "        plt.title('Entrada')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.imshow(img_saida_real.squeeze(), cmap='gray')\n",
        "        plt.title('Saída Esperada')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(img_saida_modelo.squeeze(), cmap='gray')\n",
        "        plt.title('Saída do Modelo - GPU')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8o4pT9GJiYqw",
        "outputId": "449d59c3-bccc-483a-b770-9ab8b2287ed8"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    # Métricas do parceiro de Projeto:\n",
        "\n",
        "    # Lista para armazenar os scores de IoU\n",
        "    iou_scores = []\n",
        "    # Calcular IoUs e determinar predições corretas\n",
        "    correct_predictions = 0\n",
        "    iou_threshold = 0.5\n",
        "    for mask, result in zip(y_val, img_saida_modelo):\n",
        "        intersection = np.logical_and(mask, result)\n",
        "        union = np.logical_or(mask, result)\n",
        "        iou_score = np.sum(intersection) / np.sum(union) if np.sum(union) != 0 else 0\n",
        "        iou_scores.append(iou_score)\n",
        "        # Verificar se a predição é considerada correta (IoU >= threshold)\n",
        "        if iou_score >= iou_threshold:\n",
        "            correct_predictions += 1\n",
        "        print('IoU é: ' + str(iou_score))\n",
        "    # Calcular a média dos IoUs\n",
        "    iou_mean = np.mean(iou_scores)\n",
        "    print('Média dos IoU - GPU:', iou_mean)\n",
        "    # Calcular Coverage Ratio (CovR)\n",
        "    total_predictions = len(iou_scores)\n",
        "    covr = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
        "    print('Coverage Ratio (CovR) - GPU:', covr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXXRZSPUSwTS"
      },
      "source": [
        "# Avaliação do Modelo com Imagens Desconhecidas\n",
        "\n",
        "Esta seção apresenta os resultados da avaliação do modelo utilizando um conjunto de imagens inéditas, ou seja, imagens que não foram utilizadas durante o treinamento. O objetivo principal é analisar o desempenho e comportamento do modelo frente a dados desconhecidos. \n",
        "\n",
        "A métrica principal utilizada nesta etapa inicial é a Intersection over Union (IoU), a qual será complementada com métricas adicionais na próxima sprint, proporcionando uma análise mais abrangente da performance do modelo. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Y9IihD8Sv8Q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def load_masks(masks_dir, target_size=(600, 600), crop_size=(200, 200), final_size=(256, 256)):\n",
        "    \"\"\"\n",
        "    Carrega as máscaras (masks) de segmentação a partir de um diretório.\n",
        "\n",
        "    Args:\n",
        "    masks_dir (str): O diretório contendo as máscaras.\n",
        "    target_size (tuple): Tamanho alvo para redimensionamento inicial.\n",
        "    crop_size (tuple): Tamanho do recorte para segmentação.\n",
        "    final_size (tuple): Tamanho final após redimensionamento.\n",
        "\n",
        "    Returns:\n",
        "    list: Lista de máscaras normalizadas.\n",
        "    list: Lista de nomes de arquivo de máscara correspondentes.\n",
        "    \"\"\"\n",
        "    masks = []\n",
        "    mask_filenames = []\n",
        "    ordered_masks = sorted(os.listdir(masks_dir))\n",
        "    for mask_name in ordered_masks:\n",
        "        mask_path = os.path.join(masks_dir, mask_name)\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if mask is not None:\n",
        "            if mask.shape[:2] != target_size:\n",
        "                mask = cv2.resize(mask, target_size[::-1], interpolation=cv2.INTER_NEAREST)\n",
        "            cropped_masks = crop_image(mask, crop_size)\n",
        "            resized_masks = [cv2.resize(crop, final_size[::-1], interpolation=cv2.INTER_NEAREST) for crop in cropped_masks]\n",
        "            normalized_masks = [crop / 255.0 for crop in resized_masks]\n",
        "            masks.extend(normalized_masks)\n",
        "            mask_filenames.extend([f\"{os.path.splitext(mask_name)[0]}_crop_{i}\" for i in range(len(normalized_masks))])\n",
        "        else:\n",
        "            print(f\"Falha ao carregar a máscara: {mask_path}\")\n",
        "    return masks, mask_filenames\n",
        "\n",
        "def load_images(image_dir, target_size=(600, 600), crop_size=(200, 200), final_size=(256, 256)):\n",
        "    \"\"\"\n",
        "    Carrega as imagens a partir de um diretório.\n",
        "\n",
        "    Args:\n",
        "    image_dir (str): O diretório contendo as imagens.\n",
        "    target_size (tuple): Tamanho alvo para redimensionamento inicial.\n",
        "    crop_size (tuple): Tamanho do recorte para segmentação.\n",
        "    final_size (tuple): Tamanho final após redimensionamento.\n",
        "\n",
        "    Returns:\n",
        "    list: Lista de imagens normalizadas.\n",
        "    list: Lista de nomes de arquivo de imagem correspondentes.\n",
        "    \"\"\"\n",
        "    images = []\n",
        "    image_filenames = []\n",
        "    ordered_images = sorted(os.listdir(image_dir))\n",
        "    for image_name in ordered_images:\n",
        "        image_path = os.path.join(image_dir, image_name)\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is not None:\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            if image.shape[:2] != target_size:\n",
        "                image = cv2.resize(image, target_size[::-1])\n",
        "            cropped_images = crop_image(image, crop_size)\n",
        "            resized_images = [cv2.resize(crop, final_size[::-1]) for crop in cropped_images]\n",
        "            normalized_images = [crop / 255.0 for crop in resized_images]\n",
        "            images.extend(normalized_images)\n",
        "            image_filenames.extend([f\"{os.path.splitext(image_name)[0]}_crop_{i}\" for i in range(len(normalized_images))])\n",
        "        else:\n",
        "            print(f\"Falha ao carregar a imagem: {image_path}\")\n",
        "    return images, image_filenames\n",
        "\n",
        "def crop_image(image, crop_size=(200, 200)):\n",
        "    \"\"\"\n",
        "    Realiza o recorte da imagem em múltiplas partes.\n",
        "\n",
        "    Args:\n",
        "    image (np.array): A imagem a ser recortada.\n",
        "    crop_size (tuple): Tamanho do recorte.\n",
        "\n",
        "    Returns:\n",
        "    list: Lista de partes recortadas da imagem.\n",
        "    \"\"\"\n",
        "    crops = []\n",
        "    for i in range(0, image.shape[0], crop_size[0]):\n",
        "        for j in range(0, image.shape[1], crop_size[1]):\n",
        "            crop = image[i:i+crop_size[0], j:j+crop_size[1]]\n",
        "            if crop.shape[0] == crop_size[0] and crop.shape[1] == crop_size[1]:\n",
        "                crops.append(crop)\n",
        "    return crops\n",
        "\n",
        "# Diretórios\n",
        "masks_dir = '/content/drive/Shared drives/Grupo T de Tech/Data/dataset_inteli_test/masks'\n",
        "image_dir = '/content/drive/Shared drives/Grupo T de Tech/Data/dataset_inteli_test/tci_tifs'\n",
        "\n",
        "# Carregar imagens e máscaras\n",
        "masks_test, mask_filenames = load_masks(masks_dir)\n",
        "images_test, image_filenames = load_images(image_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfSEeFHgUq_B",
        "outputId": "7ccbf918-60d6-4d4c-ca72-15d7f89e5323"
      },
      "outputs": [],
      "source": [
        "# Certificando que o conjunto possui o tamanho correto, 3 imagens divididas em 9 partes cada.\n",
        "len(images_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZQh3dacVNJE",
        "outputId": "fb9a8fbf-791b-4896-af41-b22669a219c7"
      },
      "outputs": [],
      "source": [
        "# Converter a lista de imagens em um array numpy para ser usado como entrada para o modelo\n",
        "images_test = np.array(images_test)\n",
        "\n",
        "# Gerar as saídas do modelo para um conjunto de entradas de teste\n",
        "saidas_modelo = model.predict(images_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7ctNDeiiZD3i",
        "outputId": "aaeff7e1-6b56-4b87-dc15-bfe0b41f591f"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    # Iterar sobre cada saída do modelo\n",
        "    for i in range(len(images_test)):\n",
        "        # Obter a entrada correspondente e a saída real\n",
        "        img_entrada = images_test[i]\n",
        "        img_saida_real = masks_test[i]\n",
        "\n",
        "        # Obter a saída gerada pelo modelo\n",
        "        img_saida_modelo = saidas_modelo[i]\n",
        "\n",
        "        # Mostrar as imagens\n",
        "        plt.figure(figsize=(12, 4))\n",
        "\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.imshow(img_entrada.squeeze(), cmap='gray')\n",
        "        plt.title('Entrada')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.imshow(img_saida_real.squeeze(), cmap='gray')\n",
        "        plt.title('Saída Esperada')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(img_saida_modelo.squeeze(), cmap='gray')\n",
        "        plt.title('Saída do Modelo - GPU')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlB1PhdEcXe7",
        "outputId": "6891a43e-fbfc-4d22-d590-11b2d4ec382b"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    # Métricas do parceiro de Projeto:\n",
        "\n",
        "    # Lista para armazenar os scores de IoU\n",
        "    iou_scores = []\n",
        "    # Calcular IoUs e determinar predições corretas\n",
        "    correct_predictions = 0\n",
        "    iou_threshold = 0.5\n",
        "    for mask, result in zip(masks_test, saidas_modelo):\n",
        "        intersection = np.logical_and(mask, result)\n",
        "        union = np.logical_or(mask, result)\n",
        "        iou_score = np.sum(intersection) / np.sum(union) if np.sum(union) != 0 else 0\n",
        "        iou_scores.append(iou_score)\n",
        "        # Verificar se a predição é considerada correta (IoU >= threshold)\n",
        "        if iou_score >= iou_threshold:\n",
        "            correct_predictions += 1\n",
        "        print('IoU é: ' + str(iou_score))\n",
        "    # Calcular a média dos IoUs\n",
        "    iou_mean = np.mean(iou_scores)\n",
        "    print('Média dos IoU - GPU:', iou_mean)\n",
        "    # Calcular Coverage Ratio (CovR)\n",
        "    total_predictions = len(iou_scores)\n",
        "    covr = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
        "    print('Coverage Ratio (CovR) - GPU:', covr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Podemos observar que o conjunto de imagens novo teve um ganho relativo até se comparado com as de validação e treino. Cerca de um crescimento de 7 pontos percentuais."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zbr9ZHsdDNcT"
      },
      "source": [
        "# Pós-processamento de Imagens: Operações Morfológicas e CRFs\n",
        "\n",
        "No pós-processamento de imagens, buscamos aprimorar os resultados de segmentação inicial, tornando-os mais precisos e visualmente coerentes. Duas técnicas comuns utilizadas para esse fim são as **operações morfológicas** e os **Campos Aleatórios Condicionais (CRFs)**. Este documento explora essas técnicas, seus fundamentos teóricos, benefícios e aplicações.\n",
        "\n",
        "## Operações Morfológicas\n",
        "\n",
        "Operações morfológicas são técnicas de processamento de imagem que se baseiam na forma ou estrutura de objetos dentro de uma imagem. Utilizando um elemento estruturante, essas operações podem modificar a geometria de regiões binárias da imagem para eliminar ruídos ou destacar características específicas.\n",
        "\n",
        "### Tipos de Operações\n",
        "\n",
        "1. **Erosão**: Remove pixels nas bordas dos objetos.\n",
        "2. **Dilatação**: Adiciona pixels às bordas dos objetos.\n",
        "3. **Abertura**: Erosão seguida de dilatação, útil para remover pequenos objetos.\n",
        "4. **Fechamento**: Dilatação seguida de erosão, útil para fechar pequenos buracos.\n",
        "\n",
        "### Benefícios\n",
        "\n",
        "- **Redução de Ruído**: Abertura e fechamento são eficazes na eliminação de pequenos ruídos sem alterar significativamente a forma dos objetos.\n",
        "- **Suavização de Bordas**: Dilatação e erosão podem suavizar bordas irregulares, melhorando a qualidade visual da segmentação.\n",
        "  \n",
        "Para mais detalhes sobre operações morfológicas, consulte o artigo que utilizamos como base: [Understanding Morphological Image Processing and its Operations](https://towardsdatascience.com/understanding-morphological-image-processing-and-its-operations-7bcf1ed11756).\n",
        "\n",
        "## Campos Aleatórios Condicionais (CRFs)\n",
        "\n",
        "Os CRFs são modelos gráficos não direcionados que consideram as dependências entre pixels vizinhos para melhorar a segmentação de imagens. Diferente de outros classificadores, os CRFs são discriminativos e consideram as relações espaciais entre os pixels.\n",
        "\n",
        "### Tipos de CRFs\n",
        "\n",
        "1. **Linear CRF**: Adequado para sequências lineares, como texto.\n",
        "2. **Grid CRF**: Conecta cada pixel aos seus vizinhos imediatos em uma grade.\n",
        "3. **Dense CRF**: Conecta cada pixel a todos os outros pixels, ideal para capturar relações de longo alcance.\n",
        "\n",
        "### Benefícios\n",
        "\n",
        "- **Aprimoramento de Bordas**: CRFs são eficazes na recuperação de bordas suaves e contornos detalhados em imagens segmentadas.\n",
        "- **Redução de Ambiguidade**: Considerando a vizinhança, os CRFs ajudam a resolver ambiguidades na classificação de pixels.\n",
        "\n",
        "O uso de CRFs densos é particularmente notável pela sua eficiência e precisão, conforme descrito no artigo \"Efficient Inference in Fully Connected CRFs with Gaussian Edge Potentials\" por Krähenbühl e Koltun. Para um estudo detalhado, consulte o artigo: [Dense Conditional Random Field](https://medium.com/lis-computer-vision-blogs/dense-conditional-random-field-dfdeb6655005).\n",
        "\n",
        "### Referências\n",
        "\n",
        "- DHAWAN, Aashish; BODANI, Pankaj; GARG, Vishal. Post Processing of Image Segmentation using Conditional Random Fields. 2019. Disponível em: [ResearchGate](https://www.researchgate.net/publication/355020007_Post_Processing_of_Image_Segmentation_using_Conditional_Random_Fields).\n",
        "- Towards Data Science. Understanding Morphological Image Processing and its Operations. Disponível em: [Medium](https://towardsdatascience.com/understanding-morphological-image-processing-and-its-operations-7bcf1ed11756).\n",
        "- LIS Computer Vision Blogs. Dense Conditional Random Field. Disponível em: [Medium](https://medium.com/lis-computer-vision-blogs/dense-conditional-random-field-dfdeb6655005)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9GHwiagDP2x",
        "outputId": "e5da9867-a841-453b-9777-c56f699b398f"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/lucasb-eyer/pydensecrf.git\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import jaccard_score\n",
        "import pydensecrf.densecrf as dcrf\n",
        "from pydensecrf.utils import unary_from_softmax, create_pairwise_bilateral"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## GridSerach\n",
        "\n",
        "\n",
        "Abaixo, implementamos uma técnica de GridSearch para encontrar os melhores parâmetros para o algoritmo de CRF e para as operações morfológicas. Utilizamos a métrica de **Jaccard Score**, também conhecida como **Intersection Over Union (IoU)**, para avaliar os hiperparâmetros que proporcionam os melhores resultados.\n",
        "\n",
        "### Métrica de Avaliação: Jaccard Score (IoU)\n",
        "A métrica **Jaccard Score** é amplamente utilizada na avaliação de segmentação de imagens, pois mede a similaridade entre os conjuntos previstos e os conjuntos reais. É calculada como a razão entre a interseção e a união dos conjuntos, proporcionando uma medida clara de precisão.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6tnniH2EJ6D",
        "outputId": "561a2347-c8cf-4701-8e34-6671f0e165c3"
      },
      "outputs": [],
      "source": [
        "pip install tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Gridsearch para encontrar os melhores parâmetros de CRF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qk2_ZxvvqDQi",
        "outputId": "84388b08-1619-4055-f237-bb64d34772b7"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def postprocess_mask_with_crf(image, mask, crf_params):\n",
        "    softmax = np.stack([1 - mask, mask], axis=-1)\n",
        "    softmax = np.ascontiguousarray(softmax.transpose(2, 0, 1))\n",
        "    image = np.ascontiguousarray(image)\n",
        "    image_uint8 = (image * 255).astype(np.uint8)\n",
        "    d = dcrf.DenseCRF2D(image.shape[1], image.shape[0], 2)\n",
        "    unary = unary_from_softmax(softmax)\n",
        "    d.setUnaryEnergy(unary)\n",
        "    d.addPairwiseGaussian(sxy=crf_params['sxy'], compat=crf_params['compat'])\n",
        "    d.addPairwiseBilateral(sxy=crf_params['sxy_bilateral'], srgb=crf_params['srgb'], rgbim=image_uint8, compat=crf_params['compat_bilateral'])\n",
        "    Q = d.inference(5)\n",
        "    refined_mask = np.argmax(Q, axis=0).reshape((image.shape[0], image.shape[1]))\n",
        "    return refined_mask / 255.0\n",
        "\n",
        "def calculate_iou(true_mask, pred_mask):\n",
        "    true_mask_bin = (true_mask > 0).astype(np.uint8)\n",
        "    pred_mask_bin = (pred_mask > 0).astype(np.uint8)\n",
        "    return jaccard_score(true_mask_bin.flatten(), pred_mask_bin.flatten(), average='binary')\n",
        "\n",
        "# Espaço de busca de hiperparâmetros do CRF\n",
        "crf_param_grid = {\n",
        "    'sxy': [1, 3, 5],\n",
        "    'compat': [3, 5, 10],\n",
        "    'sxy_bilateral': [49, 81],\n",
        "    'srgb': [3, 10, 13],\n",
        "    'compat_bilateral': [3, 10, 20]\n",
        "}\n",
        "\n",
        "best_iou_crf = 0\n",
        "best_crf_params = None\n",
        "\n",
        "# Calcular o número total de iterações para CRF\n",
        "total_iterations_crf = (len(crf_param_grid['sxy']) * len(crf_param_grid['compat']) *\n",
        "                        len(crf_param_grid['sxy_bilateral']) * len(crf_param_grid['srgb']) *\n",
        "                        len(crf_param_grid['compat_bilateral']))\n",
        "\n",
        "# Realizar busca em grade para encontrar os melhores hiperparâmetros do CRF\n",
        "with tqdm(total=total_iterations_crf, desc=\"Grid Search CRF\") as pbar:\n",
        "    for sxy in crf_param_grid['sxy']:\n",
        "        for compat in crf_param_grid['compat']:\n",
        "            for sxy_bilateral in crf_param_grid['sxy_bilateral']:\n",
        "                for srgb in crf_param_grid['srgb']:\n",
        "                    for compat_bilateral in crf_param_grid['compat_bilateral']:\n",
        "                        crf_params = {\n",
        "                            'sxy': sxy,\n",
        "                            'compat': compat,\n",
        "                            'sxy_bilateral': sxy_bilateral,\n",
        "                            'srgb': srgb,\n",
        "                            'compat_bilateral': compat_bilateral\n",
        "                        }\n",
        "                        # Aplicar pós-processamento e calcular IoU\n",
        "                        iou_scores = []\n",
        "                        for i in range(len(saidas_modelo)):\n",
        "                            refined_mask = postprocess_mask_with_crf(images_test[i], saidas_modelo[i].squeeze(), crf_params)\n",
        "                            iou = calculate_iou(masks_test[i], refined_mask)\n",
        "                            iou_scores.append(iou)\n",
        "                        avg_iou = np.mean(iou_scores)\n",
        "                        if avg_iou > best_iou_crf:\n",
        "                            best_iou_crf = avg_iou\n",
        "                            best_crf_params = crf_params\n",
        "                        pbar.update(1)\n",
        "\n",
        "print(\"Melhores parâmetros CRF:\", best_crf_params)\n",
        "print(\"Melhor IoU CRF:\", best_iou_crf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SQ_ebz8RkS_"
      },
      "source": [
        "#### Aplicando apenas CRF e comparando a qualidade da imagem\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHF1GMouRqeQ"
      },
      "outputs": [],
      "source": [
        "best_crf_params = {\n",
        "    'sxy': 5,\n",
        "    'compat': 3,\n",
        "    'sxy_bilateral': 81,\n",
        "    'srgb': 10,\n",
        "    'compat_bilateral': 20\n",
        "}\n",
        "\n",
        "# Pós-processar as máscaras preditas com CRF denso\n",
        "saidas_modelo_postprocessed_with_best_crf = np.array([postprocess_mask_with_crf(images_test[i], saidas_modelo[i].squeeze(), best_crf_params) for i in range(len(saidas_modelo))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0f16P35SgcB",
        "outputId": "334ffa59-87a0-4ccf-cb54-54754cafec94"
      },
      "outputs": [],
      "source": [
        "# Converter as máscaras de teste para binário (0 e 1)\n",
        "masks_test_binary = (np.array(masks_test) > 0).astype(np.uint8)\n",
        "saidas_modelo_postprocessed_with_best_crf_binary = (saidas_modelo_postprocessed_with_best_crf > 0).astype(np.uint8)\n",
        "\n",
        "# Calcular Jaccard Score\n",
        "jaccard_scores = [jaccard_score(masks_test_binary[i].flatten(), saidas_modelo_postprocessed_with_best_crf_binary[i].flatten(), average='binary') for i in range(len(masks_test))]\n",
        "print(f\"Jaccard Score: {np.mean(jaccard_scores)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xQ6S5lY2T1fH",
        "outputId": "4c5ab441-6280-4575-8d04-c5f4ac37606c"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    # Iterar sobre cada saída do modelo\n",
        "    for i in range(len(images_test)):\n",
        "        # Obter a entrada correspondente e a saída real\n",
        "        img_entrada = masks_test[i]\n",
        "        img_saida_real = saidas_modelo[i]\n",
        "\n",
        "        # Obter a saída gerada pelo modelo\n",
        "        img_saida_modelo = saidas_modelo_postprocessed_with_best_crf[i]\n",
        "\n",
        "        # Mostrar as imagens\n",
        "        plt.figure(figsize=(12, 4))\n",
        "\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.imshow(img_entrada.squeeze(), cmap='gray')\n",
        "        plt.title('saida real')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.imshow(img_saida_real.squeeze(), cmap='gray')\n",
        "        plt.title('Saída modelo')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(img_saida_modelo.squeeze(), cmap='gray')\n",
        "        plt.title('Saída do Modelo - pós')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Gridsearch para encontrar os melhores operações morfológicas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fyIyL8o7zli",
        "outputId": "09fb5d2b-408c-4d86-c28b-104ac125abc4"
      },
      "outputs": [],
      "source": [
        "# Cálculo para operações morfológicas\n",
        "def postprocess_mask_with_morphology(mask, morph_params):\n",
        "    refined_mask = (mask * 255).astype(np.uint8)\n",
        "    kernel = cv2.getStructuringElement(morph_params['shape'], morph_params['kernel_size'])\n",
        "    if morph_params['operation'] == 'open':\n",
        "        refined_mask = cv2.morphologyEx(refined_mask, cv2.MORPH_OPEN, kernel, iterations=morph_params['iterations'])\n",
        "    elif morph_params['operation'] == 'close':\n",
        "        refined_mask = cv2.morphologyEx(refined_mask, cv2.MORPH_CLOSE, kernel, iterations=morph_params['iterations'])\n",
        "    elif morph_params['operation'] == 'dilate':\n",
        "        refined_mask = cv2.dilate(refined_mask, kernel, iterations=morph_params['iterations'])\n",
        "    elif morph_params['operation'] == 'erode':\n",
        "        refined_mask = cv2.erode(refined_mask, kernel, iterations=morph_params['iterations'])\n",
        "    return refined_mask / 255.0\n",
        "\n",
        "def calculate_iou(true_mask, pred_mask):\n",
        "    true_mask_bin = (true_mask > 0).astype(np.uint8)\n",
        "    pred_mask_bin = (pred_mask > 0).astype(np.uint8)\n",
        "    return jaccard_score(true_mask_bin.flatten(), pred_mask_bin.flatten(), average='binary')\n",
        "\n",
        "# Espaço de busca de hiperparâmetros das operações morfológicas\n",
        "morph_param_grid = {\n",
        "    'kernel_size': [(3, 3), (5, 5), (7, 7)],\n",
        "    'iterations': [1, 2, 3],\n",
        "    'operation': ['open', 'close', 'dilate', 'erode'],\n",
        "    'shape': [cv2.MORPH_RECT, cv2.MORPH_ELLIPSE, cv2.MORPH_CROSS]\n",
        "}\n",
        "\n",
        "best_iou_morph = 0\n",
        "best_morph_params = None\n",
        "\n",
        "# Calcular o número total de iterações para operações morfológicas\n",
        "total_iterations_morph = (len(morph_param_grid['kernel_size']) * len(morph_param_grid['iterations']) *\n",
        "                          len(morph_param_grid['operation']) * len(morph_param_grid['shape']))\n",
        "\n",
        "# Realizar busca em grade para encontrar os melhores hiperparâmetros das operações morfológicas\n",
        "with tqdm(total=total_iterations_morph, desc=\"Grid Search Morph\") as pbar:\n",
        "    for kernel_size in morph_param_grid['kernel_size']:\n",
        "        for iterations in morph_param_grid['iterations']:\n",
        "            for operation in morph_param_grid['operation']:\n",
        "                for shape in morph_param_grid['shape']:\n",
        "                    morph_params = {\n",
        "                        'kernel_size': kernel_size,\n",
        "                        'iterations': iterations,\n",
        "                        'operation': operation,\n",
        "                        'shape': shape\n",
        "                    }\n",
        "                    # Aplicar pós-processamento e calcular IoU\n",
        "                    iou_scores = []\n",
        "                    for i in range(len(saidas_modelo)):\n",
        "                        refined_mask_crf = postprocess_mask_with_crf(images_test[i], saidas_modelo[i].squeeze(), best_crf_params)\n",
        "                        refined_mask = postprocess_mask_with_morphology(refined_mask_crf, morph_params)\n",
        "                        iou = calculate_iou(masks_test[i], refined_mask)\n",
        "                        iou_scores.append(iou)\n",
        "                    avg_iou = np.mean(iou_scores)\n",
        "                    if avg_iou > best_iou_morph:\n",
        "                        best_iou_morph = avg_iou\n",
        "                        best_morph_params = morph_params\n",
        "                    pbar.update(1)\n",
        "\n",
        "print(\"Melhores parâmetros de Morfologia:\", best_morph_params)\n",
        "print(\"Melhor IoU Morph:\", best_iou_morph)\n",
        "\n",
        "# Teste: Operação Morfológica Antes ou Depois do CRF\n",
        "iou_scores_before_crf = []\n",
        "iou_scores_after_crf = []\n",
        "\n",
        "for i in range(len(saidas_modelo)):\n",
        "    # Aplicar operação morfológica antes do CRF\n",
        "    morph_mask_before_crf = postprocess_mask_with_morphology(saidas_modelo[i].squeeze(), best_morph_params)\n",
        "    refined_mask_before_crf = postprocess_mask_with_crf(images_test[i], morph_mask_before_crf, best_crf_params)\n",
        "    iou_before_crf = calculate_iou(masks_test[i], refined_mask_before_crf)\n",
        "    iou_scores_before_crf.append(iou_before_crf)\n",
        "\n",
        "    # Aplicar operação morfológica depois do CRF\n",
        "    refined_mask_crf = postprocess_mask_with_crf(images_test[i], saidas_modelo[i].squeeze(), best_crf_params)\n",
        "    morph_mask_after_crf = postprocess_mask_with_morphology(refined_mask_crf, best_morph_params)\n",
        "    iou_after_crf = calculate_iou(masks_test[i], morph_mask_after_crf)\n",
        "    iou_scores_after_crf.append(iou_after_crf)\n",
        "\n",
        "avg_iou_before_crf = np.mean(iou_scores_before_crf)\n",
        "avg_iou_after_crf = np.mean(iou_scores_after_crf)\n",
        "\n",
        "print(\"IoU Médio - Operação Morfológica Antes do CRF:\", avg_iou_before_crf)\n",
        "print(\"IoU Médio - Operação Morfológica Depois do CRF:\", avg_iou_after_crf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoZL0OC2WqFH"
      },
      "source": [
        "#### Avaliando operações morfológicas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AOf6DxLWy1S"
      },
      "outputs": [],
      "source": [
        "best_morph_params = {\n",
        "    'kernel_size': (3,3),\n",
        "    'iterations': 1,\n",
        "    'operation': 'dilate',\n",
        "    'shape': cv2.MORPH_CROSS\n",
        "}\n",
        "\n",
        "# Pós-processar as máscaras preditas com CRF denso\n",
        "saidas_modelo_postprocessed_with_morphology = np.array([postprocess_mask_with_morphology(saidas_modelo[i].squeeze(), best_morph_params) for i in range(len(saidas_modelo))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RG7MmIL-Wy1c",
        "outputId": "ffaa9f7b-dac0-4c65-f2b0-a50a244e17c1"
      },
      "outputs": [],
      "source": [
        "# Converter as máscaras de teste para binário (0 e 1)\n",
        "saidas_modelo_postprocessed_with_morphology_binary = (saidas_modelo_postprocessed_with_morphology > 0).astype(np.uint8)\n",
        "\n",
        "# Calcular Jaccard Score\n",
        "jaccard_scores = [jaccard_score(masks_test_binary[i].flatten(), saidas_modelo_postprocessed_with_morphology_binary[i].flatten(), average='binary') for i in range(len(masks_test))]\n",
        "print(f\"Jaccard Score: {np.mean(jaccard_scores)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCnXQ9vaZT7A"
      },
      "source": [
        "## Pós processamento completo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQgErWgMZXLR"
      },
      "outputs": [],
      "source": [
        "def morphology_then_crf(image, mask, morph_params, crf_params):\n",
        "    morph_mask = postprocess_mask_with_morphology(mask, morph_params)\n",
        "    refined_mask = postprocess_mask_with_crf(image, morph_mask, crf_params)\n",
        "    return refined_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkwNOACRZxwj"
      },
      "outputs": [],
      "source": [
        "# Pós-processar as máscaras preditas com CRF denso\n",
        "saidas_modelo_postprocessed = np.array([morphology_then_crf(images_test[i], saidas_modelo[i].squeeze(), best_morph_params, best_crf_params) for i in range(len(saidas_modelo))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOzY53pjaEqz",
        "outputId": "f5c8be42-7620-4855-fcca-688304d71d8f"
      },
      "outputs": [],
      "source": [
        "# Converter as máscaras de teste para binário (0 e 1)\n",
        "saidas_modelo_postprocessed_binary = (saidas_modelo_postprocessed > 0).astype(np.uint8)\n",
        "\n",
        "# Calcular Jaccard Score\n",
        "jaccard_scores = [jaccard_score(masks_test_binary[i].flatten(), saidas_modelo_postprocessed_binary[i].flatten(), average='binary') for i in range(len(masks_test))]\n",
        "print(f\"Jaccard Score: {np.mean(jaccard_scores)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ao avaliarmos a saída das imagens do modelo, percebemos que, para as próximas sprints, há necessidade de um refinamento maior do algoritmo de CRF e uma melhora circunstancial da máscara predita pelo modelo, permitindo alcançarmos um maior nível de generalização para o modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XydFhgJQaPpc",
        "outputId": "42b8e51f-4669-44bc-a466-3a8f2a3e3896"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    # Iterar sobre cada saída do modelo\n",
        "    for i in range(len(images_test)):\n",
        "        # Obter a entrada correspondente e a saída real\n",
        "        img_entrada = masks_test[i]\n",
        "        img_saida_real = saidas_modelo[i]\n",
        "\n",
        "        # Obter a saída gerada pelo modelo\n",
        "        img_saida_modelo = saidas_modelo_postprocessed[i]\n",
        "\n",
        "        # Mostrar as imagens\n",
        "        plt.figure(figsize=(12, 4))\n",
        "\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.imshow(img_entrada.squeeze(), cmap='gray')\n",
        "        plt.title('saida real')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.imshow(img_saida_real.squeeze(), cmap='gray')\n",
        "        plt.title('Saída modelo')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(img_saida_modelo.squeeze(), cmap='gray')\n",
        "        plt.title('Saída do Modelo - pós')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6Oxp8I9cibS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1fNtBmKk1nD"
      },
      "source": [
        "## TESTE COM MODELOS DE TREINO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BNmSfGQk3eD",
        "outputId": "2ee2f410-13e8-41e7-e6f4-8b8022303ea1"
      },
      "outputs": [],
      "source": [
        "# Gerar as saídas do modelo para um conjunto de entradas de teste\n",
        "saidas_modelo_treino = model.predict(X_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NCx6XT1k-nq"
      },
      "outputs": [],
      "source": [
        "# Pós-processar as máscaras preditas com CRF denso\n",
        "imagens_treino_postprocessed = np.array([morphology_then_crf(X_val[i], saidas_modelo_treino[i].squeeze(), best_morph_params, best_crf_params) for i in range(len(saidas_modelo_treino))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "wrH-CslJk-n0",
        "outputId": "b400622d-7d44-4f64-fe2b-3f3a7477f8f8"
      },
      "outputs": [],
      "source": [
        "# Converter as máscaras de teste para binário (0 e 1)\n",
        "masks_treino = (np.array(y_val) > 0).astype(np.uint8)\n",
        "imagens_treino_postprocessed_binary = (np.array(X_val) > 0).astype(np.uint8)\n",
        "\n",
        "# Calcular Jaccard Score\n",
        "jaccard_scores = [jaccard_score(masks_treino[i].flatten(), imagens_treino_postprocessed_binary[i].flatten(), average='binary') for i in range(len(masks_treino))]\n",
        "print(f\"Jaccard Score: {np.mean(jaccard_scores)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHSk6asZnGbr",
        "outputId": "ec4210ad-b159-4d45-a956-65b5bfdb4b9d"
      },
      "outputs": [],
      "source": [
        "X_val.shape, y_val.shape, imagens_treino_postprocessed.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hB3-Vtw0k-n1",
        "outputId": "3e7a6671-e77c-4171-92a2-e1799d0492ee"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    # Iterar sobre cada saída do modelo\n",
        "    for i in range(len(X_val)):\n",
        "        # Obter a entrada correspondente e a saída real\n",
        "        img_entrada = X_val[i]\n",
        "        img_saida_real = y_val[i]\n",
        "\n",
        "        # Obter a saída gerada pelo modelo\n",
        "        img_saida_modelo = saidas_modelo_treino[i]\n",
        "        img_saida_modelo_post = imagens_treino_postprocessed[i]\n",
        "\n",
        "        # Mostrar as imagens\n",
        "        plt.figure(figsize=(12, 4))\n",
        "\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.imshow(img_saida_real.squeeze(), cmap='gray')\n",
        "        plt.title('Saída Esperada')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.imshow(img_saida_modelo.squeeze(), cmap='gray')\n",
        "        plt.title('Saída Modelo')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(img_saida_modelo_post.squeeze(), cmap='gray')\n",
        "        plt.title('Saída do Modelo - PÓS')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgFlBHyUk-n1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "cQl90jW20q1D",
        "Zbr9ZHsdDNcT",
        "6OMjPq-V-Ahs",
        "JDxZfL6B7bUm"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
