{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQl90jW20q1D"
      },
      "source": [
        "# Obter dados no drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehPwUJLzSsLC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.config.run_functions_eagerly(True)\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "import time\n",
        "from PIL import Image, ImageDraw\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, Callback\n",
        "from glob import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from keras import layers, models, Input, regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibpCXTgmS_Hi",
        "outputId": "20581241-f887-49ad-87fa-99a0ec29e479"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xSP-0NwWdAq"
      },
      "source": [
        "# Carregamento de dados - Sem Data Augmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yz6Rn0h26UVx"
      },
      "outputs": [],
      "source": [
        "images = []\n",
        "masks = []\n",
        "\n",
        "for path in glob('/content/drive/Shared drives/Grupo T de Tech/Data/dataset_inteli/cropped_images/*/*'):\n",
        "  images.append(path + '/image.tif')\n",
        "  masks.append(path + '/mask.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgFIh5hrObFb"
      },
      "outputs": [],
      "source": [
        "# Função para carregar e pré-processar uma imagem e sua máscara\n",
        "def load_and_preprocess_image(image_path, mask_path, target_size):\n",
        "\n",
        "    image = load_img(image_path, target_size=target_size)\n",
        "    image = img_to_array(image) / 255.0  # Normalização entre 0 e 1\n",
        "\n",
        "    mask = load_img(mask_path, target_size=target_size, color_mode='grayscale')\n",
        "    mask = img_to_array(mask) / 255.0  # Normalização entre 0 e 1\n",
        "\n",
        "    return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Qu_4ZJaKOTGF"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    # Lista para armazenar imagens e máscaras pré-processadas\n",
        "    images_processed = []\n",
        "    masks_processed = []\n",
        "\n",
        "    # Carregar e pré-processar todas as imagens e máscaras\n",
        "    for img_path, mask_path in zip(images, masks):\n",
        "        img, mask = load_and_preprocess_image(img_path, mask_path, target_size=(256, 256))\n",
        "        images_processed.append(img)\n",
        "        masks_processed.append(mask)\n",
        "\n",
        "    # Converter para arrays numpy\n",
        "    images_processed = np.array(images_processed)\n",
        "    masks_processed = np.array(masks_processed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kRApOxtFQ3IX",
        "outputId": "b423f11f-0236-46a6-cfba-911a49562405"
      },
      "outputs": [],
      "source": [
        "images_processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1XJsmj6Iu1W"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(images_processed, masks_processed, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dApijRqyWk_n"
      },
      "source": [
        "# Definição de parâmetros e modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JcNGKwDxX94"
      },
      "outputs": [],
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZMBQc7JL15q"
      },
      "outputs": [],
      "source": [
        "# Função para calcular a sigmoide e converter para 0 ou 1 o output\n",
        "class ThresholdLayer(tf.keras.layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        return tf.where(inputs < 0.5, 0.0, 1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCfQonXrv6nG"
      },
      "outputs": [],
      "source": [
        "# Métrica de acurácia customizada\n",
        "def custom_accuracy(y_train, y_val):\n",
        "    # Calcular a acurácia considerando uma tolerância de 0.5 na predição\n",
        "    y_val_binary = tf.round(y_val)\n",
        "    accuracy = tf.reduce_mean(tf.cast(tf.equal(y_train, y_val_binary), tf.float32))\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJk0H6D6T9F1"
      },
      "outputs": [],
      "source": [
        "def Unet(input_shape, dropout_rate):\n",
        "    num_filters=(16, 32, 64, 128)\n",
        "    kernel_size=3\n",
        "    val_reg=0.001\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "    reg = regularizers.L2(val_reg)\n",
        "\n",
        "    # Encoder (contraction path)\n",
        "    conv1 = layers.Conv2D(num_filters[0], kernel_size, activation='relu', padding='same', kernel_regularizer=reg)(inputs)\n",
        "    conv1 = layers.Conv2D(num_filters[0], kernel_size, activation='relu', padding='same', kernel_regularizer=reg)(conv1)\n",
        "    drop1 = layers.Dropout(dropout_rate)(conv1)\n",
        "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(drop1)\n",
        "\n",
        "    conv2 = layers.Conv2D(num_filters[1], kernel_size, activation='relu', padding='same', kernel_regularizer=reg)(pool1)\n",
        "    conv2 = layers.Conv2D(num_filters[1], kernel_size, activation='relu', padding='same', kernel_regularizer=reg)(conv2)\n",
        "    drop2 = layers.Dropout(dropout_rate)(conv2)\n",
        "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(drop2)\n",
        "\n",
        "    conv3 = layers.Conv2D(num_filters[2], kernel_size, activation='relu', padding='same', kernel_regularizer=reg)(pool2)\n",
        "    conv3 = layers.Conv2D(num_filters[2], kernel_size, activation='relu', padding='same', kernel_regularizer=reg)(conv3)\n",
        "    drop3 = layers.Dropout(dropout_rate)(conv3)\n",
        "    pool3 = layers.MaxPooling2D(pool_size=(2, 2))(drop3)\n",
        "\n",
        "    # Bottleneck\n",
        "    conv4 = layers.Conv2D(num_filters[3], kernel_size, activation='relu', padding='same', kernel_regularizer=reg)(pool3)\n",
        "    conv4 = layers.Conv2D(num_filters[3], kernel_size, activation='relu', padding='same', kernel_regularizer=reg)(conv4)\n",
        "    drop4 = layers.Dropout(dropout_rate)(conv4)\n",
        "\n",
        "    # Decoder (expansion path)\n",
        "    up5 = layers.Conv2DTranspose(num_filters[2], (2, 2), strides=(2, 2), padding='same')(drop4)\n",
        "    merge5 = layers.concatenate([conv3, up5], axis=3)\n",
        "    conv5 = layers.Conv2D(num_filters[2], kernel_size, activation='relu', padding='same', kernel_regularizer=reg)(merge5)\n",
        "    conv5 = layers.Conv2D(num_filters[2], kernel_size, activation='relu', padding='same', kernel_regularizer=reg)(conv5)\n",
        "\n",
        "    up6 = layers.Conv2DTranspose(num_filters[1], (2, 2), strides=(2, 2), padding='same')(conv5)\n",
        "    merge6 = layers.concatenate([conv2, up6], axis=3)\n",
        "    conv6 = layers.Conv2D(num_filters[1], kernel_size, activation='relu', padding='same', kernel_regularizer=reg)(merge6)\n",
        "    conv6 = layers.Conv2D(num_filters[1], kernel_size, activation='relu', padding='same', kernel_regularizer=reg)(conv6)\n",
        "\n",
        "    up7 = layers.Conv2DTranspose(num_filters[0], (2, 2), strides=(2, 2), padding='same')(conv6)\n",
        "    merge7 = layers.concatenate([conv1, up7], axis=3)\n",
        "    conv7 = layers.Conv2D(num_filters[0], kernel_size, activation='relu', padding='same', kernel_regularizer=reg)(merge7)\n",
        "    conv7 = layers.Conv2D(num_filters[0], kernel_size, activation='relu', padding='same', kernel_regularizer=reg)(conv7)\n",
        "\n",
        "    outputs = layers.Conv2D(1, 1, activation='sigmoid')(conv7)  # Saída com um canal (máscara binária)\n",
        "\n",
        "    threshold_output = ThresholdLayer()(outputs)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OIxkz9tyUEb8",
        "outputId": "0a6f4f77-8df1-422d-9d4b-66dcf4bf441b"
      },
      "outputs": [],
      "source": [
        "# Criar modelo U-Net\n",
        "model = Unet(input_shape=(256, 256, 3), dropout_rate=0.3)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_K8INbM9Wpi8"
      },
      "source": [
        "# Treino do modelo - GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTLb8OpzUHrj",
        "outputId": "4ca5d9d7-2033-494c-84ef-e2a0e079de06"
      },
      "outputs": [],
      "source": [
        "callbacks = early_stopping\n",
        "with tf.device('/gpu:0'):\n",
        "    # Compilar o modelo\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=[custom_accuracy])\n",
        "\n",
        "    # Calcula o tempo de treino\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Definições\n",
        "    max_epochs = 200\n",
        "    batch_size = 16\n",
        "\n",
        "    # Treinar o modelo\n",
        "    H = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=max_epochs, batch_size=batch_size, callbacks=callbacks)\n",
        "\n",
        "    # Para o cronômetro e salva o tempo de treino\n",
        "    training_time_gpu = time.time() - start_time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_XrQw1fWtkp"
      },
      "source": [
        "## Avaliação do modelo - GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "IpbWkEwibEV2",
        "outputId": "204e1b4a-ab56-49d1-e863-df8eeaf81c3a"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    # Mostrando resultados\n",
        "    plt.style.use(\"ggplot\")\n",
        "    plt.figure()\n",
        "    plt.plot(H.epoch, H.history[\"loss\"], label=\"train_loss\")\n",
        "    plt.plot(H.epoch, H.history[\"val_loss\"], label=\"val_loss\")\n",
        "    plt.plot(H.epoch, H.history[\"custom_accuracy\"], label=\"train_acc\")\n",
        "    plt.plot(H.epoch, H.history[\"val_custom_accuracy\"], label=\"val_acc\")\n",
        "    plt.title(\"Training Loss and Accuracy - GPU\")\n",
        "    plt.xlabel(\"Epoch #\")\n",
        "    plt.ylabel(\"Loss/Accuracy\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXe7NUljUoKH",
        "outputId": "6eb034b8-a352-4f61-d27e-85425cea9980"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    # Calcula o tempo de inferência\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Avaliar o modelo nos dados de teste\n",
        "    results = model.evaluate(X_val, y_val)\n",
        "\n",
        "    # Para o cronômetro e salva o tempo de treino\n",
        "    inference_time_gpu = time.time() - start_time\n",
        "\n",
        "    print(\"Test Loss - GPU:\", results[0])\n",
        "    print(\"Test Accuracy - GPU:\", results[1])\n",
        "\n",
        "    # Prever máscaras usando o modelo\n",
        "    predicted_masks = model.predict(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        },
        "id": "3E-mOKTEWw90",
        "outputId": "7044da68-1c90-45d7-ead1-9f9427bfcff9"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    # Obter métricas de precisão e perda do histórico de treinamento\n",
        "    acc = H.history['custom_accuracy']\n",
        "    val_acc = H.history['val_custom_accuracy']\n",
        "    loss = H.history['loss']\n",
        "    val_loss = H.history['val_loss']\n",
        "\n",
        "    # Número de épocas\n",
        "    epochs = range(1, len(acc) + 1)\n",
        "\n",
        "    # Plotar precisão do conjunto de treino e validação\n",
        "    plt.plot(epochs, acc, 'r', label='Precisão do Conjunto de Treino')\n",
        "    plt.plot(epochs, val_acc, 'b', label='Precisão do Conjunto de Validação')\n",
        "    plt.title('Precisão do Conjunto de Treino e Validação - GPU')\n",
        "    plt.xlabel('Épocas')\n",
        "    plt.ylabel('Precisão')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Plotar perda do conjunto de treino e validação\n",
        "    plt.plot(epochs, loss, 'r', label='Perda do Conjunto de Treino')\n",
        "    plt.plot(epochs, val_loss, 'b', label='Perda do Conjunto de Validação')\n",
        "    plt.title('Perda do Conjunto de Treino e Validação - GPU')\n",
        "    plt.xlabel('Épocas')\n",
        "    plt.ylabel('Perda')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "50cPtSMOWIqb",
        "outputId": "78b21b11-b451-40be-ab89-2d770fdddd5f"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    # Gerar as saídas do modelo para um conjunto de entradas de teste\n",
        "    saidas_modelo = model.predict(X_val)\n",
        "\n",
        "    # Iterar sobre cada saída do modelo\n",
        "    for i in range(len(X_val)):\n",
        "        # Obter a entrada correspondente e a saída real\n",
        "        img_entrada = X_val[i]\n",
        "        img_saida_real = y_val[i]\n",
        "\n",
        "        # Obter a saída gerada pelo modelo\n",
        "        img_saida_modelo = saidas_modelo[i]\n",
        "\n",
        "        # Mostrar as imagens\n",
        "        plt.figure(figsize=(12, 4))\n",
        "\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.imshow(img_entrada.squeeze(), cmap='gray')\n",
        "        plt.title('Entrada')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.imshow(img_saida_real.squeeze(), cmap='gray')\n",
        "        plt.title('Saída Esperada')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(img_saida_modelo.squeeze(), cmap='gray')\n",
        "        plt.title('Saída do Modelo - GPU')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8o4pT9GJiYqw",
        "outputId": "fad806ff-566f-4f47-b911-3e86c561707c"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    # Métricas do parceiro de Projeto:\n",
        "\n",
        "    # Lista para armazenar os scores de IoU\n",
        "    iou_scores = []\n",
        "    # Calcular IoUs e determinar predições corretas\n",
        "    correct_predictions = 0\n",
        "    iou_threshold = 0.5\n",
        "    for mask, result in zip(y_val, img_saida_modelo):\n",
        "        intersection = np.logical_and(mask, result)\n",
        "        union = np.logical_or(mask, result)\n",
        "        iou_score = np.sum(intersection) / np.sum(union) if np.sum(union) != 0 else 0\n",
        "        iou_scores.append(iou_score)\n",
        "        # Verificar se a predição é considerada correta (IoU >= threshold)\n",
        "        if iou_score >= iou_threshold:\n",
        "            correct_predictions += 1\n",
        "    # Calcular a média dos IoUs\n",
        "    iou_mean = np.mean(iou_scores)\n",
        "    print('Média dos IoU - GPU:', iou_mean)\n",
        "    # Calcular Coverage Ratio (CovR)\n",
        "    total_predictions = len(iou_scores)\n",
        "    covr = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
        "    print('Coverage Ratio (CovR) - GPU:', covr)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "mOUyygDLvAWU"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
