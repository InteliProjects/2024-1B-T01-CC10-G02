{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQl90jW20q1D"
      },
      "source": [
        "# Obter dados no drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xMX0kYMziwp",
        "outputId": "fdd1f172-46bc-4352-f02e-0dfe342d16f9"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow_model_optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehPwUJLzSsLC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.config.run_functions_eagerly(True)\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "import time\n",
        "from PIL import Image, ImageDraw\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, Callback\n",
        "from glob import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from keras import layers, regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow_model_optimization.sparsity import keras as sparsity\n",
        "from tensorflow.keras.applications import MobileNetV2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibpCXTgmS_Hi",
        "outputId": "b74fa33f-2b38-48a5-c002-7cba25e35ab2"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xSP-0NwWdAq"
      },
      "source": [
        "# Carregamento de dados - Com Data Augmentation e Pré Procesamento\n",
        "\n",
        "Estamos utilizando o processo de data augmentation explicitado no [notebook de préprocessamento e data augmentation](./Sprint04_data_augmentation_com_processamento_imagem.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxE5QCuW1Bvw",
        "outputId": "96e20cd5-917a-4124-de67-132f9b370c07"
      },
      "outputs": [],
      "source": [
        "# Paths\n",
        "dataset_dir = '/content/drive/Shared drives/Grupo T de Tech/Data/datasets_sprint4/data_aug'\n",
        "\n",
        "# Função para carregar e pré-processar uma imagem e sua máscara\n",
        "def load_and_preprocess_image(image_path, mask_path, target_size=(256, 256)):\n",
        "    image = load_img(image_path, target_size=target_size)\n",
        "    image = img_to_array(image) / 255.0  # Normalização entre 0 e 1\n",
        "\n",
        "    mask = load_img(mask_path, target_size=target_size, color_mode='grayscale')\n",
        "    mask = img_to_array(mask) / 255.0  # Normalização entre 0 e 1\n",
        "\n",
        "    return image, mask\n",
        "\n",
        "# Listas para armazenar imagens e máscaras pré-processadas\n",
        "images_processed = []\n",
        "masks_processed = []\n",
        "\n",
        "# Obter lista de todos os arquivos de imagens e máscaras\n",
        "image_files = sorted(glob(os.path.join(dataset_dir, 'processed_image_*.tif')))\n",
        "mask_files = sorted(glob(os.path.join(dataset_dir, 'processed_mask_*.png')))\n",
        "\n",
        "# Verificar se temos o mesmo número de arquivos de imagem e máscara\n",
        "assert len(image_files) == len(mask_files), \"O número de imagens e máscaras não corresponde!\"\n",
        "\n",
        "# Carregar e pré-processar todas as imagens e máscaras\n",
        "for img_path, mask_path in zip(image_files, mask_files):\n",
        "    img, mask = load_and_preprocess_image(img_path, mask_path, target_size=(256, 256))\n",
        "    images_processed.append(img)\n",
        "    masks_processed.append(mask)\n",
        "\n",
        "# Converter para arrays numpy\n",
        "images_processed = np.array(images_processed)\n",
        "masks_processed = np.array(masks_processed)\n",
        "\n",
        "# Dividir em conjuntos de treinamento e validação\n",
        "X_train, X_val, y_train, y_val = train_test_split(images_processed, masks_processed, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Number of training samples: {len(X_train)}\")\n",
        "print(f\"Number of validation samples: {len(X_val)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dApijRqyWk_n"
      },
      "source": [
        "# Definição de parâmetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JcNGKwDxX94"
      },
      "outputs": [],
      "source": [
        "class CyclicLR(Callback):\n",
        "    def __init__(self, base_lr=1e-4, max_lr=1e-3, step_size=2000., mode='triangular'):\n",
        "        super(CyclicLR, self).__init__()\n",
        "\n",
        "        self.base_lr = base_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.step_size = step_size\n",
        "        self.mode = mode\n",
        "        self.iterations = 0\n",
        "        self.history = {}\n",
        "\n",
        "    def clr(self):\n",
        "        cycle = np.floor(1 + self.iterations / (2 * self.step_size))\n",
        "        x = np.abs(self.iterations / self.step_size - 2 * cycle + 1)\n",
        "        lr = self.base_lr + (self.max_lr - self.base_lr) * max(0, (1 - x))\n",
        "        if self.mode == 'triangular2':\n",
        "            lr = lr / float(2 ** (cycle - 1))\n",
        "        elif self.mode == 'exp_range':\n",
        "            lr = lr * (0.999 ** self.iterations)\n",
        "        return lr\n",
        "\n",
        "    def on_train_begin(self, logs=None):\n",
        "        logs = logs or {}\n",
        "        tf.keras.backend.set_value(self.model.optimizer.lr, self.base_lr)\n",
        "\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        self.iterations += 1\n",
        "        lr = self.clr()\n",
        "        tf.keras.backend.set_value(self.model.optimizer.lr, lr)\n",
        "        self.history.setdefault('lr', []).append(lr)\n",
        "        for k, v in logs.items():\n",
        "            self.history.setdefault(k, []).append(v)\n",
        "\n",
        "# Função de callbacks\n",
        "def get_callbacks():\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
        "    clr = CyclicLR(base_lr=1e-4, max_lr=1e-3, step_size=2000., mode='triangular2')\n",
        "    pruning = sparsity.UpdatePruningStep()\n",
        "    return [pruning, early_stopping, reduce_lr, clr]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZMBQc7JL15q"
      },
      "outputs": [],
      "source": [
        "# Função para calcular a sigmoide e converter para 0 ou 1 o output\n",
        "class ThresholdLayer(tf.keras.layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        return tf.where(inputs < 0.5, 0.0, 1.0)\n",
        "\n",
        "# Função para calcular o Dice Coefficient\n",
        "def dice_coefficient(y_train, y_val):\n",
        "    smooth = 1e-6\n",
        "    intersection = tf.reduce_sum(y_train * y_val)\n",
        "    dice_coefficient = (2. * intersection + smooth) / (tf.reduce_sum(y_train) + tf.reduce_sum(y_val) + smooth)\n",
        "    return dice_coefficient\n",
        "\n",
        "# Função de perda de Dice\n",
        "def dice_loss(y_train, y_val):\n",
        "    return 1 - dice_coefficient(y_train, y_val)\n",
        "\n",
        "# Função para calcular a penalidade adicional\n",
        "def penalty_loss(y_train, y_val, penalty_weight):\n",
        "    # Calcular a penalidade considerando a diferença entre y_train e y_val\n",
        "    penalty = tf.reduce_sum(tf.abs(y_train - y_val))\n",
        "    # Multiplicar a penalidade pelo peso da penalidade\n",
        "    weighted_penalty = penalty_weight * penalty\n",
        "    return weighted_penalty\n",
        "\n",
        "# Função de perda combinada\n",
        "def combined_loss(y_train, y_val, penalty_weight):\n",
        "    # Perda padrão (por exemplo, perda de entropia cruzada binária)\n",
        "    standard_loss = tf.keras.losses.binary_crossentropy(y_train, y_val)\n",
        "    # Dice Loss\n",
        "    dice = dice_loss(y_train, y_val)\n",
        "    # Penalidade adicional\n",
        "    penalty = penalty_loss(y_train, y_val, penalty_weight)\n",
        "    # Perda total = perda padrão + penalidade + Dice Loss\n",
        "    total_loss = standard_loss + penalty + dice\n",
        "    return total_loss\n",
        "\n",
        "# Métrica de acurácia customizada\n",
        "def custom_accuracy(y_train, y_val):\n",
        "    # Calcular a acurácia considerando uma tolerância de 0.5 na predição\n",
        "    y_val_binary = tf.round(y_val)\n",
        "    accuracy = tf.reduce_mean(tf.cast(tf.equal(y_train, y_val_binary), tf.float32))\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5btDL6KcqLR8"
      },
      "source": [
        "# Modelo Pré-treinado MobileNetV2\n",
        "\n",
        "O modelo que utilizamos para fazer o transfer learning é o MobileNetV2, que pode ser encontrado o artigo de sua publicação no link:\n",
        "https://doi.org/10.48550/arXiv.1801.04381"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "V6otxFOrpik_",
        "outputId": "b2567c9e-995c-454b-d1cc-9c7085ba1c7c"
      },
      "outputs": [],
      "source": [
        "# Carregar o modelo MobileNetV2 pré-treinado\n",
        "pre_trained_model = MobileNetV2(weights='imagenet', include_top=False)\n",
        "\n",
        "# Visualizar a estrutura do modelo\n",
        "pre_trained_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQzJkyv7qVyy"
      },
      "outputs": [],
      "source": [
        "class UNet:\n",
        "    def __init__(self, input_shape, num_filters, kernel_size, dropout_rate, val_reg):\n",
        "        self.input_shape = input_shape\n",
        "        self.num_filters = num_filters\n",
        "        self.kernel_size = kernel_size\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.val_reg = val_reg\n",
        "\n",
        "    def build_model(self):\n",
        "        inputs = tf.keras.Input(shape=self.input_shape)\n",
        "        reg = regularizers.L2(self.val_reg)\n",
        "\n",
        "        # Pruning parameters\n",
        "        pruning_params = {'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity=0.0,\n",
        "                                                                       final_sparsity=0.5,\n",
        "                                                                       begin_step=0,\n",
        "                                                                       end_step=1000,\n",
        "                                                                       frequency=100)}\n",
        "\n",
        "        # Encoder (contraction path)\n",
        "        base_model = MobileNetV2(weights='imagenet', include_top=False, input_tensor=inputs)\n",
        "        base_model.trainable = False\n",
        "\n",
        "        # Extract specific layers for connections\n",
        "        conv2 = base_model.get_layer('block_1_expand_relu').output\n",
        "        conv3 = base_model.get_layer('block_3_expand_relu').output\n",
        "        decoded = base_model.get_layer('block_6_expand_relu').output\n",
        "\n",
        "        # Decoder (expansion path)\n",
        "        up5 = sparsity.prune_low_magnitude(layers.Conv2DTranspose(self.num_filters[2], (2, 2), strides=(2, 2), padding='same'), **pruning_params)(decoded)\n",
        "        up5 = layers.BatchNormalization()(up5)\n",
        "        up5 = layers.Activation('relu')(up5)\n",
        "        merge5 = layers.concatenate([conv3, up5], axis=3)\n",
        "        conv5 = layers.Conv2D(self.num_filters[2], self.kernel_size, activation='relu', padding='same', kernel_regularizer=reg)(merge5)\n",
        "        conv5 = layers.Conv2D(self.num_filters[2], self.kernel_size, activation='relu', padding='same', kernel_regularizer=reg)(conv5)\n",
        "\n",
        "        up6 = sparsity.prune_low_magnitude(layers.Conv2DTranspose(self.num_filters[1], (2, 2), strides=(2, 2), padding='same'), **pruning_params)(conv5)\n",
        "        up6 = layers.BatchNormalization()(up6)\n",
        "        up6 = layers.Activation('relu')(up6)\n",
        "        merge6 = layers.concatenate([conv2, up6], axis=3)\n",
        "        conv6 = layers.Conv2D(self.num_filters[1], self.kernel_size, activation='relu', padding='same', kernel_regularizer=reg)(merge6)\n",
        "        conv6 = layers.Conv2D(self.num_filters[1], self.kernel_size, activation='relu', padding='same', kernel_regularizer=reg)(conv6)\n",
        "\n",
        "        up7 = sparsity.prune_low_magnitude(layers.Conv2DTranspose(self.num_filters[0], (2, 2), strides=(2, 2), padding='same'), **pruning_params)(conv6)\n",
        "        up7 = layers.BatchNormalization()(up7)\n",
        "        up7 = layers.Activation('relu')(up7)\n",
        "        conv7 = layers.Conv2D(self.num_filters[0], self.kernel_size, activation='relu', padding='same', kernel_regularizer=reg)(up7)\n",
        "        conv7 = layers.Conv2D(self.num_filters[0], self.kernel_size, activation='relu', padding='same', kernel_regularizer=reg)(conv7)\n",
        "\n",
        "        outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(conv7)\n",
        "\n",
        "        model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "        return model\n",
        "\n",
        "    def compile_and_train(self, X_train, y_train, X_val, y_val, max_epochs, batch_size):\n",
        "        model = self.build_model()\n",
        "        callbacks = get_callbacks()\n",
        "\n",
        "        # Compilar o modelo\n",
        "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "                      loss=lambda y_train, y_val: combined_loss(y_train, y_val, 0.001),\n",
        "                      metrics=[custom_accuracy])\n",
        "\n",
        "        model.summary()\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Treinar o modelo\n",
        "        H = model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
        "                      epochs=max_epochs, batch_size=batch_size, callbacks=callbacks)\n",
        "\n",
        "        # Salvar o tempo de treino\n",
        "        training_time_gpu = time.time() - start_time\n",
        "\n",
        "        return H, training_time_gpu, model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loNPT4OttA8L"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, X_val, y_val, H, training_time_gpu, max_epochs):\n",
        "    plt.style.use(\"ggplot\")\n",
        "    plt.figure(figsize=(12, 10))\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    results = model.evaluate(X_val, y_val)\n",
        "\n",
        "    inference_time_gpu = time.time() - start_time\n",
        "\n",
        "    print(\"Test Loss:\", results[0])\n",
        "    print(\"Test Accuracy:\", results[1])\n",
        "\n",
        "    # Prever máscaras usando o modelo\n",
        "    predicted_masks = model.predict(X_val)\n",
        "\n",
        "    # Obter métricas de precisão e perda do treinamento\n",
        "    acc = H.history['custom_accuracy']\n",
        "    val_acc = H.history['val_custom_accuracy']\n",
        "    loss = H.history['loss']\n",
        "    val_loss = H.history['val_loss']\n",
        "\n",
        "    epochs = range(1, len(acc) + 1)\n",
        "\n",
        "    # Plotar precisão do conjunto\n",
        "    plt.subplot(2, 2, 3)\n",
        "    plt.plot(epochs, acc, 'r', label='Precisão do Conjunto de Treino')\n",
        "    plt.plot(epochs, val_acc, 'b', label='Precisão do Conjunto de Validação')\n",
        "    plt.title('Precisão do Conjunto de Treino e Validação')\n",
        "    plt.xlabel('Épocas')\n",
        "    plt.ylabel('Precisão')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plotar perda do conjunto\n",
        "    plt.subplot(2, 2, 4)\n",
        "    plt.plot(epochs, loss, 'r', label='Perda do Conjunto de Treino')\n",
        "    plt.plot(epochs, val_loss, 'b', label='Perda do Conjunto de Validação')\n",
        "    plt.title('Perda do Conjunto de Treino e Validação')\n",
        "    plt.xlabel('Épocas')\n",
        "    plt.ylabel('Perda')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print('Tempo de treino (segundos): ', training_time_gpu)\n",
        "    print('Tempo de treino por época (segundos): ', training_time_gpu / max_epochs)\n",
        "    print('Tempo de inferência (segundos): ', inference_time_gpu)\n",
        "\n",
        "    # Plotando o tempo de treinamento e inferência\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.bar(['Training'], [training_time_gpu], color='orange', label='Training Time')\n",
        "    plt.bar(['Inference'], [inference_time_gpu], color='blue', label='Inference Time')\n",
        "    plt.ylabel('Time (seconds)')\n",
        "    plt.title('Training and Inference Time')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    return predicted_masks, inference_time_gpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUkKiT3jmoXB"
      },
      "source": [
        "# Transfer Learning - MobileNetV2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNt2sNQFfu4f"
      },
      "source": [
        "## Treino e inferência com GPU\n",
        "Para fazer esse teste conecte uma máquina do colab que possua GPU. Embaixo de compartilhar, no canto superior direito está escrito \"Conect\". Clique na seta para baixo ao lado de conectar. Selecione \"Change runtime type\" e selecione uma máquina que tenha GPU no nome. A que utilizamos foi a T4 GPU. Após isso, execute as células do início do notebook até o código abaixo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mM7vOJJNgZrY",
        "outputId": "1c2310ed-e99a-4e37-cff5-96c6515b2c2b"
      },
      "outputs": [],
      "source": [
        "max_epochs = 100\n",
        "\n",
        "unet = UNet(input_shape = (256, 256, 3),\n",
        "            num_filters=(16, 32, 64, 128),\n",
        "            kernel_size = 3,\n",
        "            dropout_rate=0.1,\n",
        "            val_reg =0.01)\n",
        "\n",
        "with tf.device('/gpu:0'):\n",
        "  # Treinando o modelo\n",
        "  H1Net, training_time_gpu1Net, model1Net = unet.compile_and_train(X_train, y_train, X_val, y_val,\n",
        "                                                      max_epochs = max_epochs,\n",
        "                                                      batch_size = 16)\n",
        "\n",
        "\n",
        "  # Avaliando o modelo\n",
        "  predicted_masks1Net, inference_time_gpu1Net = evaluate_model(model1Net, X_val, y_val, H1Net, training_time_gpu1Net, max_epochs=max_epochs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sy1DRMN9moXJ"
      },
      "source": [
        "## Amostragem das máscaras e IoU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7F4F5gFY4r6f",
        "outputId": "9ae23a39-d8e1-44c0-b104-ccbd9c913fc8"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    # Gerar as saídas do modelo para um conjunto de entradas de teste\n",
        "    saidas_modelo1Net = model1Net.predict(X_val)\n",
        "\n",
        "    # Iterar sobre cada saída do modelo\n",
        "    for i in range(len(X_val)):\n",
        "        # Obter a entrada correspondente e a saída real\n",
        "        img_entrada = X_val[i]\n",
        "        img_saida_real = y_val[i]\n",
        "\n",
        "        # Obter a saída gerada pelo modelo\n",
        "        #img_saida_modelo1Net = saidas_modelo1Net[i]\n",
        "        img_saida_modelo1Net = np.where(saidas_modelo1Net[i] < 0.5, 0, 1)\n",
        "\n",
        "        # Mostrar as imagens\n",
        "        plt.figure(figsize=(12, 4))\n",
        "\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.imshow(img_entrada.squeeze(), cmap='gray')\n",
        "        plt.title('Entrada')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.imshow(img_saida_real.squeeze(), cmap='gray')\n",
        "        plt.title('Saída Esperada')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(img_saida_modelo1Net.squeeze(), cmap='gray')\n",
        "        plt.title('Saída do Modelo - GPU')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMZy6GoO4r6g",
        "outputId": "e897ad4b-75a1-4ea7-f87f-628e5b743a8f"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    # Métricas do parceiro de Projeto:\n",
        "\n",
        "    # Lista para armazenar os scores de IoU\n",
        "    iou_scores = []\n",
        "    # Calcular IoUs e determinar predições corretas\n",
        "    correct_predictions = 0\n",
        "    iou_threshold = 0.5\n",
        "    for mask, result in zip(y_val, saidas_modelo1Net):\n",
        "        intersection = np.logical_and(mask, result)\n",
        "        union = np.logical_or(mask, result)\n",
        "        iou_score = np.sum(intersection) / np.sum(union) if np.sum(union) != 0 else 0\n",
        "        iou_scores.append(iou_score)\n",
        "        # Verificar se a predição é considerada correta (IoU >= threshold)\n",
        "        if iou_score >= iou_threshold:\n",
        "            correct_predictions += 1\n",
        "        print('IoU é: ' + str(iou_score))\n",
        "    # Calcular a média dos IoUs\n",
        "    iou_mean = np.mean(iou_scores)\n",
        "    print('Média dos IoU - GPU:', iou_mean)\n",
        "    # Calcular Coverage Ratio (CovR)\n",
        "    total_predictions = len(iou_scores)\n",
        "    covr = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
        "    print('Coverage Ratio (CovR) - GPU:', covr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IN4iOjzRyQf"
      },
      "source": [
        "# Testes com novas imagens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSZXJZ0cSBj-"
      },
      "source": [
        "## Importando as imagens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fyAjsjcR2Xm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def load_masks(masks_dir, target_size=(600, 600), crop_size=(200, 200), final_size=(256, 256)):\n",
        "    masks = []\n",
        "    mask_filenames = []\n",
        "    ordered_masks = sorted(os.listdir(masks_dir))\n",
        "    for mask_name in ordered_masks:\n",
        "        mask_path = os.path.join(masks_dir, mask_name)\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if mask is not None:\n",
        "            if mask.shape[:2] != target_size:\n",
        "                mask = cv2.resize(mask, target_size[::-1], interpolation=cv2.INTER_NEAREST)\n",
        "            cropped_masks = crop_image(mask, crop_size)\n",
        "            resized_masks = [cv2.resize(crop, final_size[::-1], interpolation=cv2.INTER_NEAREST) for crop in cropped_masks]\n",
        "            normalized_masks = [crop / 255.0 for crop in resized_masks]\n",
        "            masks.extend(normalized_masks)\n",
        "            mask_filenames.extend([f\"{os.path.splitext(mask_name)[0]}_crop_{i}\" for i in range(len(normalized_masks))])\n",
        "        else:\n",
        "            print(f\"Failed to load mask: {mask_path}\")\n",
        "    return masks, mask_filenames\n",
        "\n",
        "def load_images(image_dir, target_size=(600, 600), crop_size=(200, 200), final_size=(256, 256)):\n",
        "    images = []\n",
        "    image_filenames = []\n",
        "    ordered_images = sorted(os.listdir(image_dir))\n",
        "    for image_name in ordered_images:\n",
        "        image_path = os.path.join(image_dir, image_name)\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is not None:\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            if image.shape[:2] != target_size:\n",
        "                image = cv2.resize(image, target_size[::-1])\n",
        "            cropped_images = crop_image(image, crop_size)\n",
        "            resized_images = [cv2.resize(crop, final_size[::-1]) for crop in cropped_images]\n",
        "            normalized_images = [crop / 255.0 for crop in resized_images]\n",
        "            images.extend(normalized_images)\n",
        "            image_filenames.extend([f\"{os.path.splitext(image_name)[0]}_crop_{i}\" for i in range(len(normalized_images))])\n",
        "        else:\n",
        "            print(f\"Failed to load image: {image_path}\")\n",
        "    return images, image_filenames\n",
        "\n",
        "def crop_image(image, crop_size=(200, 200)):\n",
        "    crops = []\n",
        "    for i in range(0, image.shape[0], crop_size[0]):\n",
        "        for j in range(0, image.shape[1], crop_size[1]):\n",
        "            crop = image[i:i+crop_size[0], j:j+crop_size[1]]\n",
        "            if crop.shape[0] == crop_size[0] and crop.shape[1] == crop_size[1]:\n",
        "                crops.append(crop)\n",
        "    return crops\n",
        "\n",
        "# Paths\n",
        "masks_dir = '/content/drive/Shared drives/Grupo T de Tech/Data/dataset_inteli_test/masks'\n",
        "image_dir = '/content/drive/Shared drives/Grupo T de Tech/Data/dataset_inteli_test/tci_tifs'\n",
        "\n",
        "# Load images and masks\n",
        "masks_test, mask_filenames = load_masks(masks_dir)\n",
        "images_test, image_filenames = load_images(image_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34LhLotgSFBX",
        "outputId": "3505493d-bcd4-4e91-9d2f-e13f3decf8a9"
      },
      "outputs": [],
      "source": [
        "# verificando o tamanho correto\n",
        "len(images_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRDGi9SFSJm-",
        "outputId": "0e8dbb3d-3c52-4ef0-90c6-58d718ac0e96"
      },
      "outputs": [],
      "source": [
        "# Ensure the images are in the correct format for model prediction\n",
        "images_test = np.array(images_test)\n",
        "\n",
        "# Gerar as saídas do modelo para um conjunto de entradas de teste\n",
        "saidas_novas_imagens_modelo = model1Net.predict(images_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ttfBzu7USPMR",
        "outputId": "970978bb-60f5-4091-ba35-349ddde44cd5"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    # Iterar sobre cada saída do modelo\n",
        "    for i in range(len(images_test)):\n",
        "        # Obter a entrada correspondente e a saída real\n",
        "        img_entrada = images_test[i]\n",
        "        img_saida_real = masks_test[i]\n",
        "\n",
        "        # Obter a saída gerada pelo modelo\n",
        "        img_saida_modelo = saidas_novas_imagens_modelo[i]\n",
        "\n",
        "        # Mostrar as imagens\n",
        "        plt.figure(figsize=(12, 4))\n",
        "\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.imshow(img_entrada.squeeze(), cmap='gray')\n",
        "        plt.title('Entrada')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.imshow(img_saida_real.squeeze(), cmap='gray')\n",
        "        plt.title('Saída Esperada')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(img_saida_modelo.squeeze(), cmap='gray')\n",
        "        plt.title('Saída do Modelo - GPU')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FOtR6fVmL0U",
        "outputId": "24a88cc1-571c-4c41-a80c-4f6682cdb199"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    # Métricas do parceiro de Projeto:\n",
        "\n",
        "    # Lista para armazenar os scores de IoU\n",
        "    iou_scores = []\n",
        "    # Calcular IoUs e determinar predições corretas\n",
        "    correct_predictions = 0\n",
        "    iou_threshold = 0.5\n",
        "    for mask, result in zip(masks_test, saidas_novas_imagens_modelo):\n",
        "        intersection = np.logical_and(mask, result)\n",
        "        union = np.logical_or(mask, result)\n",
        "        iou_score = np.sum(intersection) / np.sum(union) if np.sum(union) != 0 else 0\n",
        "        iou_scores.append(iou_score)\n",
        "        # Verificar se a predição é considerada correta (IoU >= threshold)\n",
        "        if iou_score >= iou_threshold:\n",
        "            correct_predictions += 1\n",
        "        print('IoU é: ' + str(iou_score))\n",
        "    # Calcular a média dos IoUs\n",
        "    iou_mean = np.mean(iou_scores)\n",
        "    print('Média dos IoU - GPU:', iou_mean)\n",
        "    # Calcular Coverage Ratio (CovR)\n",
        "    total_predictions = len(iou_scores)\n",
        "    covr = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
        "    print('Coverage Ratio (CovR) - GPU:', covr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4WO5UXTmikl"
      },
      "source": [
        "# Pós processamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PfsMAkSmkCZ",
        "outputId": "0f0bd7fb-6203-417c-c77b-e4136ed8755e"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/lucasb-eyer/pydensecrf.git\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pydensecrf.densecrf as dcrf\n",
        "from pydensecrf.utils import unary_from_softmax\n",
        "from sklearn.metrics import jaccard_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "def postprocess_mask_with_crf(image, mask, crf_params):\n",
        "    softmax = np.stack([1 - mask, mask], axis=-1)\n",
        "    softmax = np.ascontiguousarray(softmax.transpose(2, 0, 1))\n",
        "    image = np.ascontiguousarray(image)\n",
        "    image_uint8 = (image * 255).astype(np.uint8)\n",
        "    d = dcrf.DenseCRF2D(image.shape[1], image.shape[0], 2)\n",
        "    unary = unary_from_softmax(softmax)\n",
        "    d.setUnaryEnergy(unary)\n",
        "    d.addPairwiseGaussian(sxy=crf_params['sxy'], compat=crf_params['compat'])\n",
        "    d.addPairwiseBilateral(sxy=crf_params['sxy_bilateral'], srgb=crf_params['srgb'], rgbim=image_uint8, compat=crf_params['compat_bilateral'])\n",
        "    Q = d.inference(5)\n",
        "    refined_mask = np.argmax(Q, axis=0).reshape((image.shape[0], image.shape[1]))\n",
        "    return refined_mask / 255.0\n",
        "\n",
        "best_crf_params = {\n",
        "    'sxy': 5,\n",
        "    'compat': 3,\n",
        "    'sxy_bilateral': 81,\n",
        "    'srgb': 10,\n",
        "    'compat_bilateral': 20\n",
        "}\n",
        "\n",
        "# Cálculo para operações morfológicas\n",
        "def postprocess_mask_with_morphology(mask, morph_params):\n",
        "    refined_mask = (mask * 255).astype(np.uint8)\n",
        "    kernel = cv2.getStructuringElement(morph_params['shape'], morph_params['kernel_size'])\n",
        "    if morph_params['operation'] == 'open':\n",
        "        refined_mask = cv2.morphologyEx(refined_mask, cv2.MORPH_OPEN, kernel, iterations=morph_params['iterations'])\n",
        "    elif morph_params['operation'] == 'close':\n",
        "        refined_mask = cv2.morphologyEx(refined_mask, cv2.MORPH_CLOSE, kernel, iterations=morph_params['iterations'])\n",
        "    elif morph_params['operation'] == 'dilate':\n",
        "        refined_mask = cv2.dilate(refined_mask, kernel, iterations=morph_params['iterations'])\n",
        "    elif morph_params['operation'] == 'erode':\n",
        "        refined_mask = cv2.erode(refined_mask, kernel, iterations=morph_params['iterations'])\n",
        "    return refined_mask / 255.0\n",
        "\n",
        "best_morph_params = {\n",
        "    'kernel_size': (3,3),\n",
        "    'iterations': 1,\n",
        "    'operation': 'dilate',\n",
        "    'shape': cv2.MORPH_CROSS\n",
        "}\n",
        "\n",
        "def morphology_then_crf(image, mask, morph_params, crf_params):\n",
        "    morph_mask = postprocess_mask_with_morphology(mask, morph_params)\n",
        "    refined_mask = postprocess_mask_with_crf(image, morph_mask, crf_params)\n",
        "    return refined_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iL6rXWeInTHi"
      },
      "outputs": [],
      "source": [
        "# Pós-processar as máscaras preditas com CRF denso\n",
        "saidas_modelo_postprocessed = np.array([morphology_then_crf(images_test[i], saidas_novas_imagens_modelo[i].squeeze(), best_morph_params, best_crf_params) for i in range(len(saidas_novas_imagens_modelo))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "O94vp7orn3qs",
        "outputId": "78c002e4-eedf-4243-caa8-0526c35c2ab4"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    # Iterar sobre cada saída do modelo\n",
        "    for i in range(len(images_test)):\n",
        "        # Obter a entrada correspondente e a saída real\n",
        "        img_entrada = masks_test[i]\n",
        "        img_saida_real = saidas_novas_imagens_modelo[i]\n",
        "\n",
        "        # Obter a saída gerada pelo modelo\n",
        "        img_saida_modelo = saidas_modelo_postprocessed[i]\n",
        "\n",
        "        # Mostrar as imagens\n",
        "        plt.figure(figsize=(12, 4))\n",
        "\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.imshow(img_entrada.squeeze(), cmap='gray')\n",
        "        plt.title('saida real')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.imshow(img_saida_real.squeeze(), cmap='gray')\n",
        "        plt.title('Saída modelo')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(img_saida_modelo.squeeze(), cmap='gray')\n",
        "        plt.title('Saída do Modelo - pós')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pushMzE7oAvz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "cQl90jW20q1D",
        "3xSP-0NwWdAq"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
