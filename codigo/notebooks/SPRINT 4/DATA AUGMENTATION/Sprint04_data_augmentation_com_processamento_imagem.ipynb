{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9sLIH5p_0jF"
      },
      "source": [
        "## Data Augmentation com Pré-processamento de Imagens\n",
        "\n",
        "Este notebook abrange o mesmo processo de Data Augmentation explicado anteriormente e detalhado no notebook da Sprint 3 [Notebook Sprint 4](../../SPRINT%203/DATA%20AUGMENTATION/20240524%20-%20Data%20Augmentation.ipynb).\n",
        "\n",
        "Contudo, alterações foram feitas no pré-processamento. Após a realização de testes com o pré-processamento anterior, observamos que o processo de Data Augmentation resultava em uma redução de cerca de 10% na acurácia do modelo, além de comprometer a qualidade das máscaras preditas.\n",
        "\n",
        "Além disso, percebemos que o processo de salvamento das imagens foi afetado. A função responsável por esta tarefa estava gerando imagens com um contraste inferior ao necessário, o que prejudicava os processos de convolução.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYiAf2kBJjDC",
        "outputId": "fbb6fa95-8fd7-46df-f707-531d15ec0e20"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5Y20_9xPI_E"
      },
      "outputs": [],
      "source": [
        "def load_masks(masks_dir, target_size=(600, 600)):\n",
        "    masks = []\n",
        "    ordered_masks = sorted(os.listdir(masks_dir))\n",
        "    mask_filenames = []\n",
        "    for mask_name in ordered_masks:\n",
        "        mask_path = os.path.join(masks_dir, mask_name)\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if mask is not None:\n",
        "            if mask.shape[:2] != target_size:\n",
        "                mask = cv2.resize(mask, target_size[::-1], interpolation=cv2.INTER_NEAREST)\n",
        "            masks.append(mask)\n",
        "            mask_filenames.append(os.path.splitext(mask_name)[0])\n",
        "        else:\n",
        "            print(f\"Failed to load mask: {mask_path}\")\n",
        "    return masks, mask_filenames\n",
        "\n",
        "def load_images(image_dir, target_size=(600, 600)):\n",
        "    images = []\n",
        "    ordered_images = sorted(os.listdir(image_dir))\n",
        "    image_filenames = []\n",
        "    for image_name in ordered_images:\n",
        "        image_path = os.path.join(image_dir, image_name)\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        if image is not None:\n",
        "            if image.shape[:2] != target_size:\n",
        "                image = cv2.resize(image, target_size[::-1])\n",
        "            images.append(image)\n",
        "            image_filenames.append(os.path.splitext(image_name)[0])\n",
        "        else:\n",
        "            print(f\"Failed to load image: {image_path}\")\n",
        "    return images, image_filenames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHEW1mn5_0jO"
      },
      "source": [
        "### Descrição do Processo de Melhoria de Imagem (Enhance Image)\n",
        "\n",
        "O método *enhance_image* descrito no código realiza uma série de operações para aumentar a qualidade visual das imagens, baseando-se em técnicas bem estabelecidas de processamento de imagem. A principal referência para essas técnicas é o artigo \"A Comprehensive Review of Image Enhancement Techniques\" de Raman Maini e Himanshu Aggarwal, que oferece uma visão aprofundada sobre as técnicas de melhoria de imagem.\n",
        "\n",
        "#### Conversão para Escala de Cinza\n",
        "A conversão de imagens coloridas para escala de cinza simplifica o processamento subsequente ao focar nas intensidades dos pixels, eliminando as informações de cor que podem não ser necessárias para certas análises. Este passo é essencial, pois muitas técnicas de melhoria de imagem funcionam melhor em imagens em escala de cinza.\n",
        "\n",
        "#### Equalização de Histograma\n",
        "A equalização de histograma redistribui os valores de intensidade dos pixels para melhorar o contraste global da imagem. Esta técnica é especialmente útil em imagens com iluminação desigual, tornando os detalhes mais visíveis e uniformizando a distribuição de brilho. O artigo de Maini e Aggarwal destaca que a equalização de histograma é eficaz em melhorar a visualização de detalhes em imagens que têm áreas de baixo contraste.\n",
        "\n",
        "#### Mascaramento de Nitidez\n",
        "Para melhorar a nitidez da imagem, o método utiliza o mascaramento de nitidez, uma técnica que envolve a suavização da imagem original para reduzir o ruído e, em seguida, a combinação da imagem suavizada com a imagem original para realçar bordas e detalhes finos. Esta técnica melhora a clareza visual da imagem, tornando os detalhes mais proeminentes.\n",
        "\n",
        "### Justificativas para as Modificações\n",
        "1. **Conversão para Escala de Cinza**: Simplifica o processamento e foca nas intensidades dos pixels.\n",
        "2. **Equalização de Histograma**: Melhora o contraste, destacando detalhes em áreas de baixo contraste.\n",
        "3. **Mascaramento de Nitidez**: Realça bordas e detalhes, aumentando a clareza e definição da imagem.\n",
        "\n",
        "### Referências\n",
        "\n",
        "- Maini, R., & Aggarwal, H. (2010). A Comprehensive Review of Image Enhancement Techniques. *Journal of Computing, 2*(3). Disponível em: [arXiv](https://doi.org/10.48550/arXiv.1003.4053)\n",
        "\n",
        "### Referências adicionais\n",
        "- OpenCV. (2024). Histogram Equalization. Disponível em: https://docs.opencv.org/3.4/d4/d1b/tutorial_histogram_equalization.html\n",
        "\n",
        "- Kaggle. (2018). Data Science Bowl 2018 Discussion. Disponível em: https://www.kaggle.com/c/data-science-bowl-2018/discussion/54741#477226\n",
        "\n",
        "- Neptune. (2023). Image Segmentation Tips and Tricks from Kaggle Competitions. Disponível em: https://neptune.ai/blog/image-segmentation-tips-and-tricks-from-kaggle-competitions\n",
        "\n",
        "- Dev Genius. (2023). Image Enhancement in Digital Image Processing. Disponível em: https://blog.devgenius.io/image-enhancement-digital-image-processing-21e32f730ced\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5AYSXvr9qcq",
        "outputId": "11fb49fa-ebfd-4aa4-a742-ca67b324fa7c"
      },
      "outputs": [],
      "source": [
        "class ImageProcessingPipeline:\n",
        "    def __init__(self, images, masks):\n",
        "        \"\"\"\n",
        "        Inicializa a classe ImageProcessingPipeline com as imagens e máscaras fornecidas.\n",
        "\n",
        "        Args:\n",
        "            images (list): Lista de arrays representando imagens.\n",
        "            masks (list): Lista de arrays representando máscaras correspondentes às imagens.\n",
        "        \"\"\"\n",
        "        self.images = images\n",
        "        self.masks = masks\n",
        "\n",
        "    def crop_image(self, image, crop_size=(200, 200)):\n",
        "        \"\"\"\n",
        "        Recorta a imagem em pedaços menores de acordo com o tamanho especificado.\n",
        "\n",
        "        Args:\n",
        "            image (array): Array representando a imagem.\n",
        "            crop_size (tuple): Tamanho do recorte desejado. Padrão é (200, 200).\n",
        "\n",
        "        Returns:\n",
        "            list: Lista de recortes da imagem.\n",
        "        \"\"\"\n",
        "        crops = []\n",
        "        for i in range(0, image.shape[0], crop_size[0]):\n",
        "            for j in range(0, image.shape[1], crop_size[1]):\n",
        "                crop = image[i:i+crop_size[0], j:j+crop_size[1]]\n",
        "                if crop.shape[0] == crop_size[0] and crop.shape[1] == crop_size[1]:\n",
        "                    crops.append(crop)\n",
        "        return crops\n",
        "\n",
        "    def augment_images(self, image):\n",
        "        \"\"\"\n",
        "        Realiza aprimoramentos nas imagens, incluindo rotação e espelhamento.\n",
        "\n",
        "        Args:\n",
        "            image (array): Array representando a imagem.\n",
        "\n",
        "        Returns:\n",
        "            list: Lista de imagens aprimoradas.\n",
        "        \"\"\"\n",
        "        aug_images = []\n",
        "        for angle in [0, 90, 180, 270]:\n",
        "            rotated = self.rotate_image(image, angle)\n",
        "            aug_images.append(rotated)\n",
        "            aug_images.append(cv2.flip(rotated, 1))\n",
        "        return aug_images\n",
        "\n",
        "    @staticmethod\n",
        "    def rotate_image(image, angle):\n",
        "        \"\"\"\n",
        "        Rotaciona a imagem pelo ângulo especificado.\n",
        "\n",
        "        Args:\n",
        "            image (array): Array representando a imagem.\n",
        "            angle (int): Ângulo de rotação.\n",
        "\n",
        "        Returns:\n",
        "            array: Array representando a imagem rotacionada.\n",
        "        \"\"\"\n",
        "        (h, w) = image.shape[:2]\n",
        "        center = (w // 2, h // 2)\n",
        "        M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
        "        return cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_NEAREST if len(image.shape) == 2 else cv2.INTER_LINEAR)\n",
        "\n",
        "    @staticmethod\n",
        "    def enhance_image(image):\n",
        "        \"\"\"\n",
        "        Aprimora a imagem aplicando equalização de histograma e máscara de nitidez.\n",
        "\n",
        "        Args:\n",
        "            image (array): Array representando a imagem.\n",
        "\n",
        "        Returns:\n",
        "            array: Array representando a imagem aprimorada.\n",
        "        \"\"\"\n",
        "        if len(image.shape) == 3:\n",
        "            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "        else:\n",
        "            gray = image\n",
        "\n",
        "        equalized = cv2.equalizeHist(gray)\n",
        "        blurred = cv2.GaussianBlur(equalized, (5, 5), 0)\n",
        "        sharpened = cv2.addWeighted(equalized, 1.5, blurred, -0.5, 0)\n",
        "\n",
        "        return sharpened\n",
        "\n",
        "    def process_and_save_images_and_masks(self, output_dir):\n",
        "        \"\"\"\n",
        "        Processa as imagens e máscaras, realiza aprimoramentos e salva os resultados.\n",
        "\n",
        "        Args:\n",
        "            output_dir (str): Diretório de saída para salvar os resultados.\n",
        "        \"\"\"\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "        count = 0\n",
        "        for img, mask in zip(self.images, self.masks):\n",
        "            cropped_images = self.crop_image(img)\n",
        "            cropped_masks = self.crop_image(mask)\n",
        "            for crop_img, crop_mask in zip(cropped_images, cropped_masks):\n",
        "                enhanced_img = self.enhance_image(crop_img)\n",
        "                augmented_imgs = self.augment_images(enhanced_img)\n",
        "                augmented_masks = self.augment_images(crop_mask)\n",
        "                for aug_img, aug_mask in zip(augmented_imgs, augmented_masks):\n",
        "                    aug_img = Image.fromarray(aug_img)\n",
        "                    aug_mask = Image.fromarray(aug_mask)\n",
        "                    output_img_path = os.path.join(output_dir, f'processed_image_{count}.tif')\n",
        "                    output_mask_path = os.path.join(output_dir, f'processed_mask_{count}.png')\n",
        "                    print(f\"Salvando imagem processada em {output_img_path}\")\n",
        "                    print(f\"Salvando máscara processada em {output_mask_path}\")\n",
        "                    aug_img.save(output_img_path)\n",
        "                    aug_mask.save(output_mask_path)\n",
        "                    count += 1\n",
        "\n",
        "    def show_image(self, image):\n",
        "        \"\"\"\n",
        "        Exibe a imagem.\n",
        "\n",
        "        Args:\n",
        "            image (array): Array representando a imagem.\n",
        "        \"\"\"\n",
        "        plt.imshow(image, cmap='gray')\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "# Caminhos\n",
        "masks_dir = '/content/drive/Shared drives/Grupo T de Tech/Data/dataset_inteli/masks'\n",
        "image_dir = '/content/drive/Shared drives/Grupo T de Tech/Data/dataset_inteli/tci_tifs'\n",
        "\n",
        "# Carregar imagens e máscaras\n",
        "masks, mask_filenames = load_masks(masks_dir)\n",
        "images, image_filenames = load_images(image_dir)\n",
        "\n",
        "# Processar e aumentar imagens e máscaras\n",
        "output_dir = '/content/drive/Shareddrives/Grupo T de Tech/Data/datasets_sprint4/data_aug'\n",
        "\n",
        "pipeline = ImageProcessingPipeline(images, masks)\n",
        "pipeline.process_and_save_images_and_masks(output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4gmVWbuDFjM"
      },
      "source": [
        "Abaixo estamos aplicando a mesma função que utilzamos no modelo treinado com as imagens geradas no processo acima, para entender e validar que as imagens foram geradas com sucesso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eG_ka_qmAyPd",
        "outputId": "5866a62a-89ce-4e7c-da1d-e4963dac3ade"
      },
      "outputs": [],
      "source": [
        "from glob import glob\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "# Função para carregar e pré-processar uma imagem e sua máscara\n",
        "def load_and_preprocess_image(image_path, mask_path, target_size=(256, 256)):\n",
        "    image = load_img(image_path, target_size=target_size)\n",
        "    image = img_to_array(image) / 255.0  # Normalização entre 0 e 1\n",
        "\n",
        "    mask = load_img(mask_path, target_size=target_size, color_mode='grayscale')\n",
        "    mask = img_to_array(mask) / 255.0  # Normalização entre 0 e 1\n",
        "\n",
        "    return image, mask\n",
        "\n",
        "# Listas para armazenar imagens e máscaras pré-processadas\n",
        "images_processed = []\n",
        "masks_processed = []\n",
        "\n",
        "# Obter lista de todos os arquivos de imagens e máscaras\n",
        "image_files = sorted(glob(os.path.join(output_dir, 'processed_image_*.tif')))\n",
        "mask_files = sorted(glob(os.path.join(output_dir, 'processed_mask_*.png')))\n",
        "\n",
        "# Verificar se temos o mesmo número de arquivos de imagem e máscara\n",
        "assert len(image_files) == len(mask_files), \"O número de imagens e máscaras não corresponde!\"\n",
        "\n",
        "\n",
        "# Carregar e pré-processar todas as imagens e máscaras\n",
        "for img_path, mask_path in zip(image_files, mask_files):\n",
        "    img, mask = load_and_preprocess_image(img_path, mask_path, target_size=(256, 256))\n",
        "    images_processed.append(img)\n",
        "    masks_processed.append(mask)\n",
        "\n",
        "# Converter para arrays numpy\n",
        "images_processed = np.array(images_processed)\n",
        "masks_processed = np.array(masks_processed)\n",
        "\n",
        "print(f\"Shape of images samples: {images_processed.shape}\")\n",
        "print(f\"Shape of masks samples: {masks_processed.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TNbs9lSHC0Z8",
        "outputId": "a75f8dcb-ab6f-4806-ed32-36d5addb17ea"
      },
      "outputs": [],
      "source": [
        "# Mostrar algumas das imagens processadas\n",
        "for img in images_processed[:8]:  # Mostra as primeiras 8 imagens processadas\n",
        "    pipeline.show_image(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twJNuF3lEbgi"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
