{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atyNYKI5RdqL",
        "outputId": "9634e69c-60b7-4d93-b1ed-c4a5906170ba"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6UivDHREQAr",
        "outputId": "c29bd51b-c254-4277-ce8f-d28831d17a63"
      },
      "outputs": [],
      "source": [
        "!pip install -q git+https://github.com/tensorflow/examples.git\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "import torch.nn.functional as F\n",
        "from glob import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import Sequence\n",
        "from keras.utils import to_categorical\n",
        "from skimage.transform import resize\n",
        "from skimage import img_as_float\n",
        "from tensorflow_examples.models.pix2pix import pix2pix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExLu1TiVNFc6"
      },
      "outputs": [],
      "source": [
        "class GeradorSequencias(Sequence):\n",
        "\n",
        "    def __init__(self, entradas, saidas, batch_size):\n",
        "        self.entradas = entradas\n",
        "        self.saidas = saidas\n",
        "        self.batch_size  = batch_size\n",
        "\n",
        "    #como calcular a quantidade de lotes: (tamanho do dataset / tamanho do lote)\n",
        "    def __len__(self):\n",
        "        return len(self.entradas) // (self.batch_size) # \"//\" pega o inteiro\n",
        "\n",
        "    #forma de acessar o índice do lote ([0, 1]) --> para obter o índice 0, multiplique o nº do lote pelo seu tamanho\n",
        "    def __getitem__(self, id):\n",
        "        esquerda = id * self.batch_size\n",
        "        direita = min(esquerda + self.batch_size, len(self.entradas))\n",
        "        batch_entradas = self.entradas[esquerda:direita]\n",
        "        batch_saidas = self.saidas[esquerda:direita]\n",
        "\n",
        "        #redimensionar as imagens de entrada (já está normalizada)\n",
        "        entradas_redimensionadas = []\n",
        "        for caminho_img in batch_entradas:\n",
        "            img_entrada = img.imread(caminho_img + 'image.tif')\n",
        "            img_redimensionada_entrada = resize(img_entrada, (256, 256))\n",
        "            entradas_redimensionadas.append(img_redimensionada_entrada)\n",
        "\n",
        "        #redimensionar as máscaras de saída\n",
        "        saidas_redimensionadas = []\n",
        "        for caminho_img in batch_saidas:\n",
        "            img_saida = img.imread(caminho_img + 'mask.png')\n",
        "            img_redimensionada_saida = resize(img_saida, (256, 256))\n",
        "            img_redimensionada_saida = np.array(img_redimensionada_saida)\n",
        "            min_val = np.min(img_redimensionada_saida)\n",
        "            max_val = np.max(img_redimensionada_saida)\n",
        "            img_redimensionada_saida = (img_redimensionada_saida - min_val) / (max_val - min_val)\n",
        "            threshold = 0.5\n",
        "            img_redimensionada_saida = tf.where(img_redimensionada_saida < threshold, 0.0, 1.0)\n",
        "            saidas_redimensionadas.append(img_redimensionada_saida)\n",
        "\n",
        "        return np.array(entradas_redimensionadas), np.array(saidas_redimensionadas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PSECdShKdT0",
        "outputId": "c5bbad4c-4076-4ff3-e471-139e652f36de"
      },
      "outputs": [],
      "source": [
        "#atribuição dos dados de satétite, contendo talhões e suas máscaras\n",
        "caminhos = glob('/content/drive/Shareddrives/Grupo T de Tech/Data/dataset_inteli/cropped_images/*/*/')\n",
        "np.random.shuffle(caminhos)\n",
        "\n",
        "#dividindo os caminhos em conjuntos de treino e teste\n",
        "caminhos_treino, caminhos_teste = train_test_split(caminhos, test_size=0.3, random_state=42)\n",
        "print(\"Número de caminhos de treino:\", len(caminhos_treino))\n",
        "print(\"Número de caminhos de treino:\", len(caminhos_teste))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrEOZs_9PHQx"
      },
      "outputs": [],
      "source": [
        "#variável que contem o X_treino e Y_treino (saída do __getitem__)\n",
        "sequencia_treino = GeradorSequencias(caminhos_treino, caminhos_treino, 128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xrt4tICXOk04"
      },
      "outputs": [],
      "source": [
        "#variável que contem o X_teste e Y_teste (saída do __getitem__)\n",
        "sequencia_teste = GeradorSequencias(caminhos_teste, caminhos_teste, 128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHSQeWkAPH2K",
        "outputId": "d9316b96-6845-4d35-ae53-906fcfef5619"
      },
      "outputs": [],
      "source": [
        "#verificação da normalização da imagem tif (1ª parte) e da máscara binária (2ª parte)\n",
        "sequencia_teste.__getitem__(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0iIPPs6pW6Kk",
        "outputId": "0f7e6c22-fa5d-4a8b-9f73-9bb90dc0ca22"
      },
      "outputs": [],
      "source": [
        "# Obtendo o primeiro lote de entradas e saídas\n",
        "primeiro_lote_entradas, primeiro_lote_saidas = sequencia_teste.__getitem__(0)\n",
        "\n",
        "# Iterando sobre cada entrada e saída no lote\n",
        "for i in range(len(primeiro_lote_entradas)):\n",
        "    # Convertendo a entrada e saída para imagens\n",
        "    img_entrada = primeiro_lote_entradas[i]\n",
        "    img_saida = primeiro_lote_saidas[i]\n",
        "\n",
        "    # Mostrando as imagens\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(img_entrada)\n",
        "    plt.title('Entrada')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(img_saida, cmap='gray')\n",
        "    plt.title('Saída')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXmssX1XzH-j",
        "outputId": "74e981fa-e6ff-4a5b-cf59-c66fabe877ac"
      },
      "outputs": [],
      "source": [
        "#encoder - modelo MobileNetV2 pré-treinado\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=[256, 256, 3], include_top=False)\n",
        "\n",
        "# Usar as ativações das camadas\n",
        "layer_names = [\n",
        "    'block_1_expand_relu',   # 64x64\n",
        "    'block_3_expand_relu',   # 32x32\n",
        "    'block_6_expand_relu',   # 16x16\n",
        "    'block_13_expand_relu',  # 8x8\n",
        "    'block_16_project',      # 4x4\n",
        "]\n",
        "base_model_outputs = [base_model.get_layer(name).output for name in layer_names]\n",
        "\n",
        "# Criar modelo de feature de extração\n",
        "down_stack = tf.keras.Model(inputs=base_model.input, outputs=base_model_outputs)\n",
        "\n",
        "down_stack.trainable = False\n",
        "\n",
        "# Decoder/upsampler - série de blocos de upsample implementados nos exemplos do TensorFlow:\n",
        "up_stack = [\n",
        "    pix2pix.upsample(512, 3),  # 4x4 -> 8x8\n",
        "    pix2pix.upsample(256, 3),  # 8x8 -> 16x16\n",
        "    pix2pix.upsample(128, 3),  # 16x16 -> 32x32\n",
        "    pix2pix.upsample(64, 3),   # 32x32 -> 64x64\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Itwgm11lY6sB"
      },
      "outputs": [],
      "source": [
        "def UNet(output_channels:int):\n",
        "  inputs = tf.keras.layers.Input(shape=[256, 256, 3])\n",
        "\n",
        "  # Downsampling\n",
        "  skips = down_stack(inputs)\n",
        "  x = skips[-1]\n",
        "  skips = reversed(skips[:-1])\n",
        "\n",
        "  # Upsampling e conexões\n",
        "  for up, skip in zip(up_stack, skips):\n",
        "    x = up(x)\n",
        "    concat = tf.keras.layers.Concatenate()\n",
        "    x = concat([x, skip])\n",
        "\n",
        "  # Última camada do modelo\n",
        "  last = tf.keras.layers.Conv2DTranspose(\n",
        "      filters=output_channels, kernel_size=3, strides=2,\n",
        "      padding='same')  #64x64 -> 256x256\n",
        "\n",
        "  x = last(x)\n",
        "\n",
        "  # Ativação sigmoid\n",
        "  x = tf.keras.layers.Activation('sigmoid')(x)\n",
        "\n",
        "  return tf.keras.Model(inputs=inputs, outputs=x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "f-vChhORRGdc",
        "outputId": "faca9077-3896-402b-ce26-5945ef7ee046"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    OUTPUT_CLASSES = 1\n",
        "    model = UNet(output_channels=OUTPUT_CLASSES)\n",
        "    model.compile(optimizer='adam',\n",
        "                loss=\"binary_crossentropy\",\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "    tf.keras.utils.plot_model(model, show_shapes=True)\n",
        "\n",
        "    EPOCHS = 100\n",
        "    BATCH_SIZE = 128\n",
        "\n",
        "    H = model.fit(sequencia_treino, epochs=EPOCHS,\n",
        "                            validation_data=sequencia_teste)\n",
        "\n",
        "    # Avaliar o modelo\n",
        "    loss, accuracy = model.evaluate(sequencia_teste)\n",
        "    print(f'Acurácia do modelo: {accuracy}')\n",
        "\n",
        "    # Mostrar o resultado\n",
        "    plt.style.use(\"ggplot\")\n",
        "    plt.figure()\n",
        "    plt.plot(H.epoch, H.history[\"loss\"], label=\"train_loss\")\n",
        "    plt.plot(H.epoch, H.history[\"val_loss\"], label=\"val_loss\")\n",
        "    plt.plot(H.epoch, H.history[\"accuracy\"], label=\"train_acc\")\n",
        "    plt.plot(H.epoch, H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "    plt.title(\"Training Loss and Accuracy\")\n",
        "    plt.xlabel(\"Epoch #\")\n",
        "    plt.ylabel(\"Loss/Accuracy\")\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "T7xbaQnRccgA",
        "outputId": "50eb2f26-dfbf-4736-eff2-37be8e6de8a3"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    # Gerar as saídas do modelo para um conjunto de entradas de teste\n",
        "    saidas_modelo = model.predict(sequencia_teste)\n",
        "\n",
        "    # Iterar sobre cada saída do modelo\n",
        "    for i in range(BATCH_SIZE):\n",
        "        # Obter a entrada correspondente e a saída real\n",
        "        img_entrada = primeiro_lote_entradas[i]\n",
        "        img_saida_real = primeiro_lote_saidas[i]\n",
        "\n",
        "        # Obter a saída gerada pelo modelo\n",
        "        img_saida_modelo = saidas_modelo[i]\n",
        "\n",
        "        #Aplicar limiarização apenas durante a inferência\n",
        "        img_saida_modelo_limiarizada = np.where(img_saida_modelo < 0.5, 0, 1)\n",
        "\n",
        "        # Mostrar as imagens\n",
        "        plt.figure(figsize=(12, 4))\n",
        "\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.imshow(img_entrada)\n",
        "        plt.title('Entrada')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.imshow(img_saida_real, cmap='gray')\n",
        "        plt.title('Saída Esperada')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(img_saida_modelo_limiarizada, cmap='gray')\n",
        "        plt.title('Saída do Modelo (Limiarizada)')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ro6UI8CPfwfe"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
