{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pK_QvweQpOj",
        "outputId": "f29d302e-431f-4130-b3f9-91bbe15acd03"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import re\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHflRqFzbfye"
      },
      "source": [
        "## Crop das images e respectivas segmentações\n",
        "Todas as 18 imagens(15 de treino + 3 de teste) de 1200x1200 dadas pelo parceiro serão cropadas em 36 imagens de 200x200, assim como suas respectivas masks, e serão armazenadas na pasta 'cropped_images' na pasta de teste e na de treino no drive do grupo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsVD3zxUgBuj"
      },
      "source": [
        "### Treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EgWF9KXcIs_"
      },
      "outputs": [],
      "source": [
        "train_tifs_path = '/content/drive/Shared drives/Grupo T de Tech/Data/dataset_inteli/tci_tifs/'\n",
        "train_masks_path = '/content/drive/Shared drives/Grupo T de Tech/Data/dataset_inteli/masks/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvVt14-Wc3wl"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "ordered_masks = sorted(os.listdir(train_masks_path))\n",
        "ordered_tifs = sorted(os.listdir(train_tifs_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqyRcc2db7QR"
      },
      "outputs": [],
      "source": [
        "for i in range(len(ordered_masks)):\n",
        "  count = 0\n",
        "  mask = Image.open('/content/drive/Shared drives/Grupo T de Tech/Data/dataset_inteli/masks/' + ordered_masks[i])\n",
        "  tif = Image.open('/content/drive/Shared drives/Grupo T de Tech/Data/dataset_inteli/tci_tifs/' + ordered_tifs[i])\n",
        "  image_name = re.findall(r'\\d+', ordered_masks[i])\n",
        "  os.mkdir('/content/drive/Shared drives/Grupo T de Tech/Data/dataset_inteli/cropped_images/{}'.format((''.join(image_name))))\n",
        "  for row in range(6):\n",
        "    for col in range(6):\n",
        "      os.mkdir('/content/drive/Shared drives/Grupo T de Tech/Data/dataset_inteli/cropped_images/{}/{}'.format((''.join(image_name)), (count)))\n",
        "      left = (col)*200\n",
        "      top = (row)*200\n",
        "      right = left + 200\n",
        "      bottom = top + 200\n",
        "\n",
        "      cropped_mask = mask.crop((left, top, right, bottom))\n",
        "      cropped_tif = tif.crop((left, top, right, bottom))\n",
        "      cropped_mask.save(os.path.join('/content/drive/Shared drives/Grupo T de Tech/Data/dataset_inteli/cropped_images/{}/{}'.format((''.join(image_name)), (count)), 'mask.png'))\n",
        "      cropped_tif.save(os.path.join('/content/drive/Shared drives/Grupo T de Tech/Data/dataset_inteli/cropped_images/{}/{}'.format((''.join(image_name)), (count)), 'image.tif'))\n",
        "      count += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GmR8umBgD0u"
      },
      "source": [
        "### Teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgCXxIgkjN7M"
      },
      "outputs": [],
      "source": [
        "test_tifs_path = '/content/drive/Shared drives/Grupo T de Tech/Data/dataset_inteli_test/tci_tifs/'\n",
        "test_masks_path = '/content/drive/Shared drives/Grupo T de Tech/Data/dataset_inteli_test/masks/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kH_ktZjAjN7N"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "ordered_masks = sorted(os.listdir(test_masks_path))\n",
        "ordered_tifs = sorted(os.listdir(test_tifs_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkNOo-iOjN7N"
      },
      "outputs": [],
      "source": [
        "for i in range(len(ordered_masks)):\n",
        "  count = 0\n",
        "  mask = Image.open('/content/drive/Shared drives/Grupo T de Tech/Data/dataset_inteli_test/masks/' + ordered_masks[i])\n",
        "  tif = Image.open('/content/drive/Shared drives/Grupo T de Tech/Data/dataset_inteli_test/tci_tifs/' + ordered_tifs[i])\n",
        "  image_name = re.findall(r'\\d+', ordered_masks[i])\n",
        "  os.mkdir('/content/drive/Shared drives/Grupo T de Tech/Data/dataset_inteli_test/cropped_images/{}'.format((''.join(image_name))))\n",
        "  for row in range(6):\n",
        "    for col in range(6):\n",
        "      os.mkdir('/content/drive/Shared drives/Grupo T de Tech/Data/dataset_inteli_test/cropped_images/{}/{}'.format((''.join(image_name)), (count)))\n",
        "      left = (col)*200\n",
        "      top = (row)*200\n",
        "      right = left + 200\n",
        "      bottom = top + 200\n",
        "\n",
        "      cropped_mask = mask.crop((left, top, right, bottom))\n",
        "      cropped_tif = tif.crop((left, top, right, bottom))\n",
        "      cropped_mask.save(os.path.join('/content/drive/Shared drives/Grupo T de Tech/Data/dataset_inteli_test/cropped_images/{}/{}'.format((''.join(image_name)), (count)), 'mask.png'))\n",
        "      cropped_tif.save(os.path.join('/content/drive/Shared drives/Grupo T de Tech/Data/dataset_inteli_test/cropped_images/{}/{}'.format((''.join(image_name)), (count)), 'image.tif'))\n",
        "      count += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-SdtT3cQj5T"
      },
      "source": [
        "## Carregando as imagens e aplicando kmeans e sharpen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNhdmKcMd0ih",
        "outputId": "b59bc51b-7c23-47e6-f355-6fed85d755d0"
      },
      "outputs": [],
      "source": [
        "os.listdir('/content/drive/Shared drives/Grupo T de Tech/Data/dataset_inteli/cropped_images/575/0')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuB6fVTrQj5V",
        "outputId": "b26b99cd-c59e-47bd-eaf2-ec75d384d09b"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "import tqdm\n",
        "from glob import glob\n",
        "\n",
        "class KMeansImageProcessingPipeline:\n",
        "\tdef __init__(self, base_dir):\n",
        "\t\tself.base_dir = base_dir\n",
        "\n",
        "\tdef read_and_process_image(self, path):\n",
        "\t\timg = cv2.imread(path)\n",
        "\t\timg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\t\treturn img\n",
        "\n",
        "\tdef kmeans_image(self, img, k, attempts=10):\n",
        "\t\t# Redimensionar a imagem para um vetor 1D\n",
        "\t\tvectorized_img = img.reshape((-1,3))\n",
        "\t\tvectorized_img = np.float32(vectorized_img)\n",
        "\n",
        "\t\t# Definir critérios para o algoritmo K-means\n",
        "\t\tcriteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
        "\n",
        "\t\t# Executar o algoritmo K-means\n",
        "\t\tret, label, center = cv2.kmeans(vectorized_img, k, None, criteria, attempts, cv2.KMEANS_PP_CENTERS)\n",
        "\t\tcenter = np.uint8(center)\n",
        "\n",
        "\t\t# Recriar a imagem a partir dos clusters encontrados\n",
        "\t\tres = center[label.flatten()]\n",
        "\t\tresult_image = res.reshape((img.shape))\n",
        "\n",
        "\t\treturn result_image\n",
        "\n",
        "\tdef sharpen_image(self, img):\n",
        "\t\t# Cria um kernel para afiar a imagem\n",
        "\t\tkernel = np.array([[-1,-1,-1],\n",
        "\t\t\t\t\t\t\t\t\t\t\t[-1,9,-1],\n",
        "\t\t\t\t\t\t\t\t\t\t\t[-1,-1,-1]])\n",
        "\n",
        "\t\t# Aplica o kernel na imagem usando filter2D\n",
        "\t\tsharpened_image = cv2.filter2D(img, -1, kernel)\n",
        "\n",
        "\t\treturn sharpened_image\n",
        "\n",
        "\tdef process_all_images(self, k, attempts=10):\n",
        "\t\timg = self.read_and_process_image(self.base_dir)\n",
        "\n",
        "\t\t# Aplica o algoritmo de k-means na imagem\n",
        "\t\tkmeans_img = self.kmeans_image(img, k, attempts)\n",
        "\n",
        "\t\t# Afia a imagem resultante\n",
        "\t\tsharpened_img = self.sharpen_image(kmeans_img)\n",
        "\n",
        "\t\treturn sharpened_img\n",
        "\n",
        "\tdef analyze_kmeans_inertia(self, k_range):\n",
        "\t\tsample_image_path = os.path.join(self.base_dir, os.listdir(self.base_dir)[0])\n",
        "\t\timg = self.read_and_process_image(sample_image_path)\n",
        "\t\tvectorized_img = img.reshape((-1, 3))\n",
        "\t\tvectorized_img = np.float32(vectorized_img)\n",
        "\n",
        "\t\tinertias = []\n",
        "\t\tfor k in k_range:\n",
        "\t\t\t\tkmeans = KMeans(n_clusters=k, random_state=42)\n",
        "\t\t\t\tkmeans.fit(vectorized_img)\n",
        "\t\t\t\tinertias.append(kmeans.inertia_)\n",
        "\n",
        "\t\tplt.figure(figsize=[20, 5])\n",
        "\t\tplt.subplot(1, 2, 1)\n",
        "\t\tplt.plot(k_range, inertias, \"-o\")\n",
        "\t\tplt.xlabel(\"$k$\", fontsize=14)\n",
        "\t\tplt.ylabel(\"Inertia\", fontsize=14)\n",
        "\t\tplt.grid(True)\n",
        "\n",
        "\t\tplt.subplot(1, 2, 2)\n",
        "\t\tplt.plot(k_range[:-1], np.diff(inertias), \"-o\")\n",
        "\t\tplt.xlabel(\"$k$\", fontsize=14)\n",
        "\t\tplt.ylabel(\"Change in inertia\", fontsize=14)\n",
        "\t\tplt.grid(True)\n",
        "\t\tplt.show()\n",
        "\n",
        "# Usage\n",
        "# base_dir = '../../data/dataset_inteli/tci_pngs'\n",
        "processed_images = []\n",
        "for caminho in glob('/content/drive/Shared drives/Grupo T de Tech/Data/dataset_inteli/cropped_images/*/*/*.tif'):\n",
        "\tprint(caminho)\n",
        "\tpipeline = KMeansImageProcessingPipeline(caminho)\n",
        "\tprocessed_images.append(pipeline.process_all_images(5))  # Change k as needed\n",
        "# pipeline.analyze_kmeans_inertia(range(4, 16))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJx1lnEHQj5X"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "o1sbWyktQj5X",
        "outputId": "d634882d-7f0d-42a6-f69f-a9bcd64d3f10"
      },
      "outputs": [],
      "source": [
        "for img in processed_images[:20]:\n",
        "\tplt.imshow(img)\n",
        "\tplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BG8NbcClQj5Y"
      },
      "source": [
        "## Aplicando Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-Y10ZPwQj5Y"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class ImageProcessingPipeline:\n",
        "\tdef __init__(self, images):\n",
        "\t\tself.images = images\n",
        "\n",
        "\t@staticmethod\n",
        "\tdef normalize_image(image):\n",
        "\t\treturn image / 255.0\n",
        "\n",
        "\t@staticmethod\n",
        "\tdef resize_image(image, target_size=(1200, 1200)):\n",
        "\t\treturn cv2.resize(image, target_size)\n",
        "\n",
        "\tdef apply_clahe(self, image):\n",
        "\t\tclahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "\t\treturn clahe.apply(image.astype(np.uint8))\n",
        "\n",
        "\t@staticmethod\n",
        "\tdef crop_image(image, crop_size=(200, 200)):\n",
        "\t\tcrops = []\n",
        "\n",
        "\t\tfor i in range(0, image.shape[0], crop_size[0]):\n",
        "\n",
        "\t\t\tfor j in range(0, image.shape[1], crop_size[1]):\n",
        "\t\t\t\t\tcrop = image[i:i+crop_size[0], j:j+crop_size[1]]\n",
        "\n",
        "\t\t\t\t\tif crop.shape[0] == crop_size[0] and crop.shape[1] == crop_size[1]:\n",
        "\t\t\t\t\t\tcrops.append(crop)\n",
        "\n",
        "\t\treturn crops\n",
        "\n",
        "\tdef augment_images(self, image):\n",
        "\t\taug_images = []\n",
        "\n",
        "\t\tfor angle in [0, 90, 180, 270]:\n",
        "\t\t\trotated = self.rotate_image(image, angle)\n",
        "\t\t\taug_images.append(rotated)\n",
        "\t\t\taug_images.append(cv2.flip(rotated, 1))\n",
        "\n",
        "\t\treturn aug_images\n",
        "\n",
        "\n",
        "\t@staticmethod\n",
        "\tdef rotate_image(image, angle):\n",
        "\t\t(h, w) = image.shape[:2]\n",
        "\t\tcenter = (w // 2, h // 2)\n",
        "\n",
        "\t\tM = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
        "\n",
        "\t\treturn cv2.warpAffine(image, M, (w, h))\n",
        "\n",
        "\tdef process_images(self):\n",
        "\t\tprocessed_images = []\n",
        "\n",
        "\t\tfor img in self.images:\n",
        "\t\t\tnorm_img = ImageProcessingPipeline.normalize_image(img)\n",
        "\t\t\tresized_img = ImageProcessingPipeline.resize_image(norm_img)\n",
        "\n",
        "\t\t\tcropped_images = self.crop_image(resized_img)\n",
        "\n",
        "\t\t\tfor crop in cropped_images:\n",
        "\t\t\t\taugmented_imgs = self.augment_images(crop)\n",
        "\t\t\t\tprocessed_images.extend(augmented_imgs)\n",
        "\n",
        "\t\treturn processed_images\n",
        "\n",
        "\tdef show_image(self, image):\n",
        "\t\tplt.imshow(image, cmap='gray')\n",
        "\t\tplt.axis('off')\n",
        "\t\tplt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GebfgsQrQj5Y"
      },
      "outputs": [],
      "source": [
        "pipeline = ImageProcessingPipeline(processed_images)\n",
        "processed_images_pipeline = pipeline.process_images()\n",
        "\n",
        "# Mostrar algumas das imagens processadas\n",
        "for img in processed_images_pipeline:  # Mostra as primeiras 8 imagens processadas\n",
        "    pipeline.show_image(img)\n",
        "\n",
        "len(processed_images_pipeline)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "tHflRqFzbfye"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
