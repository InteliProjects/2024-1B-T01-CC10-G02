{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMMkvunyTnMU"
      },
      "source": [
        "# Esteira de processamento de imagens para o modelo de classificação\n",
        "\n",
        "Este notebook tem como objetivo gerar imagens para o modelo de classificação da Sprint 2. Portanto, ao final do arquivo estamos salvando imagens que contém talhões em pasta e em outra pasta os arquivos que não contém talhões.\n",
        "\n",
        "Uma amostra das imagens geradas podem ser visualizadas em [`data -> SPRINT 2 -> MODELO DE CLASSIFICACAO`](../../../../data/SPRINT%202/MODELO%20DE%20CLASSIFICACAO/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEwu0OZGMrdx"
      },
      "source": [
        "## Carregando as imagens e aplicando kmeans e sharpen\n",
        "\n",
        "Abaixo estamos implementando o modelo de KMeans e Sharpen criados na Sprint 2. [Referência para o Modelo KMEANS](../../SPRINT%201/20240425%20-%20Implementacao%20KMeans%20para%20Reducao%20de%20Cor.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHgMYr-QUMup"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btfoL54nMrdy"
      },
      "outputs": [],
      "source": [
        "class KMeansImageProcessingPipeline:\n",
        "\tdef __init__(self, base_dir):\n",
        "\t\tself.base_dir = base_dir\n",
        "\n",
        "\tdef read_and_process_image(self, path):\n",
        "\t\timg = cv2.imread(path)\n",
        "\t\timg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\t\treturn img\n",
        "\n",
        "\tdef kmeans_image(self, img, k, attempts=10):\n",
        "\t\t# Redimensionar a imagem para um vetor 1D\n",
        "\t\tvectorized_img = img.reshape((-1,3))\n",
        "\t\tvectorized_img = np.float32(vectorized_img)\n",
        "\n",
        "\t\t# Definir critérios para o algoritmo K-means\n",
        "\t\tcriteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
        "\n",
        "\t\t# Executar o algoritmo K-means\n",
        "\t\tret, label, center = cv2.kmeans(vectorized_img, k, None, criteria, attempts, cv2.KMEANS_PP_CENTERS)\n",
        "\t\tcenter = np.uint8(center)\n",
        "\n",
        "\t\t# Recriar a imagem a partir dos clusters encontrados\n",
        "\t\tres = center[label.flatten()]\n",
        "\t\tresult_image = res.reshape((img.shape))\n",
        "\n",
        "\t\treturn result_image\n",
        "\n",
        "\tdef sharpen_image(self, img):\n",
        "\t\t# Cria um kernel para afiar a imagem\n",
        "\t\tkernel = np.array([[-1,-1,-1],\n",
        "\t\t\t\t\t\t\t\t\t\t\t[-1,9,-1],\n",
        "\t\t\t\t\t\t\t\t\t\t\t[-1,-1,-1]])\n",
        "\n",
        "\t\t# Aplica o kernel na imagem usando filter2D\n",
        "\t\tsharpened_image = cv2.filter2D(img, -1, kernel)\n",
        "\n",
        "\t\treturn sharpened_image\n",
        "\n",
        "\tdef process_all_images(self, k, attempts=10):\n",
        "\t\tprocessed_images = []\n",
        "\n",
        "\t\timages = os.listdir(self.base_dir)\n",
        "\n",
        "\t\tfor image_name in tqdm.tqdm(images):\n",
        "\t\t\tpath = os.path.join(self.base_dir, image_name)\n",
        "\t\t\timg = self.read_and_process_image(path)\n",
        "\n",
        "\t\t\t# Aplica o algoritmo de k-means na imagem\n",
        "\t\t\tkmeans_img = self.kmeans_image(img, k, attempts)\n",
        "\n",
        "\t\t\t# Afia a imagem resultante\n",
        "\t\t\tsharpened_img = self.sharpen_image(kmeans_img)\n",
        "\n",
        "\t\t\t# Adiciona a imagem afiada à lista de retorno\n",
        "\t\t\tprocessed_images.append(sharpened_img)\n",
        "\n",
        "\t\treturn processed_images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpwLcnj6Mrd0"
      },
      "source": [
        "## Aplicando Data Augmentation\n",
        "\n",
        "Aplicando o processo de Data Augmentation criado na Sprint 1. Esta implementação se diferencia pois compreendemos que não há necessidade de trabalhar com o Algoritmo de Clahe, implementado na Sprint 1, quando utilizamos imagens com mais de 1 dimensão, como no caso atual.\n",
        "\n",
        "Também refatoramos o método `process_images` que agora possui a feature de salvar as imagens geradas.\n",
        "\n",
        "[Referência para Implementação do Data augmentation da Sprint anterior](../../SPRINT%201/20240426%20-%20Imagens%20TIF%20e%20Data%20Augmentation.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNNezwM9Mrd1"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "class AugmentationImageProcessingPipeline:\n",
        "    def __init__(self, output_dir):\n",
        "        self.output_dir = output_dir\n",
        "        # Cria o diretório de saída, se ele não existir\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    @staticmethod\n",
        "    def normalize_image(image):\n",
        "        # Normaliza a imagem dividindo por 255 para que os valores fiquem no intervalo [0,1]\n",
        "        return image / 255.0\n",
        "\n",
        "    @staticmethod\n",
        "    def resize_image(image, target_size):\n",
        "        # Redimensiona a imagem para o tamanho desejado usando OpenCV\n",
        "        return cv2.resize(image, target_size)\n",
        "\n",
        "    @staticmethod\n",
        "    def rotate_image(image, angle):\n",
        "        # Rotaciona a imagem em um determinado ângulo\n",
        "        (h, w) = image.shape[:2]\n",
        "        center = (w // 2, h // 2)  # Calcula o centro da imagem\n",
        "        M = cv2.getRotationMatrix2D(center, angle, 1.0)  # Cria a matriz de rotação\n",
        "        # Aplica a transformação de rotação\n",
        "        return cv2.warpAffine(image, M, (w, h))\n",
        "\n",
        "    def crop_image(self, image, crop_size=(200, 200)):\n",
        "        # Corta a imagem em sub-imagens menores de tamanho fixo\n",
        "        crops = []\n",
        "        img_height, img_width = image.shape[:2]\n",
        "\n",
        "        # Percorre as dimensões da imagem original e realiza os cortes\n",
        "        for row in range(0, img_height, crop_size[0]):\n",
        "            for col in range(0, img_width, crop_size[1]):\n",
        "                crop = image[row:row+crop_size[0], col:col+crop_size[1]]\n",
        "\n",
        "                # Verifica se o tamanho do corte é válido antes de adicionar\n",
        "                if crop.shape[0] == crop_size[0] and crop.shape[1] == crop_size[1]:\n",
        "                    crops.append(crop)\n",
        "\n",
        "        return crops\n",
        "\n",
        "    def augment_images(self, image):\n",
        "        # Gera diferentes variações da imagem original por rotação e espelhamento\n",
        "        aug_images = []\n",
        "\n",
        "        # Aplica rotações de 0, 90, 180, e 270 graus\n",
        "        for angle in [0, 90, 180, 270]:\n",
        "            rotated = self.rotate_image(image, angle)\n",
        "            aug_images.append(rotated)\n",
        "            # Espelha horizontalmente cada imagem rotacionada\n",
        "            flipped = cv2.flip(rotated, 1)\n",
        "            aug_images.append(flipped)\n",
        "\n",
        "        return aug_images\n",
        "\n",
        "    def process_and_save_images(self, images, target_size, crop=False):\n",
        "        # Inicializa o contador global para salvar as imagens com nomes únicos\n",
        "        global_count = 0\n",
        "\n",
        "        print(f\"Sinalizador de corte antes do processamento: {crop}, tipo: {type(crop)}\")\n",
        "        # Se o parâmetro `crop` for verdadeiro, executa a lógica de corte e augmentação\n",
        "        if isinstance(crop, bool) and crop:\n",
        "            for img in images:\n",
        "                # Normaliza e redimensiona cada imagem\n",
        "                norm_img = self.normalize_image(img)\n",
        "                resized_img = self.resize_image(norm_img, target_size)\n",
        "                # Corta a imagem redimensionada em patches menores\n",
        "                cropped_imgs = self.crop_image(resized_img)\n",
        "\n",
        "                for crop_img in cropped_imgs:\n",
        "                    # Aplica augmentação a cada sub-imagem cortada\n",
        "                    augmented_imgs = self.augment_images(crop_img)\n",
        "                    for augmented_img in augmented_imgs:\n",
        "                        # Converte para PIL e salva no diretório de saída\n",
        "                        pil_img = Image.fromarray((augmented_img * 255).astype(np.uint8))\n",
        "                        pil_img.save(os.path.join(self.output_dir, f\"{global_count}.png\"))\n",
        "                        global_count += 1\n",
        "        else:\n",
        "            # Caso o corte não seja necessário, apenas redimensiona e aplica augmentação\n",
        "            for img in images:\n",
        "                norm_img = self.normalize_image(img)\n",
        "                resized_img = self.resize_image(norm_img, target_size)\n",
        "                augmented_imgs = self.augment_images(resized_img)\n",
        "                for augmented_img in augmented_imgs:\n",
        "                    # Converte para PIL e salva no diretório de saída\n",
        "                    pil_img = Image.fromarray((augmented_img * 255).astype(np.uint8))\n",
        "                    pil_img.save(os.path.join(self.output_dir, f\"{global_count}.png\"))\n",
        "                    global_count += 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5XBceCPUsf4"
      },
      "source": [
        "## Aplicando a esteira nas imagens que não contém talhão\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XT2-Ch-6W1GU",
        "outputId": "4a8590a6-60cb-449b-c14d-9527e1eb9d37"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oSHleCYU0Q8",
        "outputId": "c8cd2035-6455-43c4-8a5e-23dd54406d03"
      },
      "outputs": [],
      "source": [
        "# Aplicando KMEANS E SHARPEN\n",
        "base_dir = '/content/drive/MyDrive/desmatamento'\n",
        "pipeline = KMeansImageProcessingPipeline(base_dir)\n",
        "processed_images = pipeline.process_all_images(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rjh00PgllRlD"
      },
      "outputs": [],
      "source": [
        "# Aplicando Data Augmentation e Salvando as Imagens\n",
        "output_dir = '/content/drive/MyDrive/imagens_sem_talhao'\n",
        "pipeline = AugmentationImageProcessingPipeline(output_dir)\n",
        "pipeline.process_and_save_images(processed_images, target_size=(200,200))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_q6BQ1m4Yc3G"
      },
      "source": [
        "## Aplicando a esteira nas imagens que contém talhão"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQi1yqVlbGCJ",
        "outputId": "522e3d93-e5dd-4e06-b849-5879090f6d86"
      },
      "outputs": [],
      "source": [
        "# Aplicando KMEANS E SHARPEN\n",
        "base_dir = '/content/drive/MyDrive/imagens_com_talhao_raw'\n",
        "pipeline = KMeansImageProcessingPipeline(base_dir)\n",
        "processed_images = pipeline.process_all_images(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pi1RZkIBYhHm",
        "outputId": "ef01f6bc-6d17-4ef5-eb89-b032a3a3f679"
      },
      "outputs": [],
      "source": [
        "# Aplicando Data Augmentation e Salvando as Imagens\n",
        "output_dir = '/content/drive/MyDrive/imagens_com_talhao'\n",
        "pipeline = AugmentationImageProcessingPipeline(output_dir)\n",
        "pipeline.process_and_save_images(processed_images, target_size=(1200,1200), crop=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
