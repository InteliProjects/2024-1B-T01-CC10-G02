{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRaP3hMfWWHI"
      },
      "source": [
        "# Classificando Talhões com Arquitetura CNN Personalizada\n",
        "\n",
        "Este notebook descreve a implementação da nossa própria arquitetura de CNN. O objetivo do treinamento é classificar imagens e identificar se apresentam talhões ou não.\n",
        "\n",
        "Com base nisso, utilizamos técnicas e arquiteturas já existentes como base para a implementação, descritas detalhadamente a seguir no notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAnW_Z6LhI-3"
      },
      "source": [
        "## Imports e setup da GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93JwlWOJ--X9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.config.run_functions_eagerly(True)\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q62PZ79KhU60"
      },
      "source": [
        "## Conexão com o Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huco-1oZ9vey",
        "outputId": "9ab541f4-2001-4b7f-e17c-e653acb6bd46"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhmEXyOzh0Jr"
      },
      "source": [
        "## Conferência da existência de uma GPU\n",
        "\n",
        "É preciso a GPU para fazer o teste de performance do código com GPU e com CPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Z0YnMFBEVru",
        "outputId": "c0cbc16f-47d2-4ad2-f08c-3ef1148f01f2"
      },
      "outputs": [],
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Xm1meTVidOi"
      },
      "source": [
        "# Processamento das imagens e separação entre dados de teste e treino\n",
        "\n",
        "As imagens que serão processadas e consumidas pelo modelo foram préviamente processadas em nossa pipeline. Atualmente, no contexto da Sprint 2, a pipeline pode ser encontrada no link abaixo:\n",
        "\n",
        "[Pré processamento das imagens para o modelo de classificação](../../SPRINT%202/MODELO%20CLASSIFICAÇÃO/20240509%20-%20Processamento%20de%20imagens%20para%20o%20modelo.ipynb)\n",
        "\n",
        "Caso haja interesse em rodar e verificar a funcionalidade das funções, você pode encontrar um dataset que exemplifica essas imagens em amostra menor em: [Imagens com e sem talhão](../../../../data/SPRINT%202/MODELO%20DE%20CLASSIFICACAO/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kkYQaHRjhWm"
      },
      "source": [
        "## Funções de vetorização das imagens e labels\n",
        "\n",
        "A primeira função vetoriza as imagens com talhão e salva em uma lista, também cria uma lista com os labels da imagem, que no caso serão todos 1, porque todas as imagens tem talhão. A segunda função vetoriza as imagens de desmatamento (sem talhão) e cria a label 0 para todas essa imagens. A lista com imagens de talhão é cortada para ter no máximo 150 imagens, porque a base de desmatamento tem apenas 176 images, mesmo usando o data augmentation como proposto em **Lourenço, M.; Estima, D.; Oliveira, H.; Oliveira, L.; Mora, A. Automatic Rural Road Centerline Detection and Extraction from Aerial Images for a Forest Fire Decision Support System. Remote Sens. 2023, 15, 271.** https://doi.org/10.3390/rs15010271"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piVLGxilY2aF"
      },
      "outputs": [],
      "source": [
        "def vetorizar_imagem(caminho_desmatamento, label):\n",
        "    lista_imagens = []\n",
        "    labels = []\n",
        "    for nome_imagem in os.listdir(caminho_desmatamento):\n",
        "        caminho_imagem = os.path.join(caminho_desmatamento, nome_imagem)\n",
        "        img = cv2.imread(caminho_imagem)\n",
        "        if img is not None:  # Verifica se a imagem foi carregada corretamente\n",
        "            img = cv2.resize(img, (200, 200))  # Redimensiona a imagem para ter certeza que todas têm o mesmo tamanho\n",
        "            lista_imagens.append(img)\n",
        "            labels.append(label)\n",
        "        else:\n",
        "            print(f\"Erro ao carregar a imagem: {caminho_imagem}\")  # Informa se houver erro ao carregar alguma imagem\n",
        "    return np.array(lista_imagens), np.array(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tso8WgaKa8D2"
      },
      "source": [
        "## Vetorização das imagens dos talhões\n",
        "\n",
        "Chamamos a função que vetoriza as imagens dos talhões,passando o caminho para a pasta que contém essas imagens, e salvamos o retorno. Pode-se perceber que a saída são 4321 imagens de 200x200x3. Para equalizar com o conjunto de dados que não tem talhão, reduzimos para uma lista ter apenas 150 imagens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qE510GrZF13",
        "outputId": "ad45f4bd-c286-4eab-bcd9-772a36cfa7af"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    # Com talhão\n",
        "    caminho_com_talhao = '/content/drive/MyDrive/imagens_com_talhao'\n",
        "    imagens_com_talhao, labels_com_talhao = vetorizar_imagem(caminho_com_talhao, 1)\n",
        "    print(imagens_com_talhao.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0O5P1w6bSpt",
        "outputId": "16fc7173-61e6-438f-8c2c-af4a0ee6046b"
      },
      "outputs": [],
      "source": [
        "imagens_com_talhao = imagens_com_talhao[:150]\n",
        "labels_com_talhao = labels_com_talhao[:150]\n",
        "\n",
        "print(imagens_com_talhao.shape)\n",
        "print(labels_com_talhao.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUhBP9BMbF3Z"
      },
      "source": [
        "## Vetorização das imagens de desmatamento\n",
        "\n",
        "\n",
        "Chamamos a função que vetoriza as imagens de desmatamento, passando o caminho para a pasta que contém essas imagens, e salvamos o retorno. Pode-se perceber que a saída são 176 imagens de 200x200x3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3gqnm-9sNlN",
        "outputId": "2d77739a-082e-4271-b24d-b71186bb5ed2"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    caminho_desmatamento = '/content/drive/MyDrive/cropped_desmatamento'\n",
        "    imagens_sem_talhao, labels_sem_talhao = vetorizar_imagem(caminho_desmatamento, 0)\n",
        "\n",
        "    print(imagens_sem_talhao.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZZfHgofceg5",
        "outputId": "236b09e9-39e5-4fca-e851-547764fa405c"
      },
      "outputs": [],
      "source": [
        "labels_sem_talhao.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgyjiJdCbVdZ"
      },
      "source": [
        "## Combinação e normalização das imagens\n",
        "\n",
        "Combinamos as imagens de talhão e desmatamento em uma só lista e também juntamos as labels. Após isso, normalizamos a lista das imagens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_v_Io_EibOH8",
        "outputId": "1ceb8559-abed-4127-bc33-31479208965c"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    combined_images = np.concatenate((imagens_com_talhao, imagens_sem_talhao), axis=0)\n",
        "    combined_labels = np.concatenate((labels_com_talhao, labels_sem_talhao), axis=0)\n",
        "\n",
        "    # Normalização das imagens\n",
        "    combined_images = combined_images / 255.0\n",
        "\n",
        "    # Imprimir tamanhos dos arrays combinados para confirmar a correção\n",
        "    print(\"Shape of the combined images array:\", combined_images.shape)\n",
        "    print(\"Shape of the combined labels array:\", combined_labels.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ex_9qiqYjaLu"
      },
      "source": [
        "## Separação entre dados de teste e treino\n",
        "\n",
        "Fazemos a separação entre dados de teste e de treino. Há também o embaralhamento da lista de imagens para que não fiquem apenas imagens de desmatamento no teste e vice-versa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpUMXbHOLhdy",
        "outputId": "ab5deaa2-7ed3-4de9-8ef4-2111c8cd01ac"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "(trainX, testX, trainY, testY) = train_test_split(combined_images, combined_labels)\n",
        "\n",
        "# O código abaixo converterá os rótulos em vetores one-hot encoding\n",
        "trainY = to_categorical(trainY, 2)\n",
        "testY = to_categorical(testY, 2)\n",
        "print(testY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KESW55Pjmu7"
      },
      "source": [
        "# Modelo: Implementação da LeNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEoAZW59jvzS"
      },
      "source": [
        "## Arquitetura do modelo\n",
        "\n",
        "Nossa referência para a criação do modelo foram duas: LENET e outra dada em aula pelo Prof. Raphael. A primeira pode ser vista a semelhança nas duas primeiras camadas de convolução, com o número de neurônios da camada sendo igual a LENET. Diminuímos o tamanho do kernel, em relação a LENET, para poder ter maior precisão na detecção de bordas dos talhões. De acordo com o que vimos na aula do Prof. Raphael, aumentamos o número de camadas para poder extrair características mais complexas da imagem. Nosso modelo tem o mesmo número de camadas e pooling do notebook da aula, entretanto mudamos o número de neurônios e o tamanho da janela do pooling para diminuir os parâmetros treináveis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2q-KvgV0_bel",
        "outputId": "760e9e41-32e1-491a-c65b-9d4605aa1513"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(6, (3, 3), activation='relu', input_shape=(200, 200, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(3,3),\n",
        "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_x3yUtcjzjz"
      },
      "source": [
        "## Métricas, função de perda e otimizador do modelo\n",
        "\n",
        "O modelo de classificação implementado utiliza a função de perda `binary_crossentropy`, que é ideal para problemas de classificação binária. Esta função é eficaz porque minimiza a distância entre as distribuições de probabilidade previstas e os rótulos verdadeiros, auxiliando o modelo a gerar previsões mais precisas, conforme destacado por Goodfellow et al. (2016).\n",
        "\n",
        "Para a avaliação do desempenho do modelo, utilizamos `accuracy`, uma das mais intuitivas e comumente usadas em problemas de classificação. Ela quantifica a proporção de previsões corretas feitas pelo modelo, proporcionando uma medida direta de sua capacidade de classificar corretamente as imagens (Zhang et al., 2018).\n",
        "\n",
        "O otimizador Adam é utilizado no modelo devido à sua eficácia em redes neurais profundas, adaptando automaticamente a taxa de aprendizagem e sendo computacionalmente eficiente. (Kingma e Ba, 2014).\n",
        "\n",
        "\n",
        "**Referências**\n",
        "- Goodfellow, I., Bengio, Y., & Courville, A. (2016). *Deep Learning*. MIT Press. [http://www.deeplearningbook.org](http://www.deeplearningbook.org)\n",
        "- Kingma, D. P., & Ba, J. (2014). Adam: A method for stochastic optimization. [https://arxiv.org/abs/1412.6980](https://arxiv.org/abs/1412.6980)\n",
        "- Zhang, Z., et al. (2018). *Understanding deep learning metrics and parameters.* [https://doi.org/10.1016/j.ymssp.2018.06.028](https://doi.org/10.1016/j.ymssp.2018.06.028)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7d9rCuYi83w"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdjOujzBliSY"
      },
      "source": [
        "# Teste entre GPU e CPU\n",
        "\n",
        "Comparar o desempenho de modelos treinados usando CPU e GPU é fundamental para entender como os recursos computacionais podem impactar a eficiência do treinamento. O processamento de dados em GPUs oferece paralelismo massivo e pode acelerar significativamente o treinamento de modelos de aprendizado profundo, especialmente com redes neurais complexas. No entanto, em alguns casos, as CPUs também podem ser eficientes, especialmente para modelos menores ou conjuntos de dados menos complexos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbExsb9JlwAZ"
      },
      "source": [
        "## Função para o teste de processamento\n",
        "\n",
        "Os tempos totais de treinamento e inferência são cronometrados e armazenados, permitindo análises comparativas entre as execuções em diferentes dispositivos. Esses tempos são visualizados através de gráficos de barras para facilitar a compreensão das diferenças de desempenho entre treinamento com CPU e GPU. Além disso, gráficos de linhas são utilizados para mostrar a evolução da acurácia e perda durante o treinamento, oferecendo insights sobre a eficácia do modelo ao longo das épocas em cada dispositivo. Esta abordagem não apenas destaca o impacto do hardware no desempenho do treinamento de modelos de aprendizado profundo, mas também ajuda a avaliar a eficiência do modelo em termos de velocidade e precisão."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-OosnIdlvqB"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def treinamento_e_inferência(trainX, testX, trainY, testY, device):\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(6, (3, 3), activation='relu', input_shape=(200, 200, 3)),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(3, 3),\n",
        "        tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(2, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Treinamento do modelo\n",
        "    start_time = time.time()\n",
        "    history = model.fit(trainX, trainY, batch_size=128, epochs=20, verbose=0,\n",
        "                        validation_data=(testX, testY))\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Inferência\n",
        "    start_time = time.time()\n",
        "    predictions = model.predict(testX, batch_size=64)\n",
        "    inference_time = time.time() - start_time\n",
        "\n",
        "    return training_time, inference_time, history\n",
        "\n",
        "def plot_metrics(training_time, inference_time, history, device):\n",
        "    # Plotando a acurácia e a perda\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
        "    plt.title(f'Accuracy over Epochs on {device}')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "    plt.title(f'Loss over Epochs on {device}')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Plotando tempos de treinamento e inferência\n",
        "    plt.figure(figsize=(7, 5))\n",
        "    plt.bar(['Training', 'Inference'], [training_time, inference_time])\n",
        "    plt.title(f'Training and Inference Time on {device}')\n",
        "    plt.ylabel('Time (seconds)')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15ijaEPanYRu"
      },
      "source": [
        "## Teste entre GPU e CPU\n",
        "\n",
        "Para testar o modelo na CPU, podemos alterar o ambiente de execução do Colab. No entanto, isso exige uma reinicialização completa do ambiente, o que pode ser inconveniente.\n",
        "\n",
        "Através do código abaixo, podemos executar o modelo na CPU sem a necessidade de alterar o ambiente de execução.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-fMrUcoufRA"
      },
      "source": [
        "#### Mensurando CPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 973
        },
        "id": "4kmqnslwnbck",
        "outputId": "199f3ea9-5b77-4e53-c0ea-b963ccfea5a7"
      },
      "outputs": [],
      "source": [
        "# Treinando com CPU\n",
        "with tf.device('/cpu:0'):\n",
        "    print(\"CPU\")\n",
        "    training_time_cpu, inference_time_cpu, history_cpu = treinamento_e_inferência(trainX, testX, trainY, testY, 'CPU')\n",
        "    plot_metrics(training_time_cpu, inference_time_cpu, history_cpu, 'CPU')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvITxHEatECA",
        "outputId": "6172531a-1c13-4a85-c711-d698069f3462"
      },
      "outputs": [],
      "source": [
        "print('Tempo de treino CPU: ', training_time_cpu)\n",
        "print('Tempo de inferência CPU: ', inference_time_cpu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFKzHpMBuk9E"
      },
      "source": [
        "#### Mensurando GPU\n",
        "\n",
        "Através do código abaixo, podemos executar o modelo na GPU sem a necessidade de alterar o ambiente de execução."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cvUP0mzRtf_9",
        "outputId": "ed5ff32d-ed9c-4544-c5af-72ffe34bd9be"
      },
      "outputs": [],
      "source": [
        "# Treinando com GPU\n",
        "with tf.device('/gpu:0'):\n",
        "    print(\"GPU\")\n",
        "    training_time_gpu, inference_time_gpu, history_gpu = treinamento_e_inferência(trainX, testX, trainY, testY, 'GPU')\n",
        "    plot_metrics(training_time_gpu, inference_time_gpu, history_gpu, 'GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_4U2IOktstL",
        "outputId": "d4a595be-6723-4626-9684-6d42179f3b5d"
      },
      "outputs": [],
      "source": [
        "print('Tempo de treino GPU: ', training_time_gpu)\n",
        "print('Tempo de inferência GPU: ', inference_time_gpu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkQAmnckuqp0"
      },
      "source": [
        "#### Analise dos resultados\n",
        "\n",
        "Ao analisar os gráficos de Acurácia ao longo das épocas e a Perda, ambos os dispositivos mostram uma tendência consistente de melhoria na acurácia e redução da perda à medida que o número de épocas aumenta, indicando uma convergência eficaz do modelo em aprender a partir dos dados fornecidos.\n",
        "\n",
        "O tempo de treinamento no GPU (10.22 segundos) é **drasticamente menor** em comparação com o CPU (202.24 segundos), ***refletindo a eficiência superior da GPU em manipular operações de matriz necessárias ***para o treinamento de redes neurais profundas.\n",
        "\n",
        " A GPU oferece vantagens claras para o treinamento de modelos, acelerando o processo e permitindo uma iteração mais rápida. Por outro lado, a decisão entre usar GPU ou CPU para inferência pode ser influenciada por considerações de custo e escalabilidade, dadas as semelhanças no tempo de execução.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4ShblUZlLUx"
      },
      "source": [
        "# Treinamento e teste do modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2tl7MvrM4Sp",
        "outputId": "6f70da0b-5a39-43d6-89b7-efe7b8be98c1"
      },
      "outputs": [],
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    H = model.fit(trainX, trainY, batch_size=64, epochs=20, verbose=2,\n",
        "            validation_data=(testX, testY))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W817cpPuirXX",
        "outputId": "bba5ffb1-25f0-441c-afb2-85233731d1db"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(testX, batch_size=16, verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUxObrvSjaIT"
      },
      "source": [
        "# Resultados\n",
        "\n",
        "[inserir texto]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nG18Fe-YyZUQ"
      },
      "source": [
        "\n",
        "## Funções auxiliares para mensurar os resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diEWHMROxmdU"
      },
      "outputs": [],
      "source": [
        "def plot_learning_curves(history):\n",
        "    epochs = range(1, len(history.history['accuracy']) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, history.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(epochs, history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Accuracy over Epochs')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, history.history['loss'], label='Training Loss')\n",
        "    plt.plot(epochs, history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Loss over Epochs')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kt9NAZSJxuMA"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "def plot_confusion_matrix(testY, predictions):\n",
        "    conf_mat = confusion_matrix(testY.argmax(axis=1), predictions.argmax(axis=1))\n",
        "    sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "                xticklabels=[str(label) for label in range(2)],\n",
        "                yticklabels=[str(label) for label in range(2)])\n",
        "    plt.xlabel('Predicted Labels')\n",
        "    plt.ylabel('True Labels')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEVVBaZsx2cn"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def print_classification_report(testY, predictions):\n",
        "    report = classification_report(testY.argmax(axis=1), predictions.argmax(axis=1),\n",
        "                                   target_names=[str(label) for label in range(2)])\n",
        "    print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCPTov8nyPmq"
      },
      "source": [
        "## Visualizando métricas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "EO0br1azx-9p",
        "outputId": "18ee25ee-3831-447f-9b4c-ba99eadb2d2d"
      },
      "outputs": [],
      "source": [
        "plot_learning_curves(H)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "24KM4w6XycWT",
        "outputId": "7f846e7d-f75c-4ef9-a7db-ca5f8bf3529f"
      },
      "outputs": [],
      "source": [
        "plot_confusion_matrix(testY, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6kotuc9yedG",
        "outputId": "9ff262f2-5135-47f1-9d87-ca7ee6fd2321"
      },
      "outputs": [],
      "source": [
        "print_classification_report(testY, predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCMupcU7zZhK"
      },
      "source": [
        "Os resultados obtidos na avaliação do modelo de rede neural demonstram um desempenho promissor, evidenciado pela alta acurácia e pela redução consistente da perda ao longo das épocas de treinamento e validação.\n",
        "\n",
        "A análise da perda durante as épocas mostra uma diminuição uniforme, apesar de pequenas oscilações nas últimas épocas, possivelmente devido à variação nos lotes de dados ou ajustes nos parâmetros. A tendência geral de queda na perda reitera a eficácia do processo de aprendizado.\n",
        "\n",
        "As análises dispostas, complementadas pelos comentários durante a Sprint Review, mostram a necessidade de revisitarmos (se necessário for prosseguir com o modelo), a fim de que possamos testar e aprimorar a capacidade do modelo de generalizar seu conhecimento.\n",
        "\n",
        "Contudo, uma análise mais profunda e comparativa pode ser encontrada na seção de Resultados do [artigo](../../artigo/artigo-grupo2.md).\n",
        "\n",
        "\n",
        "Referências:\n",
        "\n",
        "**How do you evaluate and compare different CNN models using metrics and plots?** *Disponível em:* <https://www.linkedin.com/advice/1/how-do-you-evaluate-compare-different-cnn-models#:~:text=For%20classification%20tasks%2C%20where%20you>. Acesso em: 11 maio. 2024.\n",
        "\n",
        "‌"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFLHaGz4zaX0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "7kkYQaHRjhWm",
        "Tso8WgaKa8D2",
        "AUhBP9BMbF3Z",
        "lgyjiJdCbVdZ",
        "Ex_9qiqYjaLu",
        "XbExsb9JlwAZ",
        "nG18Fe-YyZUQ"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
